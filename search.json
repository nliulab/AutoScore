[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AutoScore: An Interpretable Machine Learning-Based Automatic Clinical Score Generator",
    "section": "",
    "text": "AutoScore is a novel machine learning framework to automate the development of interpretable clinical scoring models. AutoScore consists of six modules: 1) variable ranking with machine learning, 2) variable transformation, 3) score derivation, 4) model selection, 5) domain knowledge-based score fine-tuning, and 6) performance evaluation. The original AutoScore structure is elaborated in this article and its flowchart is shown in the following figure. AutoScore was originally designed for binary outcomes and later extended to survival outcomes and ordinal outcomes. AutoScore could seamlessly generate risk scores using a parsimonious set of variables for different types of clinical outcomes, which can be easily implemented and validated in clinical practice. Moreover, it enables users to build transparent and interpretable clinical scores quickly in a straightforward manner. Please visit GitHub page for source code.\n\n\n\n\n\nThe five pipeline functions constitute the 5-step process for generating point-based clinical scores for binary (Chapter 4), survival (Chapter 5) and ordinal (Chapter 6) outcomes.\nThis 5-step process gives users the flexibility of customization (e.g., determining the final list of variables according to the parsimony plot, and fine-tuning the cutoffs in variable transformation). Please follow the step-by-step instructions (in following chapters) to build your own scores.\n\nSTEP(i): AutoScore_rank()or AutoScore_rank_Survival() or AutoScore_rank_Ordinal() - Rank variables with machine learning (AutoScore Module 1)\nSTEP(ii): AutoScore_parsimony() or AutoScore_parsimony_Survival() or AutoScore_parsimony_Ordinal() - Select the best model with parsimony plot (AutoScore Modules 2+3+4)\nSTEP(iii): AutoScore_weighting() or AutoScore_weighting_Survival() or AutoScore_weighting_Ordinal() - Generate the initial score with the final list of variables (Re-run AutoScore Modules 2+3)\nSTEP(iv): AutoScore_fine_tuning() or AutoScore_fine_tuning_Survival() or AutoScore_fine_tuning_Ordinal() - Fine-tune the score by revising cut_vec with domain knowledge (AutoScore Module 5)\nSTEP(v): AutoScore_testing() or AutoScore_testing_Survival() or AutoScore_testing_Ordinal() - Evaluate the final score with ROC analysis (AutoScore Module 6)\n\nWe also include several functions in the package, which could help with data analysis and result reporting. As demonstrated in Chapter 3, these functions are compute_descriptive_table() for generating the table of descriptive analysis for your dataset, compute_uni_variable_table() or compute_uni_variable_table_survival() or compute_uni_variable_table_ordinal() for creating the table of univariable analysis for your dataset, and compute_multi_variable_table() for generating the table of multivariable analysis for your dataset.\n\n\n\nInstall from GitHub or CRAN：\n\n# From Github\ninstall.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(repo = \"nliulab/AutoScore\", build_vignettes = TRUE)\n\n# From CRAN (recommended)\ninstall.packages(\"AutoScore\")\n\nLoad AutoScore package:\n\nlibrary(AutoScore)\n\n\n\n\n\n\n\nXie F, Chakraborty B, Ong MEH, Goldstein BA, Liu N. AutoScore: A machine learning-based automatic clinical score generator and its application to mortality prediction using electronic health records. JMIR Medical Informatics 2020; 8(10): e21798.\n\n\n\n\n\nXie F, Ning Y, Yuan H, Goldstein BA, Ong MEH, Liu N, Chakraborty B. AutoScore-Survival: Developing interpretable machine learning-based time-to-event scores with right-censored survival data. Journal of Biomedical Informatics 2022; 125: 103959.\nSaffari SE, Ning Y, Xie F, Chakraborty B, Volovici V, Vaughan R, Ong MEH, Liu N, AutoScore-Ordinal: An interpretable machine learning framework for generating scoring models for ordinal outcomes, BMC Medical Research Methodology 2022; 22: 286.\nNing Y, Li S, Ong ME, Xie F, Chakraborty B, Ting DS, Liu N. A novel interpretable machine learning system to generate clinical risk scores: An application for predicting early mortality or unplanned readmission in a retrospective cohort study. PLOS Digit Health 2022; 1(6): e0000062.\n\n\n\n\n\n\nFeng Xie (Email: xief@u.duke.nus.edu)\nYilin Ning (Email: yilin.ning@duke-nus.edu.sg)\nNan Liu (Email: liu.nan@duke-nus.edu.sg)"
  },
  {
    "objectID": "01-related_papers.html",
    "href": "01-related_papers.html",
    "title": "1  Related papers",
    "section": "",
    "text": "Updated on 2022-10-13\nPlease check updated list here."
  },
  {
    "objectID": "01-related_papers.html#autoscore-original-paper",
    "href": "01-related_papers.html#autoscore-original-paper",
    "title": "1  Related papers",
    "section": "1.1 AutoScore original paper",
    "text": "1.1 AutoScore original paper\n\nXie F, Chakraborty B, Ong MEH, Goldstein BA, Liu N. AutoScore: A machine learning-based automatic clinical score generator and its application to mortality prediction using electronic health records. JMIR Medical Informatics 2020; 8(10): e21798."
  },
  {
    "objectID": "01-related_papers.html#autoscore-method-extension",
    "href": "01-related_papers.html#autoscore-method-extension",
    "title": "1  Related papers",
    "section": "1.2 AutoScore method extension",
    "text": "1.2 AutoScore method extension\n\n1.2.1 Extension to survival outcomes\n\nXie F, Ning Y, Yuan H, Goldstein BA, Ong MEH, Liu N, Chakraborty B. AutoScore-Survival: Developing interpretable machine learning-based time-to-event scores with right-censored survival data. Journal of Biomedical Informatics 2022; 125: 103959.\n\n\n\n1.2.2 Extension to ordinal outcomes\n\nSaffari SE, Ning Y, Xie F, Chakraborty B, Volovici V, Vaughan R, Ong MEH, Liu N, AutoScore-Ordinal: An interpretable machine learning framework for generating scoring models for ordinal outcomes, BMC Medical Research Methodology 2022; 22: 286.\n\n\n\n1.2.3 Extension to unbalanced data\n\nYuan H, Xie F, Ong MEH, Ning Y, Chee ML, Saffari SE, Abdullah HR, Goldstein BA, Chakraborty B, Liu N. AutoScore-Imbalance: An interpretable machine learning tool for development of clinical scores with rare events data. Journal of Biomedical Informatics 2022; 129: 104072.\n\n\n\n1.2.4 AutoScore-ShapleyVIC framework for robust variable ranking\n\nNing Y, Li S, Ong ME, Xie F, Chakraborty B, Ting DS, Liu N. A novel interpretable machine learning system to generate clinical risk scores: An application for predicting early mortality or unplanned readmission in a retrospective cohort study. PLOS Digit Health 2022; 1(6): e0000062."
  },
  {
    "objectID": "01-related_papers.html#autoscore-clinical-applications",
    "href": "01-related_papers.html#autoscore-clinical-applications",
    "title": "1  Related papers",
    "section": "1.3 AutoScore clinical applications",
    "text": "1.3 AutoScore clinical applications\nA collection of clinical applications using AutoScore and its extensions can be found on this page. The list is categorized according to medical specialties and is updated regularly. However, due to the manual process of updating, we are unable to keep track of all publications.\n\nEmergency medicine\nNeurology\nOut-of-hospital cardiac arrest\nRenal medicine\n\n\n1.3.1 Emergency medicine\n\nXie F, Ong MEH, Liew JNMH, et al. Development and assessment of an interpretable machine learning triage tool for estimating mortality after emergency admissions. JAMA Network Open 2021 Aug; 4(8): e2118467.\nXie F, Liu N, Yan L, et al. Development and validation of an interpretable machine learning scoring tool for estimating time to emergency readmissions. eClinicalMedicine 2022 Mar; 45: 101315.\n\n\n\n1.3.2 Neurology\n\nPetersen KK, Lipton RB, Grober E, et al. Predicting amyloid positivity in cognitively unimpaired older adults: A machine learning approach using the A4 data. Neurology 2022 Apr; 98(24): e2425-e2435.\n\n\n\n1.3.3 Out-of-hospital cardiac arrest\n\nWong XY, Ang YK, Li K, et al. Development and validation of the SARICA score to predict survival after return of spontaneous circulation in out of hospital cardiac arrest using an interpretable machine learning framework. Resuscitation 2022 Jan; 170: 126-133.\nLiu N, Liu M, Chen X, et al. Development and validation of interpretable prehospital return of spontaneous circulation (P-ROSC) score for out-of-hospital cardiac arrest patients using machine learning. eClinicalMedicine 2022 Jun; 48: 101422.\n\n\n\n1.3.4 Renal medicine\n\nAng Y, Li S, Ong MEH, et al. Development and validation of an interpretable clinical score for early identification of acute kidney injury at the emergency department. Scientific Reports 2022 May; 12: 7111."
  },
  {
    "objectID": "03-data_processing.html",
    "href": "03-data_processing.html",
    "title": "2  Data processing and checking",
    "section": "",
    "text": "Read data from CSV or Excel files.\nFor this demo, use the integrated data samples in the package.\nsample_data has 20000 simulated samples with binary outcomes, with the same distribution as the data in the MIMIC-III ICU database (https://mimic.mit.edu/).\nsample_data_survival has 20000 simulated samples with survival outcomes, which are also from MIMIC-III ICU database.\nsample_data_ordinal has 20000 simulated samples with a 3-category ordinal outcome, based on emergency department data from a tertiary hospital.\n\n\nlibrary(AutoScore)\ndata(\"sample_data\")\ndata(\"sample_data_survival\")\ndata(\"sample_data_ordinal\")"
  },
  {
    "objectID": "03-data_processing.html#check-outcomes",
    "href": "03-data_processing.html#check-outcomes",
    "title": "2  Data processing and checking",
    "section": "2.2 Check outcomes",
    "text": "2.2 Check outcomes\nEnsure that there are dependent variable (i.e., outcome).\n\nFor binary and ordinal outcomes: Change the name of outcome to \"label\" (make sure no other variables using the same name).\nFor survival outcomes: Change the name of the outcome to \"label_time\" and \"label_status\".\nYou may use the following code to revise or check the names of outcomes.\n\n\nnames(sample_data)[names(sample_data) == \"Mortality_inpatient\"] <- \"label\"\n\n# Sample data with survival and ordinal outcome already has appropriate variable \n# names:\nnames(sample_data_survival)\n\n [1] \"Vital_A\"      \"Vital_B\"      \"Vital_C\"      \"Vital_D\"      \"Vital_E\"     \n [6] \"Vital_F\"      \"Vital_G\"      \"Lab_A\"        \"Lab_B\"        \"Lab_C\"       \n[11] \"Lab_D\"        \"Lab_E\"        \"Lab_F\"        \"Lab_G\"        \"Lab_H\"       \n[16] \"Lab_I\"        \"Lab_J\"        \"Lab_K\"        \"Lab_L\"        \"Lab_M\"       \n[21] \"Age\"          \"label_status\" \"label_time\"  \n\nnames(sample_data_ordinal)\n\n [1] \"label\"    \"Age\"      \"Gender\"   \"Util_A\"   \"Util_B\"   \"Util_C\"  \n [7] \"Util_D\"   \"Comorb_A\" \"Comorb_B\" \"Comorb_C\" \"Comorb_D\" \"Comorb_E\"\n[13] \"Lab_A\"    \"Lab_B\"    \"Lab_C\"    \"Vital_A\"  \"Vital_B\"  \"Vital_C\" \n[19] \"Vital_D\"  \"Vital_E\"  \"Vital_F\" \n\n\n\nCheck if data fulfill the basic requirement by AutoScore using the appropriate function for the outcome type.\n\n\ncheck_data(sample_data)\n\nData type check passed. \n\n\nNo NA in data \n\ncheck_data_survival(sample_data_survival)\n\nData type check passed. \nNo NA in data \n\ncheck_data_ordinal(sample_data_ordinal)\n\nData type check passed. \nNo NA in data \n\n\n\nFix the problem if you see any warnings.\nModify your data, and re-run the appropriate function to check the data again until there are no warning messages."
  },
  {
    "objectID": "03-data_processing.html#check-variables",
    "href": "03-data_processing.html#check-variables",
    "title": "2  Data processing and checking",
    "section": "2.3 Check variables",
    "text": "2.3 Check variables\nUse check_data(), check_data_survival() or check_data_ordinal() to check whether current data fulfill the following requirements:\n\nNo special characters from variable names, e.g., [, ], (, ),,. (Suggest using _ to replace them if needed).\nName of the variable should be unique and not entirely included by other variable names.\nIndependent variables should be numeric (class: num/int) or categorical (class: factor/logic).\n\n\n2.3.1 Handle missing values\nThe check data functions check_data(), check_data_survival() or check_data_ordinal() will display the missing rates as warnings for variables that contain missingness.\n\nAs input, AutoScore requires a complete dataset (no missing values). Thus, if your data is complete and fulfill other requirements, you can then move forward to modelling.\nIf there are missing values in your dataset and you believe the missingness in your dataset is informative and prevalent enough that you prefer to preserve them as NA rather than removing or doing imputation, you can also move forward because AutoScore can automatically handle missing values by treating them as a new category named ‘Unknown’.\nOtherwise, we suggest you first handle your missing values using appropriate imputation methods.\n\n\n\n\n\n\n\nNote\n\n\n\nIn either way, imputation or treating as a new category, variables with high missing rate (e.g., >80%) may reduce model stability and should be analysed with caution.\n\n\n\n\n2.3.2 Optional operations\n\nCheck variable distribution.\nHandle outliers. The raw data may contain outliers caused by system errors or clerical mistakes. User are recommended to handle them well before using AutoScore to ensure good performance."
  },
  {
    "objectID": "02-desc_analysis.html",
    "href": "02-desc_analysis.html",
    "title": "3  Descriptive analysis",
    "section": "",
    "text": "Before building AutoScore models, users can use our package and codes to conduct do descriptive analysis (e.g., univariable analysis, multivariable analysis) for data with binary, survival, or ordinal outcomes."
  },
  {
    "objectID": "02-desc_analysis.html#binary",
    "href": "02-desc_analysis.html#binary",
    "title": "3  Descriptive analysis",
    "section": "3.1 Binary outcome",
    "text": "3.1 Binary outcome\n\nCompute descriptive table (usually Table 1 in medical literature) for the dataset.\n\n\nlibrary(AutoScore)\nlibrary(knitr)\ndata(\"sample_data\")\nnames(sample_data)[names(sample_data) == \"Mortality_inpatient\"] <- \"label\"\ncompute_descriptive_table(sample_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall\nFALSE\nTRUE\np\ntest\n\n\n\n\nn\n20000\n18412\n1588\n\n\n\n\nVital_A (mean (SD))\n85.40 (15.23)\n84.81 (15.11)\n92.25 (14.98)\n<0.001\n\n\n\nVital_B (mean (SD))\n119.13 (16.72)\n119.57 (16.67)\n114.01 (16.49)\n<0.001\n\n\n\nVital_C (mean (SD))\n61.15 (10.81)\n61.50 (10.77)\n57.13 (10.48)\n<0.001\n\n\n\nVital_D (mean (SD))\n78.41 (11.14)\n78.74 (11.10)\n74.60 (10.95)\n<0.001\n\n\n\nVital_E (mean (SD))\n18.57 (3.92)\n18.35 (3.86)\n21.13 (3.74)\n<0.001\n\n\n\nVital_F (mean (SD))\n36.84 (0.59)\n36.84 (0.59)\n36.79 (0.57)\n0.001\n\n\n\nVital_G (mean (SD))\n97.17 (1.98)\n97.20 (1.97)\n96.76 (2.03)\n<0.001\n\n\n\nLab_A (mean (SD))\n138.24 (41.69)\n137.36 (41.73)\n148.42 (39.80)\n<0.001\n\n\n\nLab_B (mean (SD))\n14.12 (3.44)\n13.94 (3.39)\n16.23 (3.31)\n<0.001\n\n\n\nLab_C (mean (SD))\n24.04 (4.34)\n24.18 (4.31)\n22.47 (4.39)\n<0.001\n\n\n\nLab_D (mean (SD))\n1.55 (1.30)\n1.52 (1.29)\n1.86 (1.35)\n<0.001\n\n\n\nLab_E (mean (SD))\n104.56 (5.54)\n104.62 (5.53)\n103.90 (5.52)\n<0.001\n\n\n\nLab_F (mean (SD))\n32.80 (5.53)\n32.94 (5.51)\n31.11 (5.47)\n<0.001\n\n\n\nLab_G (mean (SD))\n11.04 (1.97)\n11.11 (1.96)\n10.30 (1.97)\n<0.001\n\n\n\nLab_H (mean (SD))\n2.09 (1.14)\n2.03 (1.12)\n2.82 (1.15)\n<0.001\n\n\n\nLab_I (mean (SD))\n229.36 (113.73)\n230.81 (113.62)\n212.51 (113.65)\n<0.001\n\n\n\nLab_J (mean (SD))\n4.23 (0.62)\n4.22 (0.61)\n4.28 (0.63)\n<0.001\n\n\n\nLab_K (mean (SD))\n25.92 (18.29)\n24.85 (17.88)\n38.34 (18.52)\n<0.001\n\n\n\nLab_L (mean (SD))\n138.27 (4.25)\n138.29 (4.24)\n138.07 (4.39)\n0.051\n\n\n\nLab_M (mean (SD))\n12.28 (8.27)\n12.04 (8.21)\n14.98 (8.60)\n<0.001\n\n\n\nAge (mean (SD))\n62.46 (16.29)\n61.62 (16.12)\n72.21 (15.12)\n<0.001\n\n\n\nlabel = TRUE (%)\n1588 (7.9)\n0 (0.0)\n1588 (100.0)\n<0.001\n\n\n\n\n\n\n\nPerform univariable analysis and generate the result table with (unadjusted) odd ratios.\n\n\nuni_table <- compute_uni_variable_table(sample_data)\nkable(uni_table)\n\n\n\n\n\nOR\np value\n\n\n\n\nVital_A\n1.033(1.03-1.037)\n<0.001\n\n\nVital_B\n0.98(0.977-0.983)\n<0.001\n\n\nVital_C\n0.963(0.958-0.968)\n<0.001\n\n\nVital_D\n0.967(0.963-0.972)\n<0.001\n\n\nVital_E\n1.209(1.192-1.226)\n<0.001\n\n\nVital_F\n0.867(0.794-0.946)\n0.001\n\n\nVital_G\n0.897(0.875-0.92)\n<0.001\n\n\nLab_A\n1.006(1.005-1.008)\n<0.001\n\n\nLab_B\n1.222(1.202-1.241)\n<0.001\n\n\nLab_C\n0.912(0.902-0.923)\n<0.001\n\n\nLab_D\n1.208(1.163-1.254)\n<0.001\n\n\nLab_E\n0.977(0.968-0.986)\n<0.001\n\n\nLab_F\n0.942(0.933-0.95)\n<0.001\n\n\nLab_G\n0.81(0.788-0.831)\n<0.001\n\n\nLab_H\n1.815(1.734-1.9)\n<0.001\n\n\nLab_I\n0.999(0.998-0.999)\n<0.001\n\n\nLab_J\n1.176(1.082-1.278)\n<0.001\n\n\nLab_K\n1.039(1.036-1.042)\n<0.001\n\n\nLab_L\n0.988(0.976-1)\n0.051\n\n\nLab_M\n1.042(1.036-1.048)\n<0.001\n\n\nAge\n1.042(1.039-1.046)\n<0.001\n\n\n\n\n\n\nPerform multivariable analysis and generate the result table with adjusted odd ratios.\n\n\nmulti_table <- compute_multi_variable_table(sample_data)\nkable(multi_table)\n\n\n\n\n\nadjusted_OR\np value\n\n\n\n\nVital_A\n1.032(1.027-1.037)\n<0.001\n\n\nVital_B\n0.976(0.97-0.983)\n<0.001\n\n\nVital_C\n0.958(0.945-0.971)\n<0.001\n\n\nVital_D\n1.049(1.031-1.067)\n<0.001\n\n\nVital_E\n1.153(1.133-1.173)\n<0.001\n\n\nVital_F\n0.844(0.757-0.942)\n0.002\n\n\nVital_G\n0.995(0.965-1.027)\n0.774\n\n\nLab_A\n1.001(1-1.002)\n0.184\n\n\nLab_B\n1.111(1.067-1.156)\n<0.001\n\n\nLab_C\n0.946(0.912-0.981)\n0.003\n\n\nLab_D\n0.774(0.728-0.823)\n<0.001\n\n\nLab_E\n0.928(0.897-0.96)\n<0.001\n\n\nLab_F\n1.122(1.081-1.165)\n<0.001\n\n\nLab_G\n0.636(0.572-0.707)\n<0.001\n\n\nLab_H\n1.615(1.526-1.71)\n<0.001\n\n\nLab_I\n0.997(0.997-0.998)\n<0.001\n\n\nLab_J\n0.73(0.654-0.814)\n<0.001\n\n\nLab_K\n1.033(1.029-1.038)\n<0.001\n\n\nLab_L\n1.04(1.005-1.077)\n0.026\n\n\nLab_M\n1.029(1.022-1.037)\n<0.001\n\n\nAge\n1.047(1.042-1.051)\n<0.001"
  },
  {
    "objectID": "02-desc_analysis.html#survival",
    "href": "02-desc_analysis.html#survival",
    "title": "3  Descriptive analysis",
    "section": "3.2 Survival outcome",
    "text": "3.2 Survival outcome\n\nCompute descriptive table (usually Table 1 in medical literature) for the data with survival outcome\n\n\ndata(\"sample_data_survival\")\ncompute_descriptive_table(sample_data_survival)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall\nFALSE\nTRUE\np\ntest\n\n\n\n\nn\n20000\n5350\n14650\n\n\n\n\nVital_A (mean (SD))\n85.40 (15.23)\n80.14 (14.64)\n87.33 (14.99)\n<0.001\n\n\n\nVital_B (mean (SD))\n119.13 (16.72)\n123.03 (16.45)\n117.70 (16.59)\n<0.001\n\n\n\nVital_C (mean (SD))\n61.15 (10.81)\n64.47 (10.54)\n59.94 (10.66)\n<0.001\n\n\n\nVital_D (mean (SD))\n78.41 (11.14)\n81.41 (10.87)\n77.31 (11.04)\n<0.001\n\n\n\nVital_E (mean (SD))\n18.57 (3.92)\n16.46 (3.64)\n19.35 (3.74)\n<0.001\n\n\n\nVital_F (mean (SD))\n36.84 (0.59)\n36.88 (0.59)\n36.82 (0.59)\n<0.001\n\n\n\nVital_G (mean (SD))\n97.17 (1.98)\n97.49 (1.92)\n97.05 (1.99)\n<0.001\n\n\n\nLab_A (mean (SD))\n138.24 (41.69)\n129.87 (41.42)\n141.29 (41.36)\n<0.001\n\n\n\nLab_B (mean (SD))\n14.12 (3.44)\n12.40 (3.25)\n14.75 (3.29)\n<0.001\n\n\n\nLab_C (mean (SD))\n24.04 (4.34)\n25.25 (4.22)\n23.60 (4.29)\n<0.001\n\n\n\nLab_D (mean (SD))\n1.55 (1.30)\n1.30 (1.22)\n1.64 (1.32)\n<0.001\n\n\n\nLab_E (mean (SD))\n104.56 (5.54)\n105.11 (5.59)\n104.36 (5.50)\n<0.001\n\n\n\nLab_F (mean (SD))\n32.80 (5.53)\n34.05 (5.43)\n32.34 (5.50)\n<0.001\n\n\n\nLab_G (mean (SD))\n11.04 (1.97)\n11.62 (1.93)\n10.83 (1.95)\n<0.001\n\n\n\nLab_H (mean (SD))\n2.09 (1.14)\n1.52 (1.00)\n2.30 (1.12)\n<0.001\n\n\n\nLab_I (mean (SD))\n229.36 (113.73)\n244.73 (114.08)\n223.74 (113.08)\n<0.001\n\n\n\nLab_J (mean (SD))\n4.23 (0.62)\n4.19 (0.62)\n4.24 (0.61)\n<0.001\n\n\n\nLab_K (mean (SD))\n25.92 (18.29)\n16.56 (15.10)\n29.34 (18.17)\n<0.001\n\n\n\nLab_L (mean (SD))\n138.27 (4.25)\n138.40 (4.29)\n138.22 (4.23)\n0.008\n\n\n\nLab_M (mean (SD))\n12.28 (8.27)\n10.27 (7.79)\n13.01 (8.32)\n<0.001\n\n\n\nAge (mean (SD))\n62.46 (16.29)\n54.06 (15.27)\n65.53 (15.56)\n<0.001\n\n\n\nlabel_status = TRUE (%)\n14650 (73.2)\n0 (0.0)\n14650 (100.0)\n<0.001\n\n\n\nlabel_time (mean (SD))\n70.03 (19.27)\n91.00 (0.00)\n62.37 (16.97)\n<0.001\n\n\n\n\n\n\n\nPerform univariable analysis and generate the result table with (unadjusted) hazard ratios.\n\n\nuni_table_survival <- compute_uni_variable_table_survival(sample_data_survival)\nkable(uni_table_survival)\n\n\n\n\n\nOR\np value\n\n\n\n\nVital_A\n1.021(1.02-1.022)\n<0.001\n\n\nVital_B\n0.988(0.987-0.989)\n<0.001\n\n\nVital_C\n0.976(0.974-0.977)\n<0.001\n\n\nVital_D\n0.979(0.978-0.98)\n<0.001\n\n\nVital_E\n1.139(1.134-1.144)\n<0.001\n\n\nVital_F\n0.904(0.879-0.929)\n<0.001\n\n\nVital_G\n0.932(0.924-0.939)\n<0.001\n\n\nLab_A\n1.004(1.004-1.005)\n<0.001\n\n\nLab_B\n1.145(1.139-1.15)\n<0.001\n\n\nLab_C\n0.945(0.942-0.949)\n<0.001\n\n\nLab_D\n1.136(1.122-1.15)\n<0.001\n\n\nLab_E\n0.984(0.981-0.987)\n<0.001\n\n\nLab_F\n0.964(0.961-0.967)\n<0.001\n\n\nLab_G\n0.876(0.868-0.883)\n<0.001\n\n\nLab_H\n1.518(1.496-1.541)\n<0.001\n\n\nLab_I\n0.999(0.999-0.999)\n<0.001\n\n\nLab_J\n1.088(1.059-1.117)\n<0.001\n\n\nLab_K\n1.027(1.026-1.028)\n<0.001\n\n\nLab_L\n0.993(0.989-0.997)\n<0.001\n\n\nLab_M\n1.027(1.025-1.029)\n<0.001\n\n\nAge\n1.03(1.029-1.031)\n<0.001\n\n\n\n\n\n\nPerform multivariable analysis and generate the result table with adjusted hazard ratios.\n\n\nmulti_table_survival <- compute_multi_variable_table_survival(sample_data_survival)\nkable(multi_table_survival)\n\n\n\n\n\nadjusted_OR\np value\n\n\n\n\nVital_A\n1.031(1.03-1.032)\n<0.001\n\n\nVital_B\n0.975(0.973-0.977)\n<0.001\n\n\nVital_C\n0.955(0.951-0.959)\n<0.001\n\n\nVital_D\n1.053(1.048-1.058)\n<0.001\n\n\nVital_E\n1.155(1.149-1.16)\n<0.001\n\n\nVital_F\n0.84(0.815-0.866)\n<0.001\n\n\nVital_G\n0.99(0.981-0.999)\n0.022\n\n\nLab_A\n1.001(1-1.001)\n<0.001\n\n\nLab_B\n1.115(1.103-1.127)\n<0.001\n\n\nLab_C\n0.952(0.943-0.962)\n<0.001\n\n\nLab_D\n0.778(0.765-0.792)\n<0.001\n\n\nLab_E\n0.934(0.925-0.943)\n<0.001\n\n\nLab_F\n1.143(1.131-1.155)\n<0.001\n\n\nLab_G\n0.603(0.586-0.621)\n<0.001\n\n\nLab_H\n1.614(1.588-1.64)\n<0.001\n\n\nLab_I\n0.997(0.997-0.997)\n<0.001\n\n\nLab_J\n0.737(0.715-0.76)\n<0.001\n\n\nLab_K\n1.032(1.031-1.034)\n<0.001\n\n\nLab_L\n1.034(1.024-1.044)\n<0.001\n\n\nLab_M\n1.03(1.028-1.032)\n<0.001\n\n\nAge\n1.046(1.045-1.047)\n<0.001"
  },
  {
    "objectID": "02-desc_analysis.html#ordinal",
    "href": "02-desc_analysis.html#ordinal",
    "title": "3  Descriptive analysis",
    "section": "3.3 Ordinal outcome",
    "text": "3.3 Ordinal outcome\n\nCompute descriptive table (usually Table 1 in medical literature) for the dataset.\n\n\ndata(\"sample_data_ordinal\")\ncompute_descriptive_table(sample_data_ordinal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall\n1\n2\n3\np\ntest\n\n\n\n\nn\n20000\n16360\n2449\n1191\n\n\n\n\nlabel (%)\n\n\n\n\n<0.001\n\n\n\n1\n16360 (81.8)\n16360 (100.0)\n0 ( 0.0)\n0 ( 0.0)\n\n\n\n\n2\n2449 (12.2)\n0 ( 0.0)\n2449 (100.0)\n0 ( 0.0)\n\n\n\n\n3\n1191 ( 6.0)\n0 ( 0.0)\n0 ( 0.0)\n1191 (100.0)\n\n\n\n\nAge (mean (SD))\n61.68 (18.19)\n60.64 (18.37)\n65.37 (16.64)\n68.32 (16.18)\n<0.001\n\n\n\nGender = MALE (%)\n9863 (49.3)\n8109 ( 49.6)\n1173 ( 47.9)\n581 ( 48.8)\n0.284\n\n\n\nUtil_A (%)\n\n\n\n\n0.626\n\n\n\nP1\n3750 (18.8)\n3082 ( 18.8)\n437 ( 17.8)\n231 ( 19.4)\n\n\n\n\nP2\n11307 (56.5)\n9218 ( 56.3)\n1413 ( 57.7)\n676 ( 56.8)\n\n\n\n\nP3 and P4\n4943 (24.7)\n4060 ( 24.8)\n599 ( 24.5)\n284 ( 23.8)\n\n\n\n\nUtil_B (mean (SD))\n0.93 (2.20)\n0.78 (1.98)\n1.40 (2.73)\n1.96 (3.18)\n<0.001\n\n\n\nUtil_C (mean (SD))\n3.54 (8.73)\n3.55 (8.77)\n3.38 (7.83)\n3.60 (9.90)\n0.632\n\n\n\nUtil_D (mean (SD))\n2.76 (1.70)\n2.80 (1.71)\n2.66 (1.69)\n2.49 (1.63)\n<0.001\n\n\n\nComorb_A = 1 (%)\n1555 ( 7.8)\n888 ( 5.4)\n348 ( 14.2)\n319 ( 26.8)\n<0.001\n\n\n\nComorb_B = 1 (%)\n2599 (13.0)\n2094 ( 12.8)\n336 ( 13.7)\n169 ( 14.2)\n0.202\n\n\n\nComorb_C = 1 (%)\n526 ( 2.6)\n414 ( 2.5)\n70 ( 2.9)\n42 ( 3.5)\n0.088\n\n\n\nComorb_D = 1 (%)\n1887 ( 9.4)\n1538 ( 9.4)\n242 ( 9.9)\n107 ( 9.0)\n0.645\n\n\n\nComorb_E = 1 (%)\n310 ( 1.6)\n253 ( 1.5)\n43 ( 1.8)\n14 ( 1.2)\n0.411\n\n\n\nLab_A (mean (SD))\n146.85 (199.74)\n143.75 (198.13)\n153.25 (196.98)\n176.29 (223.44)\n<0.001\n\n\n\nLab_B (mean (SD))\n4.15 (0.68)\n4.15 (0.68)\n4.17 (0.69)\n4.14 (0.66)\n0.326\n\n\n\nLab_C (mean (SD))\n135.15 (4.81)\n135.16 (4.81)\n135.06 (4.92)\n135.18 (4.47)\n0.607\n\n\n\nVital_A (mean (SD))\n82.67 (17.10)\n82.11 (16.78)\n84.45 (18.40)\n86.65 (17.92)\n<0.001\n\n\n\nVital_B (mean (SD))\n17.86 (1.82)\n17.86 (1.81)\n17.86 (1.88)\n17.86 (1.84)\n0.995\n\n\n\nVital_C (mean (SD))\n97.96 (3.26)\n97.97 (3.06)\n97.92 (4.07)\n97.93 (3.91)\n0.741\n\n\n\nVital_D (mean (SD))\n71.23 (13.51)\n71.21 (13.48)\n71.35 (13.70)\n71.30 (13.49)\n0.877\n\n\n\nVital_E (mean (SD))\n133.47 (25.27)\n134.13 (25.15)\n130.87 (25.45)\n129.74 (25.91)\n<0.001\n\n\n\nVital_F (mean (SD))\n22.82 (3.53)\n22.86 (3.46)\n22.73 (3.76)\n22.36 (3.94)\n<0.001\n\n\n\n\n\n\n\nPerform univariable analysis and generate the result table.\nBy default the (unadjusted) odds ratio from the commonly used proportional odds models are reported for link = \"logit\". If other link functions are selected (i.e., \"cloglog\" link corresponding to the proportional hazards model, or the \"probit\" link), the exponentiated coefficients are reported.\n\n\n\n\n\n\n\nImportant\n\n\n\nUse the same link parameter throughout descriptive analysis and model building steps.\n\n\n\nlink <- \"logit\"\nuni_table_ordinal <- compute_uni_variable_table_ordinal(sample_data_ordinal, link = link)\nkable(uni_table_ordinal)\n\n\n\n\n\nOR\np value\n\n\n\n\nAge\n1.019 (1.017 - 1.021)\n<0.001\n\n\nGenderMALE\n0.948 (0.883 - 1.019)\n0.147\n\n\nUtil_AP2\n1.040 (0.946 - 1.145)\n0.421\n\n\nUtil_AP3 and P4\n0.998 (0.894 - 1.115)\n0.974\n\n\nUtil_B\n1.136 (1.121 - 1.153)\n<0.001\n\n\nUtil_C\n0.999 (0.994 - 1.003)\n0.564\n\n\nUtil_D\n0.929 (0.908 - 0.950)\n<0.001\n\n\nComorb_A1\n4.154 (3.737 - 4.616)\n<0.001\n\n\nComorb_B1\n1.099 (0.989 - 1.218)\n0.076\n\n\nComorb_C1\n1.236 (0.997 - 1.520)\n0.049\n\n\nComorb_D1\n1.017 (0.899 - 1.147)\n0.791\n\n\nComorb_E1\n0.994 (0.739 - 1.315)\n0.969\n\n\nLab_A\n1.000 (1.000 - 1.001)\n<0.001\n\n\nLab_B\n1.010 (0.958 - 1.064)\n0.717\n\n\nLab_C\n0.998 (0.990 - 1.005)\n0.534\n\n\nVital_A\n1.010 (1.008 - 1.012)\n<0.001\n\n\nVital_B\n0.999 (0.980 - 1.019)\n0.956\n\n\nVital_C\n0.996 (0.986 - 1.007)\n0.451\n\n\nVital_D\n1.001 (0.998 - 1.003)\n0.622\n\n\nVital_E\n0.994 (0.993 - 0.996)\n<0.001\n\n\nVital_F\n0.979 (0.969 - 0.989)\n<0.001\n\n\n\n\n\n\nPerform multivariable analysis and generate the result table, with adjusted odd ratios from a proportional odds model by default.\n\n\nmulti_table_ordinal <- compute_multi_variable_table_ordinal(sample_data_ordinal, link = link)\nkable(multi_table_ordinal)\n\n\n\n\n\nadjusted_OR\np value\n\n\n\n\nAge\n1.020 (1.018 - 1.023)\n<0.001\n\n\nGenderMALE\n0.944 (0.876 - 1.017)\n0.128\n\n\nUtil_AP2\n1.020 (0.924 - 1.127)\n0.695\n\n\nUtil_AP3 and P4\n0.970 (0.865 - 1.088)\n0.603\n\n\nUtil_B\n1.144 (1.127 - 1.160)\n<0.001\n\n\nUtil_C\n0.998 (0.994 - 1.002)\n0.390\n\n\nUtil_D\n0.924 (0.902 - 0.945)\n<0.001\n\n\nComorb_A1\n4.497 (4.034 - 5.011)\n<0.001\n\n\nComorb_B1\n1.057 (0.948 - 1.177)\n0.317\n\n\nComorb_C1\n1.287 (1.032 - 1.593)\n0.023\n\n\nComorb_D1\n1.039 (0.915 - 1.177)\n0.552\n\n\nComorb_E1\n0.963 (0.706 - 1.291)\n0.808\n\n\nLab_A\n1.000 (1.000 - 1.001)\n<0.001\n\n\nLab_B\n1.007 (0.953 - 1.063)\n0.808\n\n\nLab_C\n0.995 (0.988 - 1.003)\n0.234\n\n\nVital_A\n1.011 (1.009 - 1.013)\n<0.001\n\n\nVital_B\n1.004 (0.984 - 1.024)\n0.708\n\n\nVital_C\n0.995 (0.985 - 1.007)\n0.388\n\n\nVital_D\n1.001 (0.998 - 1.003)\n0.654\n\n\nVital_E\n0.993 (0.992 - 0.995)\n<0.001\n\n\nVital_F\n0.978 (0.968 - 0.988)\n<0.001"
  },
  {
    "objectID": "04-autoscore.html",
    "href": "04-autoscore.html",
    "title": "4  AutoScore for binary outcomes",
    "section": "",
    "text": "AutoScore on binary outcomes is the original form of the AutoScore, implemented by five functions: AutoScore_rank(), AutoScore_Ordinal(), AutoScore_weighting(), AutoScore_fine_tuning() and AutoScore_testing().\nIn this chapter, we demonstrate the use of AutoScore to develop sparse risk scores for binary outcome, adjust parameters to improve interpretability, assess the performance of the final model and map the score to predict risks for new data. To facilitate clinical applications, in the following sections we have three demos for AutoScore Implementation with large and small dataset, as well as with missing data.\nCitation for original AutoScore:"
  },
  {
    "objectID": "04-autoscore.html#demo-1-large-sample",
    "href": "04-autoscore.html#demo-1-large-sample",
    "title": "4  AutoScore for binary outcomes",
    "section": "4.1 Demo 1: large sample",
    "text": "4.1 Demo 1: large sample\nIn Demo 1, we demonstrate the use of AutoScore on a dataset with 20,000 observations using split-sample approach (i.e., to randomly divide the full dataset into training, validation and test sets) for model development.\n\n\n\n\n\n\nImportant\n\n\n\n\nBefore proceeding, follow the steps in Chapter 2 to ensure all data requirements are met.\nRefer to Chapter 3 for how to generate simple descriptive statistics before building prediction models.\n\n\n\n\nLoad package and data\n\n\nlibrary(AutoScore)\ndata(\"sample_data\")\nnames(sample_data)[names(sample_data) == \"Mortality_inpatient\"] <- \"label\"\ncheck_data(sample_data)\n\nData type check passed. \n\n\nNo NA in data \n\n\n\nPrepare training, validation, and test datasets\n\n\nOption 1: Prepare three separate datasets to train, validate, and test models.\nOption 2: Use demo codes below to randomly split your dataset into training, validation, and test datasets (70%, 10%, 20%, respectively).\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n4.1.1 STEP(i): generate variable ranking list\n\nAutoScore Module 1\n\n\nmethod: \"rf\" (default) or \"auc\".\n\n\nrfauc\n\n\n\nmethod = rf: random forest-based ranking.\n\nntree: Number of trees required only when method = \"rf\" (Default: 100).\n\n\nranking <- AutoScore_rank(train_set = train_set, method = \"rf\", ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n      Age     Lab_H     Lab_K     Lab_B   Vital_E   Vital_A     Lab_I     Lab_A \n152.24380 151.60648 147.96133 134.85962 130.84508 128.05477 106.01727  96.68171 \n  Vital_C   Vital_B     Lab_M     Lab_J   Vital_D     Lab_D   Vital_F     Lab_E \n 94.91108  94.41436  92.31222  84.42058  83.63048  80.23488  77.07122  75.73559 \n    Lab_C     Lab_F     Lab_L     Lab_G   Vital_G \n 75.48998  75.08788  72.61001  56.33592  56.08578 \n\n\n\n\n\n\n\n\n\n\n\nmethod = auc: AUC-based ranking. Univariable models will be built based on the train set, and variables are ranked based on the AUC performance of corresponding univariable models on the validation set (validation_set).\n\nvalidation_set: validation set required only when method = \"auc\".\n\n\nranking <- AutoScore_rank(train_set = train_set, method = \"auc\", \n                          validation_set = validation_set)\n\nThe auc-based ranking based on variable importance was shown below for each variable: \n    Lab_H       Age     Lab_B     Lab_K   Vital_E   Vital_A     Lab_M     Lab_C \n0.7016120 0.6926165 0.6796975 0.6741446 0.6708401 0.6319503 0.6010980 0.6010525 \n    Lab_G   Vital_C   Vital_D     Lab_F     Lab_L     Lab_A   Vital_F   Vital_G \n0.5777848 0.5743282 0.5617414 0.5606434 0.5427415 0.5392167 0.5380191 0.5345188 \n  Vital_B     Lab_D     Lab_I     Lab_E     Lab_J \n0.5326130 0.5186835 0.5139225 0.4888609 0.4845179 \n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 STEP(ii): select variables with parsimony plot\n\nAutoScore Modules 2+3+4\n\n\nn_min: Minimum number of selected variables (Default: 1).\nn_max: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\n\n\nAUC <- AutoScore_parsimony(\n  train_set = train_set, validation_set = validation_set,\n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\"\n)\n\nSelect 1 Variable(s):  Area under the curve: 0.6649\nSelect 2 Variable(s):  Area under the curve: 0.7466\nSelect 3 Variable(s):  Area under the curve: 0.7729\nSelect 4 Variable(s):  Area under the curve: 0.7915\nSelect 5 Variable(s):  Area under the curve: 0.8138\nSelect 6 Variable(s):  Area under the curve: 0.8268\nSelect 7 Variable(s):  Area under the curve: 0.822\nSelect 8 Variable(s):  Area under the curve: 0.8196\nSelect 9 Variable(s):  Area under the curve: 0.8188\nSelect 10 Variable(s):  Area under the curve: 0.8184\nSelect 11 Variable(s):  Area under the curve: 0.8178\nSelect 12 Variable(s):  Area under the curve: 0.8238\nSelect 13 Variable(s):  Area under the curve: 0.8224\nSelect 14 Variable(s):  Area under the curve: 0.8256\nSelect 15 Variable(s):  Area under the curve: 0.8301\nSelect 16 Variable(s):  Area under the curve: 0.8278\nSelect 17 Variable(s):  Area under the curve: 0.8269\nSelect 18 Variable(s):  Area under the curve: 0.8273\nSelect 19 Variable(s):  Area under the curve: 0.8244\nSelect 20 Variable(s):  Area under the curve: 0.8259\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use AUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(AUC), file = \"AUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 6 variables are selected\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 9 variables are selected\nnum_var <- 9\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 6 variables, the 9th and 10th variable are selected\nnum_var <- 6\nfinal_variables <- names(ranking[c(1:num_var, 9, 10)])\n\n\n\n4.1.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\n\n\ncut_vec <- AutoScore_weighting( \n  train_set = train_set, validation_set = validation_set,\n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)\n)\n\n****Included Variables: \n  variable_name\n1           Age\n2         Lab_H\n3         Lab_K\n4         Lab_B\n5       Vital_E\n6       Vital_A\n****Initial Scores: \n\n\n========  ==========  =====\nvariable  interval    point\n========  ==========  =====\nAge       <35           0  \n          [35,49)       7  \n          [49,76)      17  \n          [76,89)      23  \n          >=89         27  \n                           \nLab_H     <0.2          0  \n          [0.2,1.1)     4  \n          [1.1,3.1)     9  \n          [3.1,4)      15  \n          >=4          18  \n                           \nLab_K     <8            0  \n          [8,42)        6  \n          [42,58)      11  \n          >=58         14  \n                           \nLab_B     <8.5          0  \n          [8.5,11.2)    4  \n          [11.2,17)     7  \n          [17,19.8)    10  \n          >=19.8       12  \n                           \nVital_E   <12           0  \n          [12,15)       2  \n          [15,22)       7  \n          [22,25)      12  \n          >=25         15  \n                           \nVital_A   <60           0  \n          [60,73)       1  \n          [73,98)       6  \n          [98,111)     10  \n          >=111        13  \n========  ==========  =====\n\n\n\n\n\n***Performance (based on validation set):\nAUC:  0.8268   95% CI: 0.7953-0.8583 (DeLong)\nBest score threshold: >= 57 \nOther performance indicators based on this score threshold: \nSensitivity: 0.8065\nSpecificity: 0.6775\nPPV:         0.1736\nNPV:         0.9766\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n4.1.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore Module 5 & Re-run AutoScore Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore Module 5).\nRe-run AutoScore Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\n\n\n## For example, we have current cutoffs of continuous variable: Age \n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n## Age             <35            0  \n##                 [35,49)        7  \n##                 [49,76)       17  \n##                 [76,89)       23  \n##                 >=89          27  \n\n\nCurrent cutoffs: c(35, 49, 76, 89). We can fine tune the cutoffs as follows:\n\n\n# Example 1: rounding up to a nice number\ncut_vec$Age <- c(35, 50, 75, 90)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Age <- c(25, 50, 75, 90)\n\n# Example 3: combining categories\ncut_vec$Age <- c(50, 75, 90)\n\n\nThen we do similar checks for other variables and update scoring table using new cutoffs if needed.\n\n\ncut_vec$Lab_H <- c(0.2, 1, 3, 4)\ncut_vec$Lab_K <- c(10, 40)\ncut_vec$Lab_B <- c(10, 17)\ncut_vec$Vital_A <- c(70, 98)\n\nscoring_table <- AutoScore_fine_tuning(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, cut_vec = cut_vec, max_score = 100\n)\n\n***Fine-tuned Scores: \n\n\n========  ========  =====\nvariable  interval  point\n========  ========  =====\nAge       <50         0  \n          [50,75)    12  \n          [75,90)    19  \n          >=90       24  \n                         \nLab_H     <0.2        0  \n          [0.2,1)     6  \n          [1,3)      11  \n          [3,4)      18  \n          >=4        22  \n                         \nLab_K     <10         0  \n          [10,40)     8  \n          >=40       15  \n                         \nLab_B     <10         0  \n          [10,17)     3  \n          >=17        8  \n                         \nVital_E   <12         0  \n          [12,15)     1  \n          [15,22)     8  \n          [22,25)    15  \n          >=25       18  \n                         \nVital_A   <70         0  \n          [70,98)     7  \n          >=98       13  \n========  ========  =====\n\n\n\n\n\n***Performance (based on validation set, after fine-tuning):\nAUC:  0.8188   95% CI: 0.7862-0.8515 (DeLong)\nBest score threshold: >= 55 \nOther performance indicators based on this score threshold: \nSensitivity: 0.8452\nSpecificity: 0.6336\nPPV:         0.1623\nNPV:         0.9799\n\n\n\n\n4.1.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore Module 6\n\n\nthreshold: Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to \"best\", the optimal threshold will be calculated (Default: \"best\").\nwith_label: Set to TRUE if there are labels in the test_set and performance will be evaluated accordingly (Default: TRUE).\nSet the with_label to FALSE if there are not label in the test_set and the final predicted scores will be the output without performance evaluation.\n\n\npred_score <- AutoScore_testing(\n  test_set = test_set, final_variables = final_variables, cut_vec = cut_vec,\n  scoring_table = scoring_table, threshold = \"best\", with_label = TRUE\n)\n\n\n\n\n***Performance using AutoScore:\nAUC:  0.8337   95% CI: 0.8125-0.8548 (DeLong)\nBest score threshold: >= 59 \nOther performance indicators based on this score threshold: \nSensitivity: 0.7524 95% CI: 0.7003-0.8013\nSpecificity: 0.7652 95% CI: 0.7525-0.7788\nPPV:         0.2106 95% CI: 0.1957-0.2249\nNPV:         0.9739 95% CI: 0.9686-0.9789\n\nhead(pred_score)\n\n  pred_score Label\n1         19 FALSE\n2         41 FALSE\n3         74  TRUE\n4         37 FALSE\n5         49 FALSE\n6         34 FALSE\n\n\n\nUse print_roc_performance() to generate the performance under different score thresholds (e.g., 50).\n\n\nprint_roc_performance(pred_score$Label, pred_score$pred_score, threshold = 50)\n\nAUC:  0.8337   95% CI: 0.8125-0.8548 (DeLong)\nScore threshold: >= 50 \nOther performance indicators based on this score threshold: \nSensitivity: 0.9055\nSpecificity: 0.5532\nPPV:         0.1442\nNPV:         0.986\n\n\n\n\n4.1.6 Map score to risk\nFurther analysis to map score to risk (e.g., conversion table, model calibration, output the score).\n\nConversion table can be generated for pre-specified risk or score cut-offs.\n\n\nBy riskBy score\n\n\n\nUse conversion_table() to generate the performance under different risk (i.e., probability of mortality based on logistic regression estimation) cut-off (e.g., 0.01, 0.05, 0.1, 0.2, 0.5).\n\n\nconversion_table(pred_score = pred_score, \n                 by = \"risk\", values = c(0.01, 0.05, 0.1, 0.2, 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted Risk [>=]\nScore cut-off [>=]\nPercentage of patients (%)\nAccuracy (95% CI)\nSensitivity (95% CI)\nSpecificity (95% CI)\nPPV (95% CI)\nNPV (95% CI)\n\n\n\n\n1%\n38\n82\n25.8% (24.5-27.1%)\n99% (97.7-100%)\n19.7% (18.4-21.1%)\n9.3% (9.1-9.5%)\n99.6% (99-100%)\n\n\n5%\n54\n42\n63.6% (62-64.9%)\n87% (83.1-90.6%)\n61.6% (60-63.1%)\n15.9% (15.1-16.6%)\n98.3% (97.8-98.7%)\n\n\n10%\n61\n25\n78.2% (77-79.4%)\n72% (67.1-76.5%)\n78.7% (77.4-80%)\n21.9% (20.4-23.6%)\n97.1% (96.7-97.6%)\n\n\n20%\n68\n11\n88% (87.1-88.9%)\n45% (39.1-50.5%)\n91.6% (90.7-92.4%)\n30.8% (27.4-34.3%)\n95.2% (94.8-95.7%)\n\n\n50%\n81\n1\n92.5% (92.2-92.9%)\n11.1% (7.8-14.7%)\n99.4% (99-99.6%)\n58% (45.6-70.6%)\n93.1% (92.8-93.3%)\n\n\n\n\n\n\n\n\nUse conversion_table() to generate the performance under different score thresholds (e.g., 20, 40, 60, 75).\n\n\nconversion_table(pred_score = pred_score, \n                 by = \"score\", values = c(20,40,60,75))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScore cut-off [>=]\nPredicted Risk [>=]\nPercentage of patients (%)\nAccuracy (95% CI)\nSensitivity (95% CI)\nSpecificity (95% CI)\nPPV (95% CI)\nNPV (95% CI)\n\n\n\n\n20\n0.1%\n99\n8.6% (8.3-8.9%)\n100% (100-100%)\n1% (0.7-1.4%)\n7.7% (7.7-7.8%)\n100% (100-100%)\n\n\n40\n1.2%\n79\n28.7% (27.4-30%)\n99% (97.7-100%)\n22.8% (21.5-24.2%)\n9.6% (9.5-9.8%)\n99.7% (99.2-100%)\n\n\n60\n9.7%\n26\n77.2% (75.9-78.5%)\n73.6% (68.7-78.2%)\n77.5% (76.1-78.8%)\n21.4% (19.9-22.9%)\n97.3% (96.7-97.7%)\n\n\n75\n34.8%\n4\n91.8% (91.2-92.3%)\n21.8% (17.3-26.7%)\n97.6% (97.1-98.1%)\n43.1% (35.8-50%)\n93.8% (93.4-94.1%)\n\n\n\n\n\n\n\n\n\nPredicted risk can also be visualized using an interactive figure.\n\n\nplot_predicted_risk(pred_score = pred_score, max_score = 100, \n                    final_variables = final_variables, \n                    scoring_table = scoring_table, point_size = 1)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use pred_score for further analysis or export it to CSV to other software (e.g., generating the calibration curve).\n\n\nwrite.csv(pred_score, file = \"pred_score.csv\")"
  },
  {
    "objectID": "04-autoscore.html#demo2",
    "href": "04-autoscore.html#demo2",
    "title": "4  AutoScore for binary outcomes",
    "section": "4.2 Demo 2: small sample",
    "text": "4.2 Demo 2: small sample\nIn Demo 2, we demonstrate the use of AutoScore on a smaller dataset where there are no sufficient samples to form a separate training and validation dataset. Thus, the cross validation is employed to generate the parsimony plot.\n\nLoad small dataset with 1000 samples\n\n\ndata(\"sample_data_small\")\n\n\nPrepare training and test datasets\n\n\nOption 1: Prepare two separate datasets to train and test models.\nOption 2: Use demo codes below to randomly split your dataset into training and test datasets (70% and 30%, respectively). For cross-validation, train_set is equal to validation_set and the ratio of validation_set should be 0. Then cross-validation will be implemented in the STEP(ii) AutoScore_parsimony().\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_small, ratio = c(0.7, 0, 0.3), \n                        cross_validation = TRUE)\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n4.2.1 STEP(i): generate variable ranking list\n\nAutoScore Module 1\n\n\nmethod: \"rf\" (default) or \"auc\".\n\n\nrfauc\n\n\n\nmethod = rf: random forest-based ranking.\n\nntree: Number of trees required only when method = \"rf\" (Default: 100).\n\n\nranking <- AutoScore_rank(train_set = train_set, method = \"rf\", ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n      Age     Lab_B     Lab_H   Vital_E     Lab_K   Vital_A     Lab_I     Lab_J \n37.406648 31.315285 25.564054 21.855069 20.907522 20.645694 16.788696 16.094679 \n  Vital_B     Lab_A     Lab_M   Vital_C   Vital_F     Lab_D     Lab_C     Lab_E \n15.574365 14.651987 14.297510 13.765633 12.932043 12.679113 12.295000 12.165724 \n    Lab_F   Vital_D     Lab_L     Lab_G   Vital_G \n11.649415 11.431833 10.108408  9.297786  7.680821 \n\n\n\n\n\n\n\n\n\n\n\nmethod = auc: AUC-based ranking. Univariable models will be built based on the train set, and variables are ranked based on the AUC performance of corresponding univariable models on the validation set (validation_set).\n\nvalidation_set: validation set required only when method = \"auc\".\n\n\nranking <- AutoScore_rank(train_set = train_set, method = \"auc\", \n                          validation_set = validation_set)\n\nThe auc-based ranking based on variable importance was shown below for each variable: \n    Lab_B       Age   Vital_E     Lab_H     Lab_K     Lab_C   Vital_A     Lab_G \n0.6668343 0.6619857 0.6522559 0.6469780 0.6347585 0.6064601 0.5986108 0.5678392 \n    Lab_A     Lab_M     Lab_F   Vital_C   Vital_D     Lab_D   Vital_B     Lab_I \n0.5672668 0.5614125 0.5613635 0.5613553 0.5500025 0.5469036 0.5395408 0.5288666 \n  Vital_F   Vital_G     Lab_L     Lab_E     Lab_J \n0.5207802 0.5175751 0.5124730 0.5098729 0.5059606 \n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.2 STEP(ii): select variables with parsimony plot\n\nAutoScore Modules 2+3+4\n\n\nn_min: Minimum number of selected variables (Default: 1).\nn_max: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\ncross_validation: TRUE if cross-validation is needed, especially for small datasets.\nfold: The number of folds used in cross validation (Default: 10). Available if cross_validation = TRUE.\ndo_trace: If set to TRUE, all results based on each fold of cross-validation would be printed out and plotted (Default: FALSE). Available if cross_validation = TRUE.\n\n\nAUC <- AutoScore_parsimony(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.25, 0.5, 0.75, 1), \n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\",\n  cross_validation = TRUE, fold = 10, do_trace = FALSE\n)\n\n***list of final mean AUC values through cross-validation are shown below \n   auc_set.sum\n1    0.6332124\n2    0.7254603\n3    0.7381319\n4    0.7623322\n5    0.7695922\n6    0.7735329\n7    0.7728111\n8    0.7700531\n9    0.7665829\n10   0.7634048\n11   0.7651904\n12   0.7617113\n13   0.7571203\n14   0.7694130\n15   0.7650977\n16   0.7572382\n17   0.7603713\n18   0.7650728\n19   0.7656964\n20   0.7645128\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use AUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(AUC), file = \"AUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 6 variables are selected\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 9 variables are selected\nnum_var <- 9\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 6 variables, the 9th and 10th variable are selected\nnum_var <- 6\nfinal_variables <- names(ranking[c(1:num_var, 9, 10)])\n\n\n\n4.2.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\n\n\ncut_vec <- AutoScore_weighting( \n  train_set = train_set, validation_set = validation_set,\n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.25, 0.5, 0.75, 1)\n)\n\n****Included Variables: \n  variable_name\n1           Age\n2         Lab_B\n3         Lab_H\n4       Vital_E\n5         Lab_K\n****Initial Scores: \n\n\n========  ===========  =====\nvariable  interval     point\n========  ===========  =====\nAge       <52            0  \n          [52,62)       15  \n          [62,73)       21  \n          >=73          30  \n                            \nLab_B     <11.9          0  \n          [11.9,14.3)    9  \n          [14.3,16.7)   15  \n          >=16.7        21  \n                            \nLab_H     <1.2           0  \n          [1.2,2.1)     15  \n          [2.1,2.82)    13  \n          >=2.82        19  \n                            \nVital_E   <16            0  \n          [16,19)        4  \n          [19,21)        9  \n          >=21          19  \n                            \nLab_K     <13            2  \n          [13,26)        0  \n          [26,40)        4  \n          >=40          11  \n========  ===========  =====\n\n\n\n\n\n***Performance (based on validation set):\nAUC:  0.781   95% CI: 0.7473-0.8148 (DeLong)\nBest score threshold: >= 58 \nOther performance indicators based on this score threshold: \nSensitivity: 0.6291\nSpecificity: 0.7976\nPPV:         0.771\nNPV:         0.665\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n4.2.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore Module 5 & Re-run AutoScore Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore Module 5).\nRe-run AutoScore Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\n\n\n## For example, we have current cutoffs of continuous variable:\n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n#> Lab_K           <9             0  \n#>                [9,43.2)       1  \n#>                [43.2,59)      9  \n#>                >=59          13  \n\n\nCurrent cutoffs: c(9, 43.2, 59). We can fine tune the cutoffs as follows:\nNote: It is just a demo using simulated data, and thus, the result might not be clinically meaningful.\n\n\n# Example 1: rounding up to a nice number\ncut_vec$Lab_K <- c(9, 45, 60)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Lab_K <- c(15, 45, 60)\n\n# Example 3: combining categories\ncut_vec$Lab_K <- c(45, 60)\n\n\nThen we do similar checks for other variables and update scoring table using new cutoffs if needed.\n\n\ncut_vec$Lab_H <- c(1, 2, 3)\ncut_vec$Age <- c(35, 50, 80)\ncut_vec$Lab_B <- c(8, 12, 18)\ncut_vec$Vital_E <- c(15, 22)\n\nscoring_table <- AutoScore_fine_tuning(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, cut_vec = cut_vec, max_score = 100\n)\n\n***Fine-tuned Scores: \n\n\n========  ========  =====\nvariable  interval  point\n========  ========  =====\nAge       <35         0  \n          [35,50)     2  \n          [50,80)    18  \n          >=80       23  \n                         \nLab_B     <8          0  \n          [8,12)      8  \n          [12,18)    15  \n          >=18       22  \n                         \nLab_H     <1          0  \n          [1,2)      12  \n          [2,3)      13  \n          >=3        18  \n                         \nVital_E   <15         0  \n          [15,22)    10  \n          >=22       20  \n                         \nLab_K     <45         0  \n          [45,60)    10  \n          >=60       17  \n========  ========  =====\n\n\n\n\n\n***Performance (based on validation set, after fine-tuning):\nAUC:  0.7623   95% CI: 0.7275-0.7971 (DeLong)\nBest score threshold: >= 60 \nOther performance indicators based on this score threshold: \nSensitivity: 0.5714\nSpecificity: 0.8214\nPPV:         0.7761\nNPV:         0.6389\n\n\n\n\n4.2.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore Module 6\n\n\nthreshold: Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to \"best\", the optimal threshold will be calculated (Default: \"best\").\nwith_label: Set to TRUE if there are labels in the test_set and performance will be evaluated accordingly (Default: TRUE).\nSet the with_label to FALSE if there are not label in the test_set and the final predicted scores will be the output without performance evaluation.\n\n\npred_score <- AutoScore_testing(\n  test_set = test_set, final_variables = final_variables, cut_vec = cut_vec,\n  scoring_table = scoring_table, threshold = \"best\", with_label = TRUE\n)\n\n\n\n\n***Performance using AutoScore:\nAUC:  0.7133   95% CI: 0.6556-0.7709 (DeLong)\nBest score threshold: >= 51 \nOther performance indicators based on this score threshold: \nSensitivity: 0.7421 95% CI: 0.673-0.805\nSpecificity: 0.5887 95% CI: 0.5035-0.6667\nPPV:         0.6704 95% CI: 0.6236-0.7143\nNPV:         0.6696 95% CI: 0.6043-0.735\n\nhead(pred_score)\n\n  pred_score Label\n1         53  TRUE\n2         56  TRUE\n3         49  TRUE\n4         38 FALSE\n5         51  TRUE\n6         40  TRUE\n\n\n\nUse print_roc_performance() to generate the performance under different score thresholds (e.g., 90).\n\n\nprint_roc_performance(pred_score$Label, pred_score$pred_score, threshold = 90)\n\nAUC:  0.7133   95% CI: 0.6556-0.7709 (DeLong)\nScore threshold: >= 90 \nOther performance indicators based on this score threshold: \nSensitivity: 0.0063\nSpecificity: 1\nPPV:         1\nNPV:         0.4716\n\n\n\n\n4.2.6 Map score to risk\n\nUsers can also generate conversion table using conversion_table(). Please refer to our demo for large sample (4.1.6) for detail."
  },
  {
    "objectID": "04-autoscore.html#demo3",
    "href": "04-autoscore.html#demo3",
    "title": "4  AutoScore for binary outcomes",
    "section": "4.3 Demo 3: data with missing values",
    "text": "4.3 Demo 3: data with missing values\nIn Demo 3, we demonstrate the use of AutoScore on a simulated dataset with missing values in two variables (i.e., Vital_A, Vital_B).\n\ncheck_data(sample_data_missing)\n\nData type check passed. \n\n\n\nWARNING: NA detected in data: -----\n.\n\n\n        Variable name No. missing %missing\nVital_A       Vital_A        4000       20\nVital_B       Vital_B       12000       60\n\n\nSUGGESTED ACTION:\n * Consider imputation and supply AutoScore with complete data.\n * Alternatively, AutoScore can handle missing values as a separate 'Unknown' category, IF:\n    - you believe the missingness in your dataset is informative, AND\n    - missing is prevalent enough that you prefer to preserve them as NA rather than removing or doing imputation, AND\n    - missing is not too prevalent, which may make results unstable.\n\n\nAutoScore can automatically treat the missingness as a new category named Unknown. The following steps are the same as those in Demo 1 (4.1).\n\n\n\n\n\n\nImportant\n\n\n\n\nHigh missing rate may cause the variable ranking less reliable, and thus, caution is needed for variable selection using parsimony plot.\n\n\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_missing, ratio = c(0.7, 0.1, 0.2))\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\nranking <- AutoScore_rank(train_set, method = \"rf\", ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n      Age     Lab_H     Lab_K     Lab_B   Vital_E   Vital_A     Lab_I     Lab_A \n152.05596 148.65760 145.97057 144.55385 135.95607 120.73739 107.02069 100.41955 \n  Vital_C     Lab_M   Vital_D     Lab_D     Lab_J   Vital_F     Lab_F     Lab_E \n 95.80391  92.82594  88.44859  85.59284  84.37891  82.78763  79.04925  78.03686 \n    Lab_L     Lab_C     Lab_G   Vital_B   Vital_G \n 74.75048  74.11922  58.84757  57.91472  57.76022 \n\n\n\n\nAUC <- AutoScore_parsimony(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\"\n)\n\nSelect 1 Variable(s):  Area under the curve: 0.6649\nSelect 2 Variable(s):  Area under the curve: 0.7466\nSelect 3 Variable(s):  Area under the curve: 0.7729\nSelect 4 Variable(s):  Area under the curve: 0.7915\nSelect 5 Variable(s):  Area under the curve: 0.8138\nSelect 6 Variable(s):  Area under the curve: 0.8178\nSelect 7 Variable(s):  Area under the curve: 0.8152\nSelect 8 Variable(s):  Area under the curve: 0.8159\nSelect 9 Variable(s):  Area under the curve: 0.814\nSelect 10 Variable(s):  Area under the curve: 0.8142\nSelect 11 Variable(s):  Area under the curve: 0.8137\nSelect 12 Variable(s):  Area under the curve: 0.8209\nSelect 13 Variable(s):  Area under the curve: 0.823\nSelect 14 Variable(s):  Area under the curve: 0.8264\nSelect 15 Variable(s):  Area under the curve: 0.8244\nSelect 16 Variable(s):  Area under the curve: 0.8213\nSelect 17 Variable(s):  Area under the curve: 0.8232\nSelect 18 Variable(s):  Area under the curve: 0.8223\nSelect 19 Variable(s):  Area under the curve: 0.8159\nSelect 20 Variable(s):  Area under the curve: 0.8243\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe Unknown category indicating the missingness will be displayed in the final scoring table.\n\n\n\n\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\ncut_vec <- AutoScore_weighting( \n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)\n)\n\n****Included Variables: \n  variable_name\n1           Age\n2         Lab_H\n3         Lab_K\n4         Lab_B\n5       Vital_E\n6       Vital_A\n****Initial Scores: \n\n\n========  ==========  =====\nvariable  interval    point\n========  ==========  =====\nAge       <35           0  \n          [35,49)       8  \n          [49,76)      17  \n          [76,89)      22  \n          >=89         26  \n                           \nLab_H     <0.2          0  \n          [0.2,1.1)     4  \n          [1.1,3.1)     9  \n          [3.1,4)      14  \n          >=4          18  \n                           \nLab_K     <8            0  \n          [8,42)        7  \n          [42,58)      11  \n          >=58         14  \n                           \nLab_B     <8.5          0  \n          [8.5,11.2)    4  \n          [11.2,17)     7  \n          [17,19.8)    11  \n          >=19.8       12  \n                           \nVital_E   <12           0  \n          [12,15)       1  \n          [15,22)       8  \n          [22,25)      13  \n          >=25         16  \n                           \nVital_A   <59           1  \n          [59,70)       0  \n          [70,100)      7  \n          [100,112)    12  \n          >=113        13  \n          Unknown       7  \n========  ==========  =====\n\n\n\n\n\n***Performance (based on validation set):\nAUC:  0.8178   95% CI: 0.785-0.8506 (DeLong)\nBest score threshold: >= 57 \nOther performance indicators based on this score threshold: \nSensitivity: 0.8581\nSpecificity: 0.6054\nPPV:         0.1545\nNPV:         0.9807\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them"
  },
  {
    "objectID": "05-autoscore_survival.html",
    "href": "05-autoscore_survival.html",
    "title": "5  AutoScore for survival outcomes (AutoScore-Survival)",
    "section": "",
    "text": "AutoScore-Survival refers to the AutoScore framework for developing point-based scoring models for survival outcomes. Similar to the implementation described in Chapter 4 for binary outcomes, AutoScore-Survival is implemented by five functions: AutoScore_rank_Survival(), AutoScore_parsimony_Survival(), AutoScore_weighting_Survival(), AutoScore_fine_tuning_Survival() and AutoScore_testing_Survival().\nIn this chapter, we demonstrate the use of AutoScore-Survival to develop sparse risk scores for a survival outcome, adjust parameters to improve interpretability, assess the performance of the final model and map the score to predict risks for new data. To facilitate clinical applications, in the following sections we demonstrate AutoScore application in 3 demos with large and small datasets and with missing information.\nCitation for AutoScore-Survival:"
  },
  {
    "objectID": "05-autoscore_survival.html#demo1",
    "href": "05-autoscore_survival.html#demo1",
    "title": "5  AutoScore for survival outcomes (AutoScore-Survival)",
    "section": "5.1 Demo 1: large sample",
    "text": "5.1 Demo 1: large sample\nIn Demo 1, we demonstrate the use of AutoScore-Survival on a dataset with 20,000 observations using split-sample approach (i.e., to randomly divide the full dataset into training, validation and test sets) for model development.\n\n\n\n\n\n\nImportant\n\n\n\n\nBefore proceeding, follow the steps in Chapter 2 to ensure all data requirements are met.\nRefer to Chapter 3 for how to generate simple descriptive statistics before building prediction models.\n\n\n\n\nLoad package and data\n\n\nlibrary(AutoScore)\ndata(\"sample_data_survival\")\ncheck_data_survival(sample_data_survival)\n\nData type check passed. \n\n\nNo NA in data \n\n\n\nPrepare training, validation, and test datasets\n\n\nOption 1: Prepare three separate datasets to train, validate, and test models.\nOption 2: Use demo codes below to randomly split your dataset into training, validation, and test datasets (70%, 10%, 20%, respectively).\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_survival, ratio = c(0.7, 0.1, 0.2))\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n5.1.1 STEP(i): generate variable ranking list\n\nAutoScore-Survival Modules 1\n\n\nVariables are ranked using random survival forest.\nntree: Number of trees required only if when method is “rf” (Default: 100).\nRun time increases with larger ntree value. Code below uses ntree = 5 for demonstration.\n\n\nranking <- AutoScore_rank_Survival(train_set = train_set, ntree = 5)\n\n\nTrees Grown:       1,    Time Remaining (sec):       0 \nTrees Grown:       5,    Time Remaining (sec):       0 \n\n\nThe ranking based on variable importance was shown below for each variable: \n    Vital_E       Lab_H         Age       Lab_K     Vital_A       Lab_B \n0.165608652 0.160762453 0.128912855 0.128557962 0.045219867 0.040417391 \n      Lab_G     Vital_C       Lab_M     Vital_B       Lab_C     Vital_D \n0.024342208 0.022561527 0.020905397 0.018080011 0.016227841 0.014980410 \n      Lab_J       Lab_F     Vital_F       Lab_L     Vital_G       Lab_I \n0.013780700 0.012120477 0.011200870 0.008297275 0.006354309 0.005682440 \n      Lab_E       Lab_D       Lab_A \n0.005093323 0.004567277 0.004141324 \n\n\n\n\n\n\n\n5.1.2 STEP(ii): select variables with parsimony plot\n\nAutoScore-Survival Modules 2+3+4\n\n\nn_min: Minimum number of selected variables (Default: 1).\nn_max: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\n\n\niAUC <- AutoScore_parsimony_Survival(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\"\n)\n\nSelect 1 Variable(s):  0.6651428 \nSelect 2 Variable(s):  0.7474401 \nSelect 3 Variable(s):  0.8111006 \nSelect 4 Variable(s):  0.8416833 \nSelect 5 Variable(s):  0.867012 \nSelect 6 Variable(s):  0.8779297 \nSelect 7 Variable(s):  0.8809597 \nSelect 8 Variable(s):  0.8830361 \nSelect 9 Variable(s):  0.8875346 \nSelect 10 Variable(s):  0.8905936 \nSelect 11 Variable(s):  0.8902906 \nSelect 12 Variable(s):  0.8906035 \nSelect 13 Variable(s):  0.8930109 \nSelect 14 Variable(s):  0.8927079 \nSelect 15 Variable(s):  0.8935644 \nSelect 16 Variable(s):  0.8922507 \nSelect 17 Variable(s):  0.8926088 \nSelect 18 Variable(s):  0.89691 \nSelect 19 Variable(s):  0.8981632 \nSelect 20 Variable(s):  0.8983681 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use iAUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(iAUC), file = \"iAUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 6 variables are selected\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 9 variables are selected\nnum_var <- 9\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 6 variables, the 9th and 10th variable are selected\nnum_var <- 6\nfinal_variables <- names(ranking[c(1:num_var, 9, 10)])\n\n\n\n5.1.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore-Survival Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\ncut_vec <- AutoScore_weighting_Survival(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n****Included Variables: \n  variable_name\n1       Vital_E\n2         Lab_H\n3           Age\n4         Lab_K\n5       Vital_A\n6         Lab_B\n****Initial Scores: \n\n\n========  ==========  =====\nvariable  interval    point\n========  ==========  =====\nVital_E   <12           0  \n          [12,15)       5  \n          [15,22)      11  \n          [22,25)      16  \n          >=25         18  \n                           \nLab_H     <0.2          0  \n          [0.2,1.1)     3  \n          [1.1,3.1)     8  \n          [3.1,4)      13  \n          >=4          18  \n                           \nAge       <35           0  \n          [35,49)       5  \n          [49,76)      13  \n          [76,89)      21  \n          >=89         24  \n                           \nLab_K     <8            0  \n          [8,42)        5  \n          [42,58)      11  \n          >=58         13  \n                           \nVital_A   <60           0  \n          [60,73)       3  \n          [73,98)       8  \n          [98,111)     11  \n          >=111        13  \n                           \nLab_B     <8.5          0  \n          [8.5,11.2)    3  \n          [11.2,17)     8  \n          [17,19.8)    11  \n          >=19.8       13  \n========  ==========  =====\nIntegrated AUC by all time points: 0.8779297\nC_index:  0.785738 \nThe AUC(t) are shown as bwlow:\n  time_point     AUC_t\n1          1 0.0002500\n2          3 1.0000000\n3          7 0.9927981\n4         14 0.9872613\n5         30 0.9433755\n6         60 0.8735564\n7         90 0.8599778\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n5.1.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore-Survival Module 5 & Re-run AutoScore-Survival Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore-Survival Module 5).\nRe-run AutoScore-Survival Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\n## For example, we have current cutoffs of continuous variable: Age \n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n## Age             <35            0  \n##                 [35,49)        5 \n##                 [49,76)       13  \n##                 [76,89)       21  \n##                 >=89          24  \n\n\nCurrent cutoffs:c(35, 49, 76, 89). We can fine tune the cutoffs as follows:\n\n\n# Example 1: rounding up to a nice number\ncut_vec$Age <- c(35, 50, 75, 90)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Age <- c(25, 50, 75, 90)\n\n# Example 3: combining categories\ncut_vec$Age <- c(50, 75, 90)\n\n\nThen we do similar checks for other variables and update scoring table using new cutoffs if needed.\n\n\ncut_vec$Lab_H <- c(0.2, 1, 3, 4)\ncut_vec$Lab_K <- c(10, 40)\ncut_vec$Lab_B <- c(10, 17)\ncut_vec$Vital_A <- c(70, 98)\nscoring_table <- AutoScore_fine_tuning_Survival(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, cut_vec = cut_vec, max_score = 100,\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n***Fine-tuned Scores: \n\n\n========  ========  =====\nvariable  interval  point\n========  ========  =====\nVital_E   <12         0  \n          [12,15)     4  \n          [15,22)    11  \n          [22,25)    19  \n          >=25       22  \n                         \nLab_H     <0.2        0  \n          [0.2,1)     4  \n          [1,3)      11  \n          [3,4)      15  \n          >=4        22  \n                         \nAge       <50         0  \n          [50,75)    11  \n          [75,90)    19  \n          >=90       22  \n                         \nLab_K     <10         0  \n          [10,40)     7  \n          >=40       11  \n                         \nVital_A   <70         0  \n          [70,98)     7  \n          >=98       11  \n                         \nLab_B     <10         0  \n          [10,17)     4  \n          >=17       11  \n========  ========  =====\n***Performance (based on validation set, after fine-tuning):\nIntegrated AUC by all time points: 0.8678829\nC_index:  0.7772233 \nThe AUC(t) are shown as bwlow:\n  time_point     AUC_t\n1          1 0.0002500\n2          3 1.0000000\n3          7 0.9853457\n4         14 0.9867337\n5         30 0.9366347\n6         60 0.8606470\n7         90 0.8585631\n\n\n\n\n5.1.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore-Survival Module 6\n\n\nthreshold: Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to \"best\", the optimal threshold will be calculated (Default: \"best\").\nwith_label: Set to TRUE if there are labels in the test_set and performance will be evaluated accordingly (Default: TRUE).\nSet the with_label to FALSE if there are not label in the test_set and the final predicted scores will be the output without performance evaluation.\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\npred_score <- AutoScore_testing_Survival(\n  test_set = test_set, final_variables = final_variables, cut_vec = cut_vec, \n  scoring_table = scoring_table, threshold = \"best\", with_label = TRUE,\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n***Performance using AutoScore (based on unseen test Set):\nIntegrated AUC by all time points: 0.873 (0.864-0.88)\nC_index:  0.782 (0.773-0.789) \nThe AUC(t) are shown as bwlow:\n  time_point               AUC_t\n1          1     0.637 (0-0.997)\n2          3  0.955 (0.91-0.996)\n3          7 0.969 (0.939-0.992)\n4         14 0.946 (0.921-0.974)\n5         30 0.937 (0.923-0.949)\n6         60 0.865 (0.854-0.875)\n7         90  0.865 (0.85-0.877)\n\nhead(pred_score)\n\n  pred_score label_time label_status\n1         19         91        FALSE\n2         44         60         TRUE\n3         70         43         TRUE\n4         37         90         TRUE\n5         51         62         TRUE\n6         33         91        FALSE\n\n\n\n\n5.1.6 Map score to risk\nFurther analysis to map score to risk (e.g., conversion table, Kaplan Meier Curve, output the score).\n\nUse plot_survival_km() to generate Kaplan-Meier curve under different score thresholds (decided by users, e.g., 50).\n\n\nplot_survival_km(pred_score = pred_score, score_cut = c(50))\n\n\n\n\n\nUser can also use several score thresholds to cut the score for generate Kaplan-Meier curve.\n\n\nplot_survival_km(pred_score, score_cut = c(40, 50, 60))\n\n\n\n\n\nUse conversion_table_survival() to generate the performance under different score_cut score cut-offs.\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\nconversion_table_survival(\n  pred_score = pred_score, score_cut = c(40,50,60), \n  time_point = c(7, 14, 30, 60, 90)\n)\n\n                       [8,40) [40,50) [50,60) [60,93]\nNumber of patients        656    1076    1241    1027\nPercentage of patients  16.4%   26.9%  31.03%  25.67%\nt=7                        0%      0%      0%   0.58%\nt=14                       0%      0%      0%   2.82%\nt=30                       0%      0%   0.32%  12.07%\nt=60                    1.52%   8.46%  29.33%   70.5%\nt=90                   24.24%  60.59%  87.19%  98.64%\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use pred_score for further analysis or export it to CSV to other software (e.g., generating the calibration curve).\n\n\nwrite.csv(pred_score, file = \"pred_score.csv\")"
  },
  {
    "objectID": "05-autoscore_survival.html#demo2",
    "href": "05-autoscore_survival.html#demo2",
    "title": "5  AutoScore for survival outcomes (AutoScore-Survival)",
    "section": "5.2 Demo 2: small sample",
    "text": "5.2 Demo 2: small sample\nIn Demo 2, we demonstrate the use of AutoScore-Survival on a smaller dataset where there are no sufficient samples to form a separate training and validation dataset. Thus, the cross validation is employed to generate the parsimony plot.\n\nLoad small dataset with 1000 samples\n\n\ndata(\"sample_data_survival_small\")\n\n\nPrepare training and test datasets\n\n\nOption 1: Prepare two separate datasets to train and test models.\nOption 2: Use demo codes below to randomly split your dataset into training and test datasets (70% and 30%, respectively). For cross-validation, train_set is equal to validation_set and the ratio of validation_set should be 0. Then cross-validation will be implemented in the STEP(ii) AutoScore_parsimony_Survival().\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_survival_small, ratio = c(0.7, 0, 0.3), \n                        cross_validation = TRUE)\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n5.2.1 STEP(i): generate variable ranking list\n\nAutoScore-Survival Modules 1\n\n\nVariables are ranked using random survival forest.\nntree: Number of trees required only if when method is “rf” (Default: 100).\nRun time increases with larger ntree value. Code below uses ntree = 5 for demonstration.\n\n\nranking <- AutoScore_rank_Survival(train_set = train_set, ntree = 5)\n\n\nTrees Grown:       1,    Time Remaining (sec):       0 \n\n\nThe ranking based on variable importance was shown below for each variable: \n      Vital_E         Lab_H           Age         Lab_K         Lab_B \n 1.056965e-01  9.211654e-02  9.174663e-02  6.298467e-02  6.046187e-02 \n      Vital_F       Vital_A         Lab_F         Lab_J       Vital_C \n 4.304715e-02  3.741877e-02  2.783056e-02  2.610612e-02  1.774737e-02 \n        Lab_E         Lab_C         Lab_M       Vital_B         Lab_G \n 1.674145e-02  1.518732e-02  1.430115e-02  1.422398e-02  9.859650e-03 \n      Vital_D         Lab_I         Lab_A       Vital_G         Lab_L \n 7.664181e-03  4.044984e-03  2.562711e-03  0.000000e+00 -2.395057e-05 \n        Lab_D \n-7.823852e-04 \n\n\n\n\n\n\n\n5.2.2 STEP(ii): select the best model with parsimony plot\n\nAutoScore-Survival Modules 2+3+4/p>\n\nnmin: Minimum number of selected variables (Default: 1).\nnmax: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\ncross_validation: TRUE if cross-validation is needed, especially for small datasets.\nfold: The number of folds used in cross validation (Default: 10). Available if cross_validation = TRUE.\ndo_trace: If set to TRUE, all results based on each fold of cross-validation would be printed out and plotted (Default: FALSE). Available if cross_validation = TRUE.\n\n\niAUC <- AutoScore_parsimony_Survival(\n  train_set = train_set, validation_set = validation_set, rank = ranking,\n  max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\",\n  cross_validation = TRUE, fold = 10, do_trace = FALSE\n)\n\n***list of final mean AUC values through cross-validation are shown below \n   auc_set.sum\n1    0.6360233\n2    0.7296583\n3    0.7991611\n4    0.8326020\n5    0.8344274\n6    0.8318417\n7    0.8449623\n8    0.8499911\n9    0.8522826\n10   0.8560715\n11   0.8547488\n12   0.8537975\n13   0.8601176\n14   0.8637747\n15   0.8626508\n16   0.8588067\n17   0.8681878\n18   0.8682324\n19   0.8665358\n20   0.8663715\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use iAUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(iAUC), file = \"iAUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 6 variables are selected\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 9 variables are selected\nnum_var <- 9\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 6 variables, the 9th and 10th variable are selected\nnum_var <- 6\nfinal_variables <- names(ranking[c(1:num_var, 9, 10)])\n\n\n\n5.2.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore-Survival Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\ncut_vec <- AutoScore_weighting_Survival(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n****Included Variables: \n  variable_name\n1       Vital_E\n2         Lab_H\n3           Age\n4         Lab_K\n5         Lab_B\n6       Vital_F\n****Initial Scores: \n\n\n========  ===========  =====\nvariable  interval     point\n========  ===========  =====\nVital_E   <12            0  \n          [12,15)        5  \n          [15,22)       15  \n          [22,25)       21  \n          >=25          22  \n                            \nLab_H     <0.1           0  \n          [0.1,1.2)      4  \n          [1.2,3.1)     11  \n          [3.1,4.1)     20  \n          >=4.1         24  \n                            \nAge       <37            0  \n          [37,49)        2  \n          [49,76)        8  \n          [76,89)       16  \n          >=89          22  \n                            \nLab_K     <8             0  \n          [8,42)         7  \n          [42,59)       12  \n          >=59          14  \n                            \nLab_B     <9             0  \n          [9,11.5)       3  \n          [11.5,16.9)    4  \n          [16.9,19.8)   10  \n          >=19.8        14  \n                            \nVital_F   <35.9          3  \n          [35.9,36.3)    2  \n          [36.3,37.3)    2  \n          [37.3,37.7)    0  \n          >=37.7         0  \n========  ===========  =====\nIntegrated AUC by all time points: 0.8551594\nC_index:  0.7644388 \nThe AUC(t) are shown as bwlow:\n  time_point     AUC_t\n1          1 0.9971388\n2          3 0.9770774\n3          7 0.9770774\n4         14 0.9856115\n5         30 0.9005364\n6         60 0.8520291\n7         90 0.8462442\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n5.2.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore-Survival Module 5 & Re-run AutoScore-Survival Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore-Survival Module 5).\nRe-run AutoScore-Survival Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\n## For example, we have current cutoffs of continuous variable: Age \n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n## Age             <35            0  \n##                 [35,49)        2  \n##                 [49,76)        8  \n##                 [76,89)       16  \n##                 >=89          22  \n\n\nCurrent cutoffs:c(35, 49, 76, 89). We can fine tune the cutoffs as follows:\n\n\n# Example 1: rounding up to a nice number\ncut_vec$Age <- c(35, 50, 75, 90)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Age <- c(25, 50, 75, 90)\n\n# Example 3: combining categories\ncut_vec$Age <- c(50, 75, 90)\n\n\nThen we do similar checks for other variables and update scoring table using new cutoffs if needed.\n\n\ncut_vec$Lab_H <- c(0.2, 1, 3, 4)\ncut_vec$Lab_K <- c(10, 40)\ncut_vec$Lab_B <- c(10, 17)\ncut_vec$Vital_A <- c(70, 98)\nscoring_table <- AutoScore_fine_tuning_Survival(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, cut_vec = cut_vec, max_score = 100,\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n***Fine-tuned Scores: \n\n\n========  ===========  =====\nvariable  interval     point\n========  ===========  =====\nVital_E   <12            0  \n          [12,15)        3  \n          [15,22)       15  \n          [22,25)       21  \n          >=25          23  \n                            \nLab_H     <0.2           0  \n          [0.2,1)        3  \n          [1,3)         11  \n          [3,4)         20  \n          >=4           26  \n                            \nAge       <50            0  \n          [50,75)        9  \n          [75,90)       15  \n          >=90          23  \n                            \nLab_K     <10            0  \n          [10,40)        9  \n          >=40          15  \n                            \nLab_B     <10            0  \n          [10,17)        3  \n          >=17           9  \n                            \nVital_F   <35.9          4  \n          [35.9,36.3)    1  \n          [36.3,37.3)    2  \n          [37.3,37.7)    0  \n          >=37.7         0  \n========  ===========  =====\n***Performance (based on validation set, after fine-tuning):\nIntegrated AUC by all time points: 0.8535286\nC_index:  0.7634054 \nThe AUC(t) are shown as bwlow:\n  time_point     AUC_t\n1          1 1.0000000\n2          3 0.9674069\n3          7 0.9674069\n4         14 0.9772662\n5         30 0.8922335\n6         60 0.8466340\n7         90 0.8518403\n\n\n\n\n5.2.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore-Survival Module 6\n\n\nthreshold: Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to \"best\", the optimal threshold will be calculated (Default: \"best\").\nwith_label: Set to TRUE if there are labels in the test_set and performance will be evaluated accordingly (Default: TRUE).\nSet the with_label to FALSE if there are not label in the test_set and the final predicted scores will be the output without performance evaluation.\ntime_point: The time points to be evaluated using time-dependent AUC(t).\n\n\npred_score <- AutoScore_testing_Survival(\n  test_set = test_set, final_variables = final_variables, cut_vec = cut_vec, \n  scoring_table = scoring_table, threshold = \"best\", with_label = TRUE,\n  time_point = c(1, 3, 7, 14, 30, 60, 90)\n)\n\n***Performance using AutoScore (based on unseen test Set):\nIntegrated AUC by all time points: 0.872 (0.848-0.898)\nC_index:  0.78 (0.751-0.805) \nThe AUC(t) are shown as bwlow:\n  time_point               AUC_t\n1          1 0.003 (0.002-0.007)\n2          3 0.003 (0.002-0.007)\n3          7     0.651 (0.002-1)\n4         14     0.864 (0.002-1)\n5         30 0.944 (0.901-0.981)\n6         60 0.856 (0.814-0.902)\n7         90 0.852 (0.801-0.892)\n\nhead(pred_score)\n\n  pred_score label_time label_status\n1         67         52         TRUE\n2         26         91        FALSE\n3         49         75         TRUE\n4         70         59         TRUE\n5         30         91        FALSE\n6         47         91        FALSE\n\n\n\n\n5.2.6 Map score to risk\n\nUsers can also generate conversion table using conversion_table_survival(), and Kaplan-Meier curve using plot_survival_km(). Please refer to our demo for large sample (5.1.6) for detail."
  },
  {
    "objectID": "05-autoscore_survival.html#demo3",
    "href": "05-autoscore_survival.html#demo3",
    "title": "5  AutoScore for survival outcomes (AutoScore-Survival)",
    "section": "5.3 Demo 3: data with missing values",
    "text": "5.3 Demo 3: data with missing values\nIn Demo #3, we demonstrate the use of AutoScore on a dataset with missing values in two variables (i.e., Vital_A, Vital_B).\n\ncheck_data_survival(sample_data_survival_missing)\n\nData type check passed. \n\n\n\nWARNING: NA detected in data: -----\n.\n\n\n        Variable name No. missing %missing\nVital_A       Vital_A        4000       20\nVital_B       Vital_B       12000       60\n\n\nSUGGESTED ACTION:\n * Consider imputation and supply AutoScore with complete data.\n * Alternatively, AutoScore can handle missing values as a separate 'Unknown' category, IF:\n    - you believe the missingness in your dataset is informative, AND\n    - missing is prevalent enough that you prefer to preserve them as NA rather than removing or doing imputation, AND\n    - missing is not too prevalent, which may make results unstable.\n\n\nAutoScore can automatically treat the missingness as a new category named Unknown. The following steps are the same as those in Demo 1 (5.1).\n\n\n\n\n\n\nImportant\n\n\n\n\nHigh missing rate may cause the variable ranking less reliable, and thus, caution is needed for variable selection using parsimony plot.\n\n\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_survival_missing, ratio = c(0.7, 0.1, 0.2))\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\nranking <- AutoScore_rank_Survival(train_set = train_set, ntree = 5)\n\n\nTrees Grown:       1,    Time Remaining (sec):       4 \nTrees Grown:       5,    Time Remaining (sec):       0 \n\n\nThe ranking based on variable importance was shown below for each variable: \n      Lab_H     Vital_E         Age       Lab_K     Vital_A       Lab_B \n0.189048035 0.153815166 0.148410072 0.113510258 0.052494936 0.039331535 \n      Lab_G     Vital_C     Vital_B       Lab_M       Lab_C       Lab_J \n0.027740318 0.020009762 0.019397757 0.017821924 0.012899126 0.011615832 \n      Lab_E     Vital_D     Vital_G       Lab_L     Vital_F       Lab_A \n0.010927125 0.008761049 0.008098151 0.007862010 0.007065528 0.006657491 \n      Lab_D       Lab_I       Lab_F \n0.006350121 0.006320267 0.005267076 \n\n\n\n\niAUC <- AutoScore_parsimony_Survival(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),\n  auc_lim_min = 0.5, auc_lim_max = \"adaptive\"\n)\n\nSelect 1 Variable(s):  0.6702443 \nSelect 2 Variable(s):  0.7474401 \nSelect 3 Variable(s):  0.8111006 \nSelect 4 Variable(s):  0.8416833 \nSelect 5 Variable(s):  0.8638688 \nSelect 6 Variable(s):  0.874965 \nSelect 7 Variable(s):  0.8787852 \nSelect 8 Variable(s):  0.8818598 \nSelect 9 Variable(s):  0.8830868 \nSelect 10 Variable(s):  0.8882672 \nSelect 11 Variable(s):  0.8883038 \nSelect 12 Variable(s):  0.8918071 \nSelect 13 Variable(s):  0.8909669 \nSelect 14 Variable(s):  0.8920578 \nSelect 15 Variable(s):  0.8908901 \nSelect 16 Variable(s):  0.891204 \nSelect 17 Variable(s):  0.8909822 \nSelect 18 Variable(s):  0.890646 \nSelect 19 Variable(s):  0.8912008 \nSelect 20 Variable(s):  0.8946074 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe Unknown category indicating the missingness will be displayed in the final scoring table.\n\n\n\n\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\ncut_vec <- AutoScore_weighting_Survival(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)\n)\n\n****Included Variables: \n  variable_name\n1         Lab_H\n2       Vital_E\n3           Age\n4         Lab_K\n5       Vital_A\n6         Lab_B\n****Initial Scores: \n\n\n========  ==========  =====\nvariable  interval    point\n========  ==========  =====\nLab_H     <0.2          0  \n          [0.2,1.1)     4  \n          [1.1,3.1)     8  \n          [3.1,4)      14  \n          >=4          18  \n                           \nVital_E   <12           0  \n          [12,15)       4  \n          [15,22)      10  \n          [22,25)      16  \n          >=25         20  \n                           \nAge       <35           0  \n          [35,49)       6  \n          [49,76)      12  \n          [76,89)      20  \n          >=89         24  \n                           \nLab_K     <8            0  \n          [8,42)        6  \n          [42,58)      10  \n          >=58         12  \n                           \nVital_A   <59           0  \n          [59,70)       2  \n          [70,100)      8  \n          [100,112)    12  \n          >=113        14  \n          Unknown       8  \n                           \nLab_B     <8.5          0  \n          [8.5,11.2)    4  \n          [11.2,17)     8  \n          [17,19.8)    10  \n          >=19.8       14  \n========  ==========  =====\nIntegrated AUC by all time points: 0.874965\nC_index:  0.7833611 \nThe AUC(t) are shown as bwlow:\n  time_point     AUC_t\n1          1 0.0002500\n2          3 1.0000000\n3          7 0.9939254\n4         14 0.9874121\n5         30 0.9424219\n6         60 0.8702307\n7         90 0.8605016\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them"
  },
  {
    "objectID": "06-autoscore_ordinal.html",
    "href": "06-autoscore_ordinal.html",
    "title": "6  AutoScore for ordinal outcomes (AutoScore-Ordinal)",
    "section": "",
    "text": "AutoScore-Ordinal refers to the AutoScore framework for developing point-based scoring models for ordinal outcomes. Similar to the implementation described in Chapter 4 for binary outcomes, AutoScore-Ordinal is implemented by five functions: AutoScore_rank_Ordinal(), AutoScore_parsimony_Ordinal(), AutoScore_weighting_Ordinal(), AutoScore_fine_tuning_Ordinal() and AutoScore_testing_Ordinal().\nIn this chapter, we demonstrate the use of AutoScore-Ordinal to develop sparse risk scores for an ordinal outcome, adjust parameters to improve interpretability, assess the performance of the final model and map the score to predict risks for new data. To facilitate clinical applications, in the following sections we demonstrate AutoScore application in 3 demos with large and small datasets and with missing information.\nCite the following paper for AutoScore-Ordinal:"
  },
  {
    "objectID": "06-autoscore_ordinal.html#demo1",
    "href": "06-autoscore_ordinal.html#demo1",
    "title": "6  AutoScore for ordinal outcomes (AutoScore-Ordinal)",
    "section": "6.1 Demo 1: large sample",
    "text": "6.1 Demo 1: large sample\nIn Demo 1, we demonstrate the use of AutoScore-Ordinal on a dataset with 20,000 observations using split-sample approach (i.e., to randomly divide the full dataset into training, validation and test sets) for model development.\n\n\n\n\n\n\nImportant\n\n\n\n\nBefore proceeding, follow the steps in Chapter 2 to ensure all data requirements are met.\nRefer to Chapter 3 for how to generate simple descriptive statistics before building prediction models.\n\n\n\n\nLoad package and data\n\n\nlibrary(AutoScore)\ndata(\"sample_data_ordinal\")\ndim(sample_data_ordinal)\n\n[1] 20000    21\n\nhead(sample_data_ordinal)\n\n  label Age Gender Util_A Util_B Util_C    Util_D Comorb_A Comorb_B Comorb_C\n1     1  63 FEMALE     P2      0   0.00 3.5933333        0        0        0\n2     1  41 FEMALE     P2      0   0.96 3.6288889        0        0        0\n3     1  86   MALE     P1      0   0.00 2.6502778        0        0        0\n4     1  51   MALE     P2      0   0.00 4.9711111        0        0        0\n5     1  23 FEMALE     P1      0   0.00 0.5352778        0        0        0\n6     1  32 FEMALE     P2      0   4.13 4.4008333        0        0        0\n  Comorb_D Comorb_E Lab_A Lab_B Lab_C Vital_A Vital_B Vital_C Vital_D Vital_E\n1        0        0   117   3.9   136      91      19     100      70     152\n2        1        0   500   3.6   114      91      16     100      70     147\n3        0        0    72   4.1   136     100      18      99      65     126\n4        0        0    67   5.0   122      73      17      97      46     100\n5        0        0  1036   4.1   138      74      18      98      89     114\n6        0        0   806   4.1   136      77      18      98      74     157\n  Vital_F\n1    25.7\n2    22.6\n3    25.7\n4    24.9\n5    25.7\n6    25.3\n\ncheck_data_ordinal(sample_data_ordinal)\n\nData type check passed. \n\n\nNo NA in data \n\n\n\nPrepare training, validation, and test datasets\n\n\nOption 1: Prepare three separate datasets to train, validate, and test models.\nOption 2: Use demo codes below to randomly split your dataset into training, validation, and test datasets (70%, 10%, 20%, respectively), possibly stratified by outcome categories (strat_by_label = TRUE) to ensure they are well represented in all three datasets.\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_ordinal, ratio = c(0.7, 0.1, 0.2), \n                        strat_by_label = TRUE)\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n6.1.1 STEP(i): generate variable ranking list\n\nAutoScore-Ordinal Module 1\n\n\nVariables are ranked by random forest for multiclass classification.\nntree: Number of trees in the random forest algorithm (Default: 100).\n\n\nranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n   Util_D     Lab_A   Vital_F   Vital_A       Age   Vital_E   Vital_D     Lab_B \n413.60631 379.51127 378.30195 372.84319 372.68880 364.51371 339.60643 296.86038 \n    Lab_C    Util_C    Util_B   Vital_C   Vital_B  Comorb_A    Util_A    Gender \n279.47643 244.28653 201.34337 186.47331 168.45639 115.28191  98.78811  51.88705 \n Comorb_B  Comorb_D  Comorb_C  Comorb_E \n 41.11154  32.31979  17.64803  11.87098 \n\n\n\n\n\n\n\n6.1.2 STEP(ii): select model with parsimony plot\n\nAutoScore-Ordinal Modules 2+3+4\n\n\nn_min: Minimum number of selected variables (Default: 1).\nn_max: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\nlink: link function in the ordinal regression, which affects predictive performance. Options include \"logit\" (for proportional odds model), \"cloglog\" (for proportional hazard model) and \"probit\" (Default: \"logit\").\n\n\n\n\n\n\n\nImportant\n\n\n\nUse the same link parameter throughout descriptive analysis and model building steps.\n\n\n\nlink <- \"logit\"\nmAUC <- AutoScore_parsimony_Ordinal(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, link = link, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  auc_lim_min = 0, auc_lim_max = \"adaptive\"\n)\n\nSelect 1 variables:  Mean area under the curve: 0.4555607 \nSelect 2 variables:  Mean area under the curve: 0.5110174 \nSelect 3 variables:  Mean area under the curve: 0.5780548 \nSelect 4 variables:  Mean area under the curve: 0.5912554 \nSelect 5 variables:  Mean area under the curve: 0.6685143 \nSelect 6 variables:  Mean area under the curve: 0.672106 \nSelect 7 variables:  Mean area under the curve: 0.6690071 \nSelect 8 variables:  Mean area under the curve: 0.6710102 \nSelect 9 variables:  Mean area under the curve: 0.6706072 \nSelect 10 variables:  Mean area under the curve: 0.6721932 \nSelect 11 variables:  Mean area under the curve: 0.7003498 \nSelect 12 variables:  Mean area under the curve: 0.6995013 \nSelect 13 variables:  Mean area under the curve: 0.6994186 \nSelect 14 variables:  Mean area under the curve: 0.7476355 \nSelect 15 variables:  Mean area under the curve: 0.7489346 \nSelect 16 variables:  Mean area under the curve: 0.7448716 \nSelect 17 variables:  Mean area under the curve: 0.744752 \nSelect 18 variables:  Mean area under the curve: 0.744752 \nSelect 19 variables:  Mean area under the curve: 0.745261 \nSelect 20 variables:  Mean area under the curve: 0.7472124 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use mAUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(mAUC), file = \"mAUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 5 variables are selected\nnum_var <- 5\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 14 variables are selected\nnum_var <- 14\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 5 variables, the 11th and 14th variable are selected\nfinal_variables <- names(ranking[c(1:5, 11, 14)])\n\n\n\n6.1.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore-Ordinal Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\nPerformance of resulting scores is evaluated using the mean AUC across dichotomous classifications (mAUC), with 95% CI computed using bootstrap (Default: n_boot = 100 bootstrap samples). Setting n_boot = 1 disables bootstrap and reports mAUC without CI.\nRun time increases with larger n_boot value. Code below uses n_boot = 10 for demonstration.\n\n\ncut_vec <- AutoScore_weighting_Ordinal(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, link = link, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  n_boot = 10\n)\n\n****Included Variables: \n  variable_name\n1        Util_D\n2         Lab_A\n3       Vital_F\n4       Vital_A\n5           Age\n6        Util_B\n7      Comorb_A\n****Initial Scores: \n\n\n========  ============  =====\nvariable  interval      point\n========  ============  =====\nUtil_D    <0.652          7  \n          [0.652,1.32)    7  \n          [1.32,3.93)     2  \n          [3.93,5.93)     1  \n          >=5.93          0  \n                             \nLab_A     <46             6  \n          [46,61)         0  \n          [61,134)        1  \n          [134,584)       8  \n          >=584           6  \n                             \nVital_F   <16.7           8  \n          [16.7,20.5)     4  \n          [20.5,25.4)     0  \n          [25.4,28.1)     1  \n          >=28.1          4  \n                             \nVital_A   <58             2  \n          [58,68)         0  \n          [68,97)         3  \n          [97,113)        6  \n          >=113          13  \n                             \nAge       <27             0  \n          [27,46)         4  \n          [46,78)        14  \n          [78,87)        18  \n          >=87           21  \n                             \nUtil_B    <1              0  \n          [1,4)          10  \n          >=4            21  \n                             \nComorb_A  0               0  \n          1              22  \n========  ============  =====\n***Performance (based on validation set):\nmAUC: 0.7402     95% CI: 0.7157-0.7593 (from 10 bootstrap samples)\n***The cutoffs of each variables generated by the AutoScore-Ordinal are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n6.1.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore-Ordinal Module 5 & Re-run AutoScore-Ordinal Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore-Ordinal Module 5).\nRe-run AutoScore-Ordinal Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\n\n\n## For example, we have current cutoffs of continuous variable: Age \n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n## Age                 <27          0  \n##                     [27,46)      4  \n##                     [46,78)     14  \n##                     [78,87)     18 \n##                     >=87        21 \n\n\nCurrent cutoffs:c(27, 46, 78, 87). We can fine tune the cutoffs as follows:\n\n\n# Example 1: rounding to a nice number\ncut_vec$Age <- c(25, 45, 75, 85)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Age <- c(25, 50, 75, 85)\n\n# Example 3: combining categories\ncut_vec$Age <- c(45, 75, 85)\n\n\nmAUC and 95% bootstrap CI (Default: n_boot = 100 bootstrap samples) are reported after fine-tuning.\nRun time increases with larger n_boot value. Code below uses n_boot = 10 for demonstration.\n\n\ncut_vec$Util_D <- c(2 / 3, 4 / 3, 4, 6)\ncut_vec$Vital_F <- c(17, 20, 25, 28)\ncut_vec$Vital_A <- c(60, 70, 95, 115)\ncut_vec$Lab_A <- c(45, 60, 135, 595)\ncut_vec$Age <- c(25, 45, 75, 85)\nscoring_table <- AutoScore_fine_tuning_Ordinal(\n  train_set = train_set, validation_set = validation_set,\n  final_variables = final_variables, link = link, cut_vec = cut_vec,\n  max_score = 100, n_boot = 10\n)\n\n***Fine-tuned Scores: \n\n\n========  ============  =====\nvariable  interval      point\n========  ============  =====\nUtil_D    <0.667          7  \n          [0.667,1.33)    7  \n          [1.33,4)        2  \n          [4,6)           1  \n          >=6             0  \n                             \nLab_A     <45             7  \n          [45,60)         0  \n          [60,135)        1  \n          [135,595)       8  \n          >=595           6  \n                             \nVital_F   <17             8  \n          [17,20)         4  \n          [20,25)         0  \n          [25,28)         0  \n          >=28            4  \n                             \nVital_A   <60             0  \n          [60,70)         0  \n          [70,95)         2  \n          [95,115)        5  \n          >=115          13  \n                             \nAge       <25             0  \n          [25,45)         4  \n          [45,75)        14  \n          [75,85)        19  \n          >=85           22  \n                             \nUtil_B    <1              0  \n          [1,4)          10  \n          >=4            21  \n                             \nComorb_A  0               0  \n          1              22  \n========  ============  =====\n***Performance (based on Validation Set, after fine-tuning):\nmAUC: 0.7466     95% CI: 0.7369-0.7633 (from 10 bootstrap samples)\n\n\n\n\n6.1.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore-Ordinal Module 6\n\n\nmAUC and generalised c-index are reported for the test set, with 95% bootstrap CI (Default: n_boot = 100 bootstrap samples).\nRun time increases with larger n_boot value. Code below uses n_boot = 10 for demonstration.\n\n\npred_score <- AutoScore_testing_Ordinal(\n  test_set = test_set, link = link, final_variables = final_variables, \n  cut_vec = cut_vec, scoring_table = scoring_table, \n  with_label = TRUE, n_boot = 10\n)\n\n***Performance using AutoScore-Ordinal (based on unseen test Set):\nmAUC: 0.7552     95% CI: 0.7585-0.7776 (from 10 bootstrap samples)\nGeneralised c-index: 0.7267      95% CI: 0.7229-0.7378 (from 10 bootstrap samples)\n\nhead(pred_score)\n\n  pred_score Label\n1         40     1\n2         35     1\n3         29     1\n4         26     1\n5         33     1\n6         22     1\n\n\n\nUsers can compute mAUC and generalised c-index (with 95% bootstrap CI) for previously saved pred_score.\n\n\nprint_performance_ordinal(\n  label = pred_score$Label, score = pred_score$pred_score, \n  n_boot = 10, report_cindex = TRUE\n)\n\nmAUC: 0.7552     95% CI: 0.7400-0.7632 (from 10 bootstrap samples)\nGeneralised c-index: 0.7267      95% CI: 0.7155-0.7360 (from 10 bootstrap samples)\n\n\n\n\n6.1.6 Map score to risk\n\nThe interactive figure below maps score to predicted risks.\npoint_size: Size of points indicating all attainable scores (Default: 0.5).\n\n\nplot_predicted_risk(pred_score = pred_score, max_score = 100, \n                    final_variables = final_variables, link = link,\n                    scoring_table = scoring_table, point_size = 1)\n\n\n\n\n\n\nGiven the proportion of subjects for each score value (see figure above), select reasonable score breaks (Default: 5, 10, 15, …, 70) to report the average predicted risk within each score interval, which can be used to predict risk for a new subject.\nWhen selecting score breaks, avoid creating score intervals with too few observations.\n\n\nconversion_table_ordinal(pred_score = pred_score, link = link,\n                         score_breaks = seq(from = 5, to = 70, by = 5), \n                         digits = 4)\n\n\n\n\n\n\n\n\n\n\nScore\nPredicted risk, category 1\nPredicted risk, category 2\nPredicted risk, category 3\n\n\n\n\n[0,5]\n0.9742\n0.0192\n0.0065\n\n\n(5,10]\n0.9617\n0.0285\n0.0098\n\n\n(10,15]\n0.9454\n0.0404\n0.0142\n\n\n(15,20]\n0.9226\n0.0569\n0.0205\n\n\n(20,25]\n0.8914\n0.0791\n0.0295\n\n\n(25,30]\n0.8497\n0.1081\n0.0423\n\n\n(30,35]\n0.7956\n0.1441\n0.0602\n\n\n(35,40]\n0.7284\n0.1864\n0.0851\n\n\n(40,45]\n0.6489\n0.2321\n0.1190\n\n\n(45,50]\n0.5602\n0.2758\n0.1640\n\n\n(50,55]\n0.4675\n0.3109\n0.2216\n\n\n(55,60]\n0.3769\n0.3307\n0.2924\n\n\n(60,65]\n0.2942\n0.3309\n0.3749\n\n\n(65,70]\n0.2231\n0.3116\n0.4653\n\n\n(70,100]\n0.0840\n0.1718\n0.7442\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use pred_score for further analysis or export it to CSV to other software (e.g., generating the calibration curve).\n\n\nwrite.csv(pred_score, file = \"pred_score.csv\")"
  },
  {
    "objectID": "06-autoscore_ordinal.html#demo2",
    "href": "06-autoscore_ordinal.html#demo2",
    "title": "6  AutoScore for ordinal outcomes (AutoScore-Ordinal)",
    "section": "6.2 Demo 2: small sample",
    "text": "6.2 Demo 2: small sample\nIn Demo 2, we demonstrate the use of AutoScore-Ordinal on a smaller dataset where there are no sufficient samples to form a separate training and validation dataset. Thus, the cross validation is employed to generate the parsimony plot.\n\nLoad small dataset with 5000 samples\n\n\ndata(\"sample_data_ordinal_small\")\n\n\nPrepare training and test datasets\n\n\nOption 1: Prepare two separate datasets to train and test models.\nOption 2: Use demo codes below to randomly split your dataset into training and test datasets (70% and 30%, respectively). For cross-validation, train_set is equal to validation_set and the ratio of validation_set should be 0. Then cross-validation will be implemented in the STEP(ii), AutoScore_parsimony_Ordinal().\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_ordinal_small, ratio = c(0.7, 0, 0.3), \n                        cross_validation = TRUE, strat_by_label = TRUE)\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\n\n6.2.1 STEP(i): generate variable ranking list\n\nAutoScore-Ordinal Module 1\n\n\nVariables are ranked by random forest for multiclass classification.\nntree: Number of trees in the random forest algorithm (Default: 100).\n\n\nranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n      Age     Lab_A    Util_D   Vital_A   Vital_F   Vital_E   Vital_D     Lab_B \n98.791839 98.073161 97.021662 93.282141 92.469166 91.677271 82.051893 72.462999 \n    Lab_C    Util_B    Util_C   Vital_C   Vital_B    Util_A  Comorb_A    Gender \n70.507041 57.778464 57.270171 45.468903 43.633031 26.120379 25.414958 13.405373 \n Comorb_B  Comorb_D  Comorb_C  Comorb_E \n 9.595971  7.320633  4.477519  2.993603 \n\n\n\n\n\n\n\n6.2.2 STEP(ii): select the best model with parsimony plot\n\nAutoScore-Ordinal Modules 2+3+4\n\n\nnmin: Minimum number of selected variables (Default: 1).\nnmax: Maximum number of selected variables (Default: 20).\ncategorize: Methods for categorizing continuous variables. Options include \"quantile\" or \"kmeans\" (Default: \"quantile\").\nquantiles: Predefined quantiles to convert continuous variables to categorical ones. (Default: c(0, 0.05, 0.2, 0.8, 0.95, 1)) Available if categorize = \"quantile\".\nmax_cluster: The maximum number of cluster (Default: 5). Available if categorize = \"kmeans\".\nmax_score: Maximum total score (Default: 100).\nauc_lim_min: Minimum y_axis limit in the parsimony plot (Default: 0.5).\nauc_lim_max: Maximum y_axis limit in the parsimony plot (Default: “adaptive”).\ncross_validation: TRUE if cross-validation is needed, especially for small datasets.\nfold: The number of folds used in cross validation (Default: 10). Available if cross_validation = TRUE.\ndo_trace: If set to TRUE, all results based on each fold of cross-validation would be printed out and plotted (Default: FALSE). Available if cross_validation = TRUE.\nlink: link function in the ordinal regression, which affects predictive performance. Options include \"logit\" (for proportional odds model), \"cloglog\" (for proportional hazard model) and \"probit\" (Default: \"logit\").\n\n\n\n\n\n\n\nImportant\n\n\n\nUse the same link parameter throughout descriptive analysis and model building steps.\n\n\n\nlink <- \"logit\"\nmAUC <- AutoScore_parsimony_Ordinal(\n  train_set = train_set, validation_set = validation_set, link = link,\n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  auc_lim_min = 0, auc_lim_max = \"adaptive\",\n  cross_validation = TRUE, fold = 10, do_trace = FALSE\n)\n\n***list of fianl Mean AUC values through cross validation are shown below \n   auc_set.sum\n1    0.4373127\n2    0.5706558\n3    0.6276256\n4    0.6361478\n5    0.6398421\n6    0.6279290\n7    0.6349191\n8    0.6341125\n9    0.6298176\n10   0.6928897\n11   0.6937431\n12   0.6811859\n13   0.6803831\n14   0.6877744\n15   0.7371436\n16   0.7366716\n17   0.7362270\n18   0.7368480\n19   0.7362830\n20   0.7373470\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsers could use mAUC for further analysis or export it to CSV to other software for plotting.\n\n\nwrite.csv(data.frame(mAUC), file = \"mAUC.csv\")\n\n\n\n\nDetermine the optimal number of variables (num_var) based on the parsimony plot obtained in STEP(ii).\nThe final list of variables is the first num_var variables in the ranked list ranking obtained in STEP(i).\nOptional: User can adjust the finally included variables final_variables based on the clinical preferences and knowledge.\n\n\n# Example 1: Top 6 variables are selected\nnum_var <- 6\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 2: Top 14 variables are selected\nnum_var <- 14\nfinal_variables <- names(ranking[1:num_var])\n\n# Example 3: Top 3 variables, the 10th and 15th variable are selected\nfinal_variables <- names(ranking[c(1:3, 10, 15)])\n\n\n\n6.2.3 STEP(iii): generate initial scores with final variables\n\nRe-run AutoScore-Ordinal Modules 2+3\n\n\nGenerate cut_vec with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).\nPerformance of resulting scores is evaluated using the mean AUC across dichotomous classifications (mAUC), with 95% CI computed using bootstrap (Default: n_boot = 100 bootstrap samples). Setting n_boot = 1 disables bootstrap and reports mAUC without CI.\n\n\ncut_vec <- AutoScore_weighting_Ordinal(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, link = link, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  n_boot = 10\n)\n\n****Included Variables: \n  variable_name\n1           Age\n2         Lab_A\n3        Util_D\n4        Util_B\n5      Comorb_A\n****Initial Scores: \n\n\n========  ===========  =====\nvariable  interval     point\n========  ===========  =====\nAge       <27            0  \n          [27,46)       12  \n          [46,78)       21  \n          [78,87)       29  \n          >=87          33  \n                            \nLab_A     <46           13  \n          [46,61)        0  \n          [61,136)       2  \n          [136,608)     10  \n          >=608         12  \n                            \nUtil_D    <0.64          6  \n          [0.64,1.3)     8  \n          [1.3,3.83)     4  \n          [3.83,5.74)    4  \n          >=5.74         0  \n                            \nUtil_B    <1             0  \n          [1,4)         10  \n          >=4           23  \n                            \nComorb_A  0              0  \n          1             23  \n========  ===========  =====\n***Performance (based on validation set):\nmAUC: 0.7440     95% CI: 0.7229-0.7539 (from 10 bootstrap samples)\n***The cutoffs of each variables generated by the AutoScore-Ordinal are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\n\n6.2.4 STEP(iv): fine-tune initial score from STEP(iii)\n\nAutoScore-Ordinal Module 5 & Re-run AutoScore-Ordinal Modules 2+3\n\n\nRevise cut_vec with domain knowledge to update the scoring table (AutoScore-Ordinal Module 5).\nRe-run AutoScore-Ordinal Modules 2+3 to generate the updated scores.\nUsers can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.\n\n\n## For example, we have current cutoffs of continuous variable: Age \n## ==============  ===========  =====\n## variable        interval     point\n## ==============  ===========  =====\n## Age                 <27          0  \n##                     [27,46)      4  \n##                     [46,78)     14  \n##                     [78,87)     18 \n##                     >=87        21 \n\n\nCurrent cutoffs:c(27, 46, 78, 87). We can fine tune the cutoffs as follows:\n\n\n# Example 1: rounding to a nice number\ncut_vec$Age <- c(25, 45, 75, 85)\n\n# Example 2: changing cutoffs according to clinical knowledge or preference \ncut_vec$Age <- c(25, 50, 75, 85)\n\n# Example 3: combining categories\ncut_vec$Age <- c(45, 75, 85)\n\n\nmAUC and 95% bootstrap CI (Default: n_boot = 100 bootstrap samples) are reported after fine-tuning.\nRun time increases with larger n_boot value. Code below uses n_boot = 10 for demonstration.\n\n\ncut_vec$Util_D <- c(2 / 3, 4 / 3, 4, 6)\ncut_vec$Lab_A <- c(45, 60, 135, 595)\ncut_vec$Age <- c(25, 45, 75, 85)\ncut_vec$Vital_A <- c(60, 70, 95, 115)\nscoring_table <- AutoScore_fine_tuning_Ordinal(\n  train_set = train_set, validation_set = validation_set, link = link,\n  final_variables = final_variables, cut_vec = cut_vec, max_score = 100, \n  n_boot = 10\n)\n\n***Fine-tuned Scores: \n\n\n========  ============  =====\nvariable  interval      point\n========  ============  =====\nAge       <25             0  \n          [25,45)         9  \n          [45,75)        20  \n          [75,85)        26  \n          >=85           30  \n                             \nLab_A     <45            14  \n          [45,60)         0  \n          [60,135)        2  \n          [135,595)       9  \n          >=595          11  \n                             \nUtil_D    <0.667          6  \n          [0.667,1.33)    9  \n          [1.33,4)        5  \n          [4,6)           6  \n          >=6             0  \n                             \nUtil_B    <1              0  \n          [1,4)          11  \n          >=4            24  \n                             \nComorb_A  0               0  \n          1              23  \n========  ============  =====\n***Performance (based on Validation Set, after fine-tuning):\nmAUC: 0.7450     95% CI: 0.7341-0.7645 (from 10 bootstrap samples)\n\n\n\n\n6.2.5 STEP(v): evaluate final risk scores on test dataset\n\nAutoScore-Ordinal Module 6\n\n\nmAUC and generalised c-index are reported for the test set, with 95% bootstrap CI (Default: n_boot = 100 bootstrap samples).\nRun time increases with larger n_boot value. Code below uses n_boot = 10 for demonstration.\n\n\npred_score <- AutoScore_testing_Ordinal(\n  test_set = test_set, link = link, final_variables = final_variables, \n  cut_vec = cut_vec, scoring_table = scoring_table, \n  with_label = TRUE, n_boot = 10\n)\n\n***Performance using AutoScore-Ordinal (based on unseen test Set):\nmAUC: 0.7425     95% CI: 0.7281-0.7679 (from 10 bootstrap samples)\nGeneralised c-index: 0.6998      95% CI: 0.6907-0.7225 (from 10 bootstrap samples)\n\nhead(pred_score)\n\n  pred_score Label\n1         25     1\n2         37     1\n3         61     1\n4         36     1\n5         15     1\n6         19     1\n\n\n\n\n6.2.6 Map score to risk\n\nUsers can also map score to risk using plot_predicted_risk() and conversion_table_ordinal(). Please refer to our demo for large sample (6.1.6) for detail."
  },
  {
    "objectID": "06-autoscore_ordinal.html#demo-3-data-with-missing-values",
    "href": "06-autoscore_ordinal.html#demo-3-data-with-missing-values",
    "title": "6  AutoScore for ordinal outcomes (AutoScore-Ordinal)",
    "section": "6.3 Demo 3: data with missing values",
    "text": "6.3 Demo 3: data with missing values\nIn Demo 3, we demonstrate AutoScore-Ordinal for application to data with missing values in two variables (i.e., Vital_A, Vital_B).\n\ncheck_data_ordinal(sample_data_ordinal_missing)\n\nData type check passed. \n\n\n\nWARNING: NA detected in data: -----\n.\n\n\n        Variable name No. missing %missing\nVital_A       Vital_A        4000       20\nVital_B       Vital_B       12000       60\n\n\nSUGGESTED ACTION:\n * Consider imputation and supply AutoScore with complete data.\n * Alternatively, AutoScore can handle missing values as a separate 'Unknown' category, IF:\n    - you believe the missingness in your dataset is informative, AND\n    - missing is prevalent enough that you prefer to preserve them as NA rather than removing or doing imputation, AND\n    - missing is not too prevalent, which may make results unstable.\n\n\nAutoScore can automatically treat the missingness as a new category named Unknown. The following steps are the same as those in Demo 1 (6.1).\n\n\n\n\n\n\nImportant\n\n\n\n\nHigh missing rate may cause the variable ranking less reliable, and thus, caution is needed for variable selection using parsimony plot.\n\n\n\n\nset.seed(4)\nout_split <- split_data(data = sample_data_ordinal_missing, ratio = c(0.7, 0.1, 0.2), \n                        strat_by_label = TRUE)\ntrain_set <- out_split$train_set\nvalidation_set <- out_split$validation_set\ntest_set <- out_split$test_set\n\nlink <- \"logit\"\nranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)\n\nThe ranking based on variable importance was shown below for each variable: \n   Util_D     Lab_A   Vital_F       Age   Vital_E   Vital_A   Vital_D     Lab_B \n425.24001 400.43374 392.73640 386.44000 381.80802 360.50478 355.61072 315.06078 \n    Lab_C    Util_C    Util_B   Vital_C  Comorb_A    Util_A    Gender  Comorb_B \n290.87695 254.94879 207.48694 196.58751 115.91414 101.57517  55.84234  43.89240 \n Comorb_D  Comorb_C  Comorb_E   Vital_B \n 33.75145  17.30841  11.98427   1.16588 \n\n\n\n\nmAUC <- AutoScore_parsimony_Ordinal(\n  train_set = train_set, validation_set = validation_set, link = link,\n  rank = ranking, max_score = 100, n_min = 1, n_max = 20,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  auc_lim_min = 0\n)\n\nSelect 1 variables:  Mean area under the curve: 0.4555607 \nSelect 2 variables:  Mean area under the curve: 0.5110174 \nSelect 3 variables:  Mean area under the curve: 0.5780548 \nSelect 4 variables:  Mean area under the curve: 0.6524352 \nSelect 5 variables:  Mean area under the curve: 0.6579466 \nSelect 6 variables:  Mean area under the curve: 0.675316 \nSelect 7 variables:  Mean area under the curve: 0.6714668 \nSelect 8 variables:  Mean area under the curve: 0.6731644 \nSelect 9 variables:  Mean area under the curve: 0.6709335 \nSelect 10 variables:  Mean area under the curve: 0.671352 \nSelect 11 variables:  Mean area under the curve: 0.6993675 \nSelect 12 variables:  Mean area under the curve: 0.7013214 \nSelect 13 variables:  Mean area under the curve: 0.7473641 \nSelect 14 variables:  Mean area under the curve: 0.7504558 \nSelect 15 variables:  Mean area under the curve: 0.7501569 \nSelect 16 variables:  Mean area under the curve: 0.7495503 \nSelect 17 variables:  Mean area under the curve: 0.7478535 \nSelect 18 variables:  Mean area under the curve: 0.7470084 \nSelect 19 variables:  Mean area under the curve: 0.7468875 \nSelect 20 variables:  Mean area under the curve: 0.7444887 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe Unknown category indicating the missingness will be displayed in the final scoring table.\n\n\n\n\nfinal_variables <- names(ranking[c(1:6)])\ncut_vec <- AutoScore_weighting_Ordinal(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = final_variables, link = link, max_score = 100,\n  categorize = \"quantile\", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), \n  n_boot = 10\n)\n\n****Included Variables: \n  variable_name\n1        Util_D\n2         Lab_A\n3       Vital_F\n4           Age\n5       Vital_E\n6       Vital_A\n****Initial Scores: \n\n\n========  ============  =====\nvariable  interval      point\n========  ============  =====\nUtil_D    <0.652         11  \n          [0.652,1.32)   10  \n          [1.32,3.93)     3  \n          [3.93,5.93)     2  \n          >=5.93          0  \n                             \nLab_A     <46             9  \n          [46,61)         0  \n          [61,134)        1  \n          [134,584)      11  \n          >=584           7  \n                             \nVital_F   <16.7          12  \n          [16.7,20.5)     4  \n          [20.5,25.4)     0  \n          [25.4,28.1)     1  \n          >=28.1          5  \n                             \nAge       <27             0  \n          [27,46)         4  \n          [46,78)        19  \n          [78,87)        25  \n          >=87           30  \n                             \nVital_E   <99            15  \n          [99,112)       10  \n          [112,153)       5  \n          [153,179)       3  \n          >=179           0  \n                             \nVital_A   <57             6  \n          [57,66)         0  \n          [66,99)         5  \n          [99,115)        9  \n          >=116          21  \n          Unknown         6  \n========  ============  =====\n***Performance (based on validation set):\nmAUC: 0.6753     95% CI: 0.6360-0.7193 (from 10 bootstrap samples)\n***The cutoffs of each variables generated by the AutoScore-Ordinal are saved in cut_vec. You can decide whether to revise or fine-tune them"
  }
]
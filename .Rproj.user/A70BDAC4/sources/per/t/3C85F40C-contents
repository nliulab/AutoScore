
##other comparasons:



#random forest itself:
#load("~/MD2.Rdata")
#names(MD2)[50]<-"label"
#BuildScore_out(testdf5_mimic)

# preprocessing:
MD2<-testdf4_mimic
MD2$glucose_max<-ifelse(MD2$glucose_max>3000,170,MD2$glucose_max)
MD2$glucose_mean<-ifelse(MD2$glucose_mean>1000,130,MD2$glucose_mean)

testdf4_mimic<-MD2


##demographic:
library(tableone)
vars<-c("INSURANCE", "heartrate_min", "heartrate_max", "heartrate_mean",
        "sysbp_min", "sysbp_max", "sysbp_mean", "diasbp_min", "diasbp_max",
        "diasbp_mean", "meanbp_min", "meanbp_max", "meanbp_mean", "resprate_min",
        "resprate_max", "resprate_mean", "tempc_min", "tempc_max", "tempc_mean",
        "spo2_min", "spo2_max", "spo2_mean", "glucose_min", "glucose_max",
        "glucose_mean", "aniongap_min", "aniongap_max", "bicarbonate_min",
        "bicarbonate_max", "creatinine_min", "creatinine_max", "chloride_min",
        "chloride_max", "glucose_min.y", "glucose_max.y", "hematocrit_min",
        "hematocrit_max", "hemoglobin_min", "hemoglobin_max", "platelet_min",
        "platelet_max", "potassium_min", "potassium_max", "sodium_min",
        "sodium_max", "bun_min", "bun_max", "wbc_min", "wbc_max", "label"
)

MD_table<-CreateTableOne(vars = vars,strata = "label",data=Dataset)
MD_table_overall<-CreateTableOne(data=Dataset)
MD_table
MD_table_overall



MD_table_train<-CreateTableOne(vars = vars,strata = "DeathLabel",data=trainSet)
MD_table_test<-CreateTableOne(vars = vars,strata = "DeathLabel",data=testSet)
MD_table_train_overall<-CreateTableOne(data=trainSet)
MD_table_test_overall<-CreateTableOne(data=testSet)
MD_table_train
MD_table_train_overall
MD_table_test
MD_table_test_overall




##extract performance data!!!!

for(i in (1:2)){
        Modelroc<-R[[1]][[i]]
        a<-coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                                          "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                                          "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                                          "precision", "recall"))

        v<-c(ci(Modelroc),a[1],a[4],a[3],a[2],a[10],a[9],a[16],R[[2]][i])
        print(v)}






testdf5_mimic<-testdf5_mimic[,c("heartrate_min", "heartrate_max", "sysbp_min",
                 "sysbp_max", "diasbp_min", "diasbp_max",
                 "meanbp_min", "meanbp_max",  "resprate_min", "resprate_max",
                  "tempc_min", "tempc_max", "spo2_min",
                 "spo2_max",  "glucose_min", "glucose_max",
                  "bicarbonate_min", "bicarbonate_max",
                 "creatinine_min", "creatinine_max",
                  "hemoglobin_min", "hemoglobin_max",

                 "potassium_min", "potassium_max", "sodium_min", "sodium_max",
                 "bun_min", "bun_max", "wbc_min", "wbc_max", "Age", "label")]


testdf5_mimic<-testdf5_mimic[,c("heartrate_min", "heartrate_max", "heartrate_mean", "sysbp_min",
                                "sysbp_max", "sysbp_mean", "diasbp_min", "diasbp_max", "diasbp_mean",
                                "meanbp_min", "meanbp_max", "meanbp_mean", "resprate_min", "resprate_max",
                                "resprate_mean", "tempc_min", "tempc_max", "tempc_mean", "spo2_min",
                                "spo2_max", "spo2_mean", "glucose_min", "glucose_max", "glucose_mean",
                                 "bicarbonate_min", "bicarbonate_max",
                                "creatinine_min", "creatinine_max",
                                 "hemoglobin_min", "hemoglobin_max",

                                "potassium_min", "potassium_max", "sodium_min", "sodium_max",
                                "bun_min", "bun_max", "wbc_min", "wbc_max", "Age", "label")]

testdf6_mimic<-testdf5_mimic[,c( "heartrate_max", 
                                "sysbp_max", "diasbp_max", 
                                "meanbp_max",  "resprate_max",
                                 "tempc_max", 
                                "spo2_max",  "glucose_max", 
                                "bicarbonate_max",
                               "creatinine_max",
                                 "hemoglobin_max",
                                
                                 "potassium_max", "sodium_max",
                                
                                "bun_max",  "wbc_max", "Age", "label")]


################final paper score from here
dput(names(testdf5_mimic)[grepl("mean",names(testdf5_mimic))])

testdf5_mimic$aniongap_mean<-rowMeans(cbind(testdf5_mimic$aniongap_min,testdf5_mimic$aniongap_max), na.rm=TRUE)
testdf5_mimic$bicarbonate_mean<-rowMeans(cbind(testdf5_mimic$bicarbonate_min,testdf5_mimic$bicarbonate_max), na.rm=TRUE)
testdf5_mimic$creatinine_mean<-rowMeans(cbind(testdf5_mimic$creatinine_min,testdf5_mimic$creatinine_max), na.rm=TRUE)
testdf5_mimic$chloride_mean<-rowMeans(cbind(testdf5_mimic$chloride_min,testdf5_mimic$chloride_max), na.rm=TRUE)
testdf5_mimic$hematocrit_mean<-rowMeans(cbind(testdf5_mimic$hematocrit_min,testdf5_mimic$hematocrit_max), na.rm=TRUE)
testdf5_mimic$hemoglobin_mean<-rowMeans(cbind(testdf5_mimic$hemoglobin_min,testdf5_mimic$hemoglobin_max), na.rm=TRUE)
testdf5_mimic$lactate_mean<-rowMeans(cbind(testdf5_mimic$lactate_min,testdf5_mimic$lactate_max), na.rm=TRUE)
testdf5_mimic$platelet_mean<-rowMeans(cbind(testdf5_mimic$platelet_min,testdf5_mimic$platelet_max), na.rm=TRUE)
testdf5_mimic$potassium_mean<-rowMeans(cbind(testdf5_mimic$potassium_min,testdf5_mimic$potassium_max), na.rm=TRUE)
testdf5_mimic$bun_mean<-rowMeans(cbind(testdf5_mimic$bun_min,testdf5_mimic$bun_max), na.rm=TRUE)
testdf5_mimic$sodium_mean<-rowMeans(cbind(testdf5_mimic$sodium_min,testdf5_mimic$sodium_max), na.rm=TRUE)
testdf5_mimic$wbc_mean<-rowMeans(cbind(testdf5_mimic$wbc_min,testdf5_mimic$wbc_max), na.rm=TRUE)

save(testdf5_mimic,file="testdf5_mimic.Rdata")

save(testdf5_mimic,s1,file="testdf5_mimic.Rdata")

testdf6_mimic<-testdf5_mimic[,c("Age", "GENDER",  "ETHNICITY","INSURANCE",# "ADMISSION_TYPE","ADMISSION_LOCATION"
                                "heartrate_mean", "sysbp_mean", "diasbp_mean", "meanbp_mean", "resprate_mean", "tempc_mean","spo2_mean", 
                                "glucose_mean", "aniongap_mean", "bicarbonate_mean", "creatinine_mean", 
                                "chloride_mean",   "lactate_mean", "hemoglobin_mean","hematocrit_mean",
                                "platelet_mean", "potassium_mean", "bun_mean", "sodium_mean", 
                                "wbc_mean", "label")]




##intermediate
set.seed(4)
s1<-selectionRF(testdf6_mimic,9)
dput(s1)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)


s2<-selectionRF(testdf6_mimic,12) 
dput(s2)
set.seed(4)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)
set.seed(5)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)
set.seed(238)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)
set.seed(1111)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)
set.seed(8)
s2<-selectionRF(testdf6_mimic,12) 
dput(s2)

#result: no impact


##manual Amendament/fine tuning

a<-min(testdf6_mimic$lactate_mean)-1
b<-max(testdf6_mimic$lactate_mean)+1
testdf6_mimic$lactate_mean<-cut(testdf6_mimic$lactate_mean,breaks = c(a,1,2.5,4,b),right = FALSE)
summary(testdf6_mimic$lactate_mean)

a<-min(testdf6_mimic$tempc_mean)-1
b<-max(testdf6_mimic$tempc_mean)+1
testdf6_mimic$tempc_mean<-cut(testdf6_mimic$tempc_mean,breaks = c(a,36,36.5,37.5,38,b),right = FALSE)
summary(testdf6_mimic$tempc_mean)

a<-min(testdf6_mimic$resprate_mean)-1
b<-max(testdf6_mimic$resprate_mean)+1
testdf6_mimic$resprate_mean<-cut(testdf6_mimic$resprate_mean,breaks = c(a,12,16,22,b),right = FALSE)
summary(testdf6_mimic$resprate_mean)

a<-min(testdf6_mimic$platelet_mean)-1
b<-max(testdf6_mimic$platelet_mean)+1
testdf6_mimic$platelet_mean<-cut(testdf6_mimic$platelet_mean,breaks = c(a,80,150,300,450,b),right = FALSE)
summary(testdf6_mimic$platelet_mean)


a<-min(testdf6_mimic$bun_mean)-1
b<-max(testdf6_mimic$bun_mean)+1
testdf6_mimic$bun_mean<-cut(testdf6_mimic$bun_mean,breaks = c(a,7.5,12,35,70,b),right = FALSE)
summary(testdf6_mimic$bun_mean)

a<-min(testdf6_mimic$spo2_mean)-1
b<-max(testdf6_mimic$spo2_mean)+1
testdf6_mimic$spo2_mean<-cut(testdf6_mimic$spo2_mean,breaks = c(a,85,90,95,b),right = FALSE)
summary(testdf6_mimic$spo2_mean)

a<-min(testdf6_mimic$Age)-1
b<-max(testdf6_mimic$Age)+1
testdf6_mimic$Age<-cut(testdf6_mimic$Age,breaks = c(a,30,48,78,85,b),right = FALSE)
summary(testdf6_mimic$Age)

a<-min(testdf6_mimic$heartrate_mean)-1
b<-max(testdf6_mimic$heartrate_mean)+1
testdf6_mimic$heartrate_mean<-cut(testdf6_mimic$heartrate_mean,breaks = c(a,62,72,98,112,b),right = FALSE)
summary(testdf6_mimic$heartrate_mean)


a<-min(testdf6_mimic$sysbp_mean)-1
b<-max(testdf6_mimic$sysbp_mean)+1
testdf6_mimic$sysbp_mean<-cut(testdf6_mimic$sysbp_mean,breaks = c(a,90,100,130,150,b),right = FALSE)
summary(testdf6_mimic$sysbp_mean)


a<-min(testdf6_mimic$wbc_mean)-1
b<-max(testdf6_mimic$wbc_mean)+1
testdf6_mimic$wbc_mean<-cut(testdf6_mimic$wbc_mean,breaks = c(a,4,8,15,22,b),right = FALSE)
summary(testdf6_mimic$wbc_mean)


#a<-min(testdf6_mimic$bicarbonate_mean)-1
#b<-max(testdf6_mimic$bicarbonate_mean)+1
#testdf6_mimic$bicarbonate_mean<-cut(testdf6_mimic$bicarbonate_mean,breaks = c(a,17,21,28,31,b),right = FALSE)
#summary(testdf6_mimic$bicarbonate_mean)


a<-min(testdf6_mimic$glucose_mean)-1
b<-max(testdf6_mimic$glucose_mean)+1
testdf6_mimic$glucose_mean<-cut(testdf6_mimic$glucose_mean,breaks = c(a,80,160,220,b),right = FALSE)
summary(testdf6_mimic$glucose_mean)

a<-min(testdf6_mimic$bicarbonate_mean)-1
b<-max(testdf6_mimic$bicarbonate_mean)+1
testdf6_mimic$bicarbonate_mean<-cut(testdf6_mimic$bicarbonate_mean,breaks = c(a,17,22,26,31,b),right = FALSE)
summary(testdf6_mimic$bicarbonate_mean)


testdf7_mimic<-testdf6_mimic[,s1]
set.seed(4)
testdf6_mimic_20000<-testdf6_mimic[sample(1:44918,20000),] ##For test and imrpove current methods
testdf7_mimic<-testdf6_mimic[,c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
                                "bun_mean", "spo2_mean", "Age","sysbp_mean", "heartrate_mean", "label")]

testdf8_mimic<-testdf6_mimic[,c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
                                "bun_mean", "spo2_mean", "Age", "sysbp_mean", "heartrate_mean", 
                                "wbc_mean", "glucose_mean", "bicarbonate_mean" , "label")]

c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
  "bun_mean", "spo2_mean", "Age", "sysbp_mean", "heartrate_mean", 
  "wbc_mean", "glucose_mean", "meanbp_mean", "label")
testdf8_mimic<-testdf6_mimic[,s2]

##after through 
#testSet3
#calibratio


glmmodel<-glm(label~TotalScore,data = testSet3,family = binomial(link="logit"))
Score_pred<-predict(glmmodel,newdata=testSet3, type = "response")

glmmodel<-glm(label~TotalScore,data = testSet3,family = binomial(link="logit"))
Score12_pred<-predict(glmmodel,newdata=testSet3, type = "response")

glmmodel<-glm(label~lasso,data = testSet3,family = binomial(link="logit"))
lasso_pred<-predict(glmmodel,newdata=testSet3, type = "response")


glmmodel<-glm(label~RF,data = testSet3,family = binomial(link="logit"))
RF_pred<-predict(glmmodel,newdata=testSet3, type = "response")

glmmodel<-glm(label~full,data = testSet3,family = binomial(link="logit"))
LR_glm_pred<-predict(glmmodel,newdata=testSet3, type = "response")



library(caret)
calPlotData <- calibration(as.factor(testSet3$label) ~ 1-Score_pred, data = testSet3)
plot(calPlotData)
#calPlotData <- calibration(as.factor(testSet3$label) ~ 1-(testSet3$TotalScore-0.5)/117, data = testSet3)
#plot(calPlotData)
calPlotData <- calibration(y_test ~ 1-full)
plot(calPlotData)

calPlotData <- calibration(y_test ~ 1-lasso)
plot(calPlotData)

library(PredictABEL)
plotCalibration(data=testSet3, cOutcome=as.factor(testSet3$label), predRisk=Score_pred, 
                groups=25, rangeaxis=c(0,1))

library(PredictABEL)
plotCalibration(data=testSet3, cOutcome=as.factor(testSet3$label), predRisk=Score_pred, 
                groups=25, rangeaxis=c(0,1))

library(generalhoslem)
logitgof(obs=as.factor(testSet3$label), exp=Score_pred, g = 10, ord = FALSE)
logitgof(obs=y_test, exp=step, g = 25, ord = FALSE)
lipsitz.test(model=glmmodel,g=10)
#################################################################################
library(givitiR)
testSet3_1<-testSet3[testSet3$TotalScore<101,]



cb_AutoScore9 <- givitiCalibrationBelt(o = testSet3$label, e = Score_pred,#(testSet3$TotalScore-0.5)/117,#(log(testSet3$TotalScore,10)/2.1)+0.00001,
                            devel = "internal",confLevels = c(.80,.95))
cb_AutoScore12 <- givitiCalibrationBelt(o = testSet3$label, e = Score12_pred,#(testSet3$TotalScore-0.5)/117,#(log(testSet3$TotalScore,10)/2.1)+0.00001,
                                       devel = "internal",confLevels = c(.80,.95))
cb_LR <- givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =full,
                             devel = "external",confLevels = c(.80,.95))
cb2 <- givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =full,
                             devel = "internal",confLevels = c(.80,.95))
cb_step <- givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =step,
                             devel = "external",confLevels = c(.80,.95))
cb_lasso<-givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =lasso_pred,
                                devel = "internal",confLevels = c(.80,.95))
RF[RF==0]<-0.00001
cb_RF<-givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =RF,
                                devel = "external",confLevels = c(.80,.95))
RF_after[RF_after==0]<-0.00001
cb_RF_after<-givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =RF_after,
                             devel = "external",confLevels = c(.80,.95))

cb_RF_glm<-givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =RF_pred,
                                   devel = "internal",confLevels = c(.80,.95))

cb_LR_glm<-givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =LR_glm_pred,
                                 devel = "internal",confLevels = c(.80,.95))


#cbx <- givitiCalibrationBelt(o = testSet3$label, e = Score_pred,#(testSet3$TotalScore-0.5)/117,#(log(testSet3$TotalScore,10)/2.1)+0.00001,
#                            devel = "external",confLevels = c(.80,.95))


#cb3 <- givitiCalibrationBelt(o = testSet3$label, e = Score_pred,#(testSet3$TotalScore-0.5)/117,#(log(testSet3$TotalScor,10)/2.1)+0.00001,
#                            devel = "internal",confLevels = c(.90,.95))
#cb4 <- givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =step,
#                             devel = "internal",confLevels = c(.90,.95))
#cb2 <- givitiCalibrationBelt(o = as.numeric(as.character(y_test)), e =as.vector((lasso-min(lasso)+0.01)/(max(lasso)-min(lasso)+0.02)),
#                            devel = "external")

#######################################
tiff(filename ="LR.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_LR, main = "Calibration for Full Logistic Regression Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()


tiff(filename ="AutoScore9.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_AutoScore9, main = "Calibration for 9-variable AutoScore Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()


tiff(filename ="AutoScore12.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_AutoScore12, main = "Calibration for 12-variable AutoScore Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

tiff(filename ="RF.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_RF, main = "Calibration for Full Random Forest Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

tiff(filename ="step.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_step, main = "Calibration for Stepwise Regression Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

tiff(filename ="lasso.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_lasso, main = "Calibration for the LASSO Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

tiff(filename ="RFm9.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_RF_after, main = "Calibration for 9-variable Random Forest Model",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

#######################################
tiff(filename ="RF_glm.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_RF_glm, main = "Calibration For the Random Forest Model glm",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()

tiff(filename ="RF_LR_glm.tiff",width = 1200, height = 1200,res=72*3)
plot(cb_LR_glm, main = "Calibration For the LR glm",
     xlab = "Predicted probability",
     ylab = "Observed mortality",polynomialString = F, nString = F,table = T)
dev.off()


########another calirabtion
#testProbs<-data.frame(class=as.factor(1-y_test),score=y_pred)
tiff(filename ="myplot2_AutoScore.tiff",width = 1200, height = 1200,res=72*3)
plot(calibration(as.factor(testSet3$label) ~ 1-Score_pred, data = testSet3),type="o",main="Model Calibration Plot")
dev.off()

testProbs<-data.frame(class=as.factor(1-y_test),score=y_pred)
tiff(filename ="myplot2_LR.tiff",width = 1200, height = 1200,res=72*3)
plot(calibration(y_test ~ 1-full),type="o",main="Model Calibration Plot")
dev.off()





plot(cb1, main = "Calibration For Logistic Regression",
       xlab = "predicted probability",
       ylab = "Observed mortality",width = 1200, height = 1200,res=72*3)

plot(prop.table(table(testSet3$label, testSet3$TotalScore), margin = 2)[2,2:105])


##picture output output
testProbs<-data.frame(class=as.factor(1-y_test),score=y_pred)
tiff(filename ="myplot.tiff",width = 1200, height = 1200,res=72*3)
plot(calibration(class ~ score,data=testProbs),type="o",main="Model Calibration Plot")
dev.off()


tiff(filename ="myplot2.tiff",width = 1200, height = 1200,res=72*3)
ggplot(calibration(class ~ score,data=testProbs),main="Model Calibration Plot")+ggtitle("Model Calibration Plot")
dev.off()


#####for my self calibration oberserved vs Scores
table(testSet3$TotalScore)
ScoreStratify_mean<-tapply(testSet3$label, testSet3$TotalScore,function(x){mean(x,na.rm = T)})
ScoreStratify_sd<-tapply(testSet3$label, testSet3$TotalScore,function(x){sd(x,na.rm = T)})
a<-data.frame(table(testSet3$TotalScore),ScoreStratify_mean,ScoreStratify_sd)
  
####grouping by 5
testSet3$ScoreGroup<-NA
  
for(i in 1:24*5) testSet3$ScoreGroup<- ifelse(testSet3$TotalScore<=i & testSet3$TotalScore>i-5, i,testSet3$ScoreGroup)
ScoreStratify_mean<-tapply(testSet3$label, testSet3$ScoreGroup,function(x){mean(x,na.rm = T)})
ScoreStratify_sd<-tapply(testSet3$label, testSet3$ScoreGroup,function(x){sd(x,na.rm = T)})
b<-data.frame(table(testSet3$ScoreGroup),ScoreStratify_mean,ScoreStratify_sd)


testSet3


qplot(c(1:105),ScoreStratify,
      geom = c("point","smooth"),method="loess",span=0.05) +scale_x_continuous(breaks = seq(0,110,10))



###after testset3 evaluation

PlotROCCurve(testSet3$TotalScore,as.numeric(y_test)-1)
print("Performance using AutoScore (out of sample validation):")
Modelroc<-roc(y_test,testSet3$TotalScore,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(Modelroc$auc)
#print(auc(Modelroc)) ##update
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold",best.method="closest.topleft"))
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
print(coords(Modelroc, "local maximas", ret="threshold"))
print(coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                              "npv", "ppv", "precision")))
set.seed(4)
ci.coords(Modelroc,x=30 ,input="threshold", ret=c( "sensitivity","specificity", "accuracy",
                                           "npv", "ppv", "precision"))
set.seed(4)
ci.coords(Modelroc,x=29.5 ,input="threshold", ret=c( "sensitivity","specificity", "accuracy",
                                                   "npv", "ppv", "precision"))
##Formal codes: After ROC
#9-variable Score
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
print(coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                               "ppv","npv", "precision")))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=48 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=30 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=64 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
w<-rbind(r1,r2,r3)


#12-variable Score
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
print(coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                              "ppv","npv", "precision")))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=48 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=30 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=64 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
w2<-rbind(r1,r2,r3)



#12-variable Score
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
print(coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                              "ppv","npv", "precision")))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=130 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=95 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=180 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
w2<-rbind(r1,r2,r3)

#LR full
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
a<-coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                              "ppv","npv", "precision"))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=0.085 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                 "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=0.028 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=0.24 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                 "ppv", "npv" )))
w3<-rbind(r1,r2,r3)

#step 
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
a<-coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                           "ppv","npv", "precision"))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=0.096 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=0.028 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=0.24 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                  "ppv", "npv" )))
w4<-rbind(r1,r2,r3)


#lasso 
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
a<-coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                           "ppv","npv", "precision"))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=-2.47 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=-3.34 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=-1.27 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                  "ppv", "npv" )))
w5<-rbind(r1,r2,r3)


#RF
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
a<-coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                           "ppv","npv", "precision"))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=0.115 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=0.025 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=	0.285 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
w7<-rbind(r1,r2,r3)


#RF after
set.seed(4)
print(ci(Modelroc))
print(Modelroc$auc)
#check best cutoff and local max
print(coords(Modelroc, "best", ret="threshold",best.method=c("youden", "closest.topleft")))
a<-coords(Modelroc, "local maximas", ret=c("threshold", "sensitivity","specificity", "accuracy",
                                           "ppv","npv", "precision"))
#CI one by one
r1<-reshapedf(ci.coords(Modelroc,x=0.085 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r2<-reshapedf(ci.coords(Modelroc,x=0.015 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
r3<-reshapedf(ci.coords(Modelroc,x=0.3 ,input="threshold", ret=c("accuracy", "sensitivity","specificity" ,
                                                                   "ppv", "npv" )))
w6<-rbind(r1,r2,r3)

#little function
reshapedf<-function(w1){
df<-data.frame(w1)[1,]
for(i in 2:5){
  df<-cbind(df,data.frame(w1)[i,])
}
print(df)
}  



#---------------
AutoScore_validation_same(testdf7_mimic)
AutoScore_validation_same(testdf8_mimic)

#support vector machine
library(AutoScore)
data<-Preprocess(testdf6_mimic,outcome = "label")
AutoScore(testdf6_mimic,n=9)
AutoScore_insample(data,n=9)
AutoScore_validation(testdf6_mimic,n=6)
AutoScore_validation(testdf6_mimic,n=9)
AutoScore_validation(testdf6_mimic,n=12)
#divide data into training(70%),validation(10%) and test(20%) set
AutoScore_validation_range(testdf6_mimic,nmin=1,nmax=20)
AutoScore_validation_range_test(testdf6_mimic,nmin=1,nmax=20)

testdf6_mimic<-testdf5_mimic[,c("Age", "GENDER",  "ETHNICITY","INSURANCE",# "ADMISSION_TYPE","ADMISSION_LOCATION"
                                "heartrate_mean", "sysbp_mean", "diasbp_mean", "meanbp_mean", "resprate_mean", "tempc_mean","spo2_mean", 
                                "glucose_mean", "aniongap_mean", "bicarbonate_mean", "creatinine_mean", 
                                "chloride_mean",   "lactate_mean", "hemoglobin_mean","hematocrit_mean",
                                "platelet_mean", "potassium_mean", "bun_mean", "sodium_mean", 
                                "wbc_mean", "label")]
################################################################
##IQR
library(tableone)
contVars<-c("Age", "heartrate_mean", 
        "sysbp_mean", "diasbp_mean", "meanbp_mean", "resprate_mean", 
        "tempc_mean", "spo2_mean", "glucose_mean", "aniongap_mean", "bicarbonate_mean", 
        "creatinine_mean", "chloride_mean", "lactate_mean", "hemoglobin_mean", 
        "hematocrit_mean", "platelet_mean", "potassium_mean", "bun_mean", 
        "sodium_mean", "wbc_mean")
contTableOverall <- CreateContTable(vars = contVars, data = testdf6_mimic, #strata = "label",
                                    funcNames = c("median", "p25", "p75"))
summary(contTableOverall)

contTableOverall <- CreateContTable(vars = contVars, data = testdf6_mimic, strata = "label",
                                    funcNames = c("n", "miss", "p.miss", "mean", "sd", "median", "p25", "p75", "min","max", "skew", "kurt"))


catVars<-c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
  "bun_mean", "spo2_mean", "Age", "sysbp_mean", "heartrate_mean", 
  "wbc_mean", "glucose_mean", "bicarbonate_mean" , "label")

catTableOverall <- CreateCatTable(vars = catVars, data = testdf6_mimic )
summary(catTableOverall)

catTableOverallbefore <- CreateCatTable(vars = catVars, data = rbind(SD2,testSet2) )
summary(catTableOverallbefore)


##collect data for plotting in python

Dataset<-testdf6_mimic
library(pROC)
library(randomForest)
library(ggplot2)

set.seed(4)
testindex<-sample((1:length(Dataset[,1])),round(length(Dataset[,1])*0.2))
MD3<-Dataset[-testindex,]
testSet<-Dataset[testindex,]
y_test<-testSet$label
#1. full model
model <- glm(label ~., family = binomial(link="logit"), data = MD3)
PlotROCCurve(predict(model,newdata=testSet, type = "response"),as.numeric(y_test)-1)
y_pred<-predict(model,newdata=testSet, type = "response")
full<-y_pred
Modelroc<-roc(y_test,full,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(auc(Modelroc))
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold"))
print("Other Performance indicators based on this cutoff: ")
print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                     "npv", "ppv", "precision")))
#2. stepwise best
names(MD3)<-gsub("\\.","_",names(MD3))
names(testSet)<-gsub("\\.","_",names(testSet))
MD4<-MD3
for(i in 1:(length(MD4)-1)){
        if(is.factor(MD4[,i]))
                names(MD4)[i]<-paste(names(MD4)[i],".",sep = "")
}


##delete redundent information
UniTbale<-Uni_glmTable(MD4)
print(UniTbale)
UniTable_sig<-UniTbale[UniTbale$V4<0.1,]
seq<-gsub("\\..*","",c(rownames(UniTable_sig),"label"))
MD4<-MD3[,seq]
seq<-gsub("\\..*","",names(MD4))
MD4<-MD4[,seq]


null1 <- glm(label ~1, family = binomial(link="logit"), data = MD4)
full1 <- glm(label ~., family = binomial(link="logit"), data = MD4)
ModelStep1<-step(full1, scope = list(lower=null1), data = MD4, direction = "backward", trace = F)
print(coef(ModelStep1))
print(length(coef(ModelStep1)))


PlotROCCurve(predict(ModelStep1,newdata=testSet, type = "response"),as.numeric(y_test)-1)
y_pred<-predict(ModelStep1,newdata=testSet, type = "response")

step<-y_pred

Modelroc<-roc(y_test,step,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(auc(Modelroc))
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold"))
print("Other Performance indicators based on this cutoff: ")
print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                     "npv", "ppv", "precision")))


#3.lasso best
x <- model.matrix(label ~ ., MD3)[, -1]
y <- MD3$label

library("glmnet")
# glmnet with alpha=1 means LASSO
lasso.mod <- glmnet(x, y, alpha=1,family = "binomial")
plot(lasso.mod, xvar="lambda", label=TRUE)


# CV for optimal lambda
set.seed(1)
lasso.cv <- cv.glmnet(x, y, alpha=1,family = "binomial")
plot(lasso.cv)

# optimal lambda
lasso.lam <- lasso.cv$lambda.min
log(lasso.lam)
points(log(lasso.lam), min(lasso.cv$cvm), cex=3)


#### alternatively, set optimal lambda to lambda.1se for a more parsimonious model ####
lasso.lam2 <- lasso.cv$lambda.1se
log(lasso.lam2)
min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)]
points(log(lasso.lam2), min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)], cex=3)

# plot optimal lambda
plot(lasso.mod, xvar="lambda", label = TRUE)
abline(v=log(lasso.lam), lty=2)
abline(v=log(lasso.lam2), lty=2)


d<-predict(lasso.cv, type="coefficient", s=lasso.lam2)
d@Dimnames[[1]][d@i]

##testset
xtest <- model.matrix(label ~ ., testSet)[, -1]
ytest <- testSet$label


y_pred<-predict(lasso.cv, s=lasso.lam2, newx=xtest,family = "binomial")
PlotROCCurve(y_pred,as.numeric(y_test)-1)


lasso<-y_pred
Modelroc<-roc(y_test,lasso,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(Modelroc$auc)
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold"))
print("Other Performance indicators based on this cutoff: ")
print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                     "npv", "ppv", "precision")))


##RF: before selection
set.seed(555)
model <- randomForest(label~., data=MD3,ntree=100,mtry=5)
                     # , preProcess="scale")

#PlotROCCurve(predict(model,newdata=testSet, type = "response"),as.numeric(y_test)-1)
y_pred<-predict(model,newdata=testSet, type="prob")
RF<-y_pred[,2]
Modelroc<-roc(y_test,RF,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(auc(Modelroc))
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold"))
print("Other Performance indicators based on this cutoff: ")
print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                     "npv", "ppv", "precision")))    

#importance <- importance(model, scale = T)


##after selection
MD4<-MD3[,c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
            "bun_mean", "spo2_mean", "Age","sysbp_mean", "heartrate_mean", "label")]
MD4<-MD3[,c("lactate_mean", "tempc_mean", "platelet_mean", "resprate_mean", 
            "bun_mean", "spo2_mean", "Age", "sysbp_mean", "heartrate_mean", 
            "wbc_mean", "glucose_mean", "bicarbonate_mean" , "label")]
set.seed(555)
model <- randomForest(label~., data=MD4,ntree=100,mtry=3)

#PlotROCCurve(predict(model,newdata=testSet, type = "response"),as.numeric(y_test)-1)
y_pred<-predict(model,newdata=testSet, type = "prob")
RF_after<-y_pred[,2]
Modelroc<-roc(y_test,RF_after,auc = T,ci=T)
print("AUC:")
print(ci(Modelroc))
print(auc(Modelroc))
print("The best cutoff of using this score：")
print(coords(Modelroc, "best", ret="threshold"))
print("Other Performance indicators based on this cutoff: ")
print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                     "npv", "ppv", "precision")))                                
##








#4. AutoScore_same

  
  library(pROC)
  library(randomForest)
  library(ggplot2)
  Dataset<-testdf7_mimic
  Dataset<-testdf8_mimic
  
  #1.divide data into training(80%) and test(20%) set
  set.seed(4)
  testindex<-sample((1:length(Dataset[,1])),round(length(Dataset[,1])*0.2))
  MD3<-Dataset[-testindex,]
  testSet<-Dataset[testindex,]
  y_test<-testSet$label
  
  
  #2.Random Forest Selection
  #s<-selectionRF(MD3,n)
  SD<-MD3
  testSet1<-testSet
  print("The selected variables for score generation are shown below")
  print(names(SD))
  
  
  # 3. cut numeric and transfer categories
  SDlist<-Dftransform(SD,testSet1)
  SD2<-SDlist[[1]]
  testSet2<-SDlist[[2]]
  #str(SD2)
  #str(testSet2)
  
  # 4.  multivariable analysis after
  
  model <- glm(label~., family = binomial(link="logit"), data = SD2)
  y_test<-testSet2$label
  
  # 5. Build ScoreAE
  coefVec<-coef(model)
  SD2<-ChangeRef(SD2,coefVec)
  model <- glm(label ~., family = binomial(link="logit"), data = SD2)
  #print(model)
  #summary(model)
  coefVec<-coef(model)
  a<-round(coefVec/min(coefVec[-1]))
  myvec<-AddBaseline(SD2,a)
  print("The generated Scores are shown below")
  print(as.data.frame(myvec))
  
  
  # 6.Auto test and  performance
  testSet3<-AutoTest(testSet2,myvec)
  testSet3$TotalScore<-rowSums(subset(testSet3,select=-label))
  y_test<-testSet3$label
  PlotROCCurve(testSet3$TotalScore,as.numeric(y_test)-1)
  
  print("Performance using AutoScore (out of sample validation):")
  Modelroc<-roc(y_test,testSet3$TotalScore,auc = T,ci=T)
  print("AUC:")
  print(ci(Modelroc))
  print(Modelroc$auc) ##update
  print("The best cutoff of using this score??????")
  print(coords(Modelroc, "best", ret="threshold"))
  print("Other Performance indicators based on this cutoff: ")
  print(coords(Modelroc, "best", ret=c("specificity", "sensitivity", "accuracy",
                                       "npv", "ppv", "precision")))
  





#~~~~~~~~~~~~~~~

dp<-data.frame(full,step,lasso,testSet3$TotalScore,y_test)
dp1<-na.omit(dp)

write.csv(dp1,file = "dp.csv")











#multi Table
model <- glm(label ~., family = binomial(link="logit"), data = MD3)
b<-cbind(exp(cbind(OR = coef(model), confint.default(model))),summary(model)$coef[, "Pr(>|z|)"])
b<-b[!grepl("Intercept", row.names(b),ignore.case = T),]
b<-round(b,digits = 3)
b<-as.data.frame(b)
b$OR<-paste(b$OR,"(",b$`2.5 %`,"-",b$`97.5 %`,")", sep = "")





Dataset<-testdf5_mimic
set.seed(4)
testindex<-sample((1:length(Dataset[,1])),round(length(Dataset[,1])*0.2))
MD3<-Dataset[-testindex,]
testSet<-Dataset[testindex,]
y_test<-testSet$label

#lasso:
### The Lasso

x <- model.matrix(label ~ ., MD3)[, -1]
y <- MD3$label

library("glmnet")
# glmnet with alpha=1 means LASSO
lasso.mod <- glmnet(x, y, alpha=1,family = "binomial")
plot(lasso.mod, xvar="lambda", label=TRUE)


# CV for optimal lambda
set.seed(1)
lasso.cv <- cv.glmnet(x, y, alpha=1,family = "binomial")
plot(lasso.cv)

# optimal lambda
lasso.lam <- lasso.cv$lambda.min
log(lasso.lam)
points(log(lasso.lam), min(lasso.cv$cvm), cex=3)


#### alternatively, set optimal lambda to lambda.1se for a more parsimonious model ####
lasso.lam2 <- lasso.cv$lambda.1se
log(lasso.lam2)
min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)]
points(log(lasso.lam2), min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)], cex=3)

# plot optimal lambda
plot(lasso.mod, xvar="lambda", label = TRUE)
abline(v=log(lasso.lam), lty=2)
abline(v=log(lasso.lam2), lty=2)


lasso.lam3<-2.718^-3.8
log(lasso.lam3)

# final model and performance
predict(lasso.cv, type="coefficient", s=lasso.lam3)
d<-data.frame(predict(lasso.cv, type="coefficient", s=lasso.lam3))
d@Dimnames[[1]][d@i]

##testset
xtest <- model.matrix(label ~ ., testSet)[, -1]
ytest <- testSet$label


y_pred<-predict(lasso.cv, s=lasso.lam3, newx=xtest,family = "binomial")
PlotROCCurve(y_pred,as.numeric(y_test)-1)
print("1. lasso:")
Modelroc<-roc(y_test,as.vector(y_pred),auc = T,ci=T)
print(ci(Modelroc))
print(auc(Modelroc))
coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                               "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                               "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                               "precision", "recall"))
a<-coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                                  "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                                  "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                                  "precision", "recall"))

v<-c(ci(Modelroc),a[1],a[4],a[3],a[2],a[10],a[9],a[16])
v



#random forest itself:
model <- randomForest(label~., data=MD3
                      , preProcess="scale")

y_pred<-predict(model,newdata=testSet,type = "prob")[,2]
PlotROCCurve(y_pred,as.numeric(y_test)-1)
print("Random forest:")
Modelroc<-roc(y_test,y_pred,auc = T,ci=T)
print(ci(Modelroc))
print(auc(Modelroc))
coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                               "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                               "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                               "precision", "recall"))
a<-coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                                  "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                                  "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                                  "precision", "recall"))

v<-c(ci(Modelroc),a[1],a[4],a[3],a[2],a[10],a[9],a[16])
v




#random forest after selection:

model <- randomForest(label~., data=MD3[,c("sysbp_min","spo2_mean","spo2_min","tempc_mean", "sysbp_mean" ,
                                           "resprate_mean" ,"bun_min","tempc_min","platelet_min","meanbp_min" ,"aniongap_min","tempc_max","label")]
                      , preProcess="scale")

y_pred<-predict(model,newdata=testSet,type = "prob")[,2]
PlotROCCurve(y_pred,as.numeric(y_test)-1)
print("Random forest:")
Modelroc<-roc(y_test,y_pred,auc = T,ci=T)
print(ci(Modelroc))
print(auc(Modelroc))
coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                               "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                               "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                               "precision", "recall"))
a<-coords(Modelroc, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                                  "tn", "tp", "fn", "fp", "npv", "ppv", "1-specificity",
                                  "1-sensitivity", "1-accuracy", "1-npv", "1-ppv",
                                  "precision", "recall"))

v<-c(ci(Modelroc),a[1],a[4],a[3],a[2],a[10],a[9],a[16])
v



###demo sample code:
#dependent package: tableone, caret,"glmnet",pROC,randomForest,ggplot2,ROCR

install.packages("D:/Document/Project_AutoScore/Project_development/AutoScore_0.1.0.zip", repos = NULL, type = "win.binary")
library(AutoScore)

load("D:/Document/Project_AutoScore/Project_development/First_Out/testdata1_mimic(testData).Rdata")
load("D:/Document/Project_AutoScore/Rdata/testdf_mimic_scoregenerator.Rdata")

data<-Preprocess(testdf1_mimic,outcome = "label")
tableone(data)
UniVariable(data)
MultiVariable(data)
stepwise(data)
lasso(data)

AutoScore(data,n=9)
AutoScore_insample(data,n=9)
AutoScore_validation(data,n=8)
AutoScore_validation(data,n=12)
#divide data into training(70%),validation(10%) and test(20%) set
AutoScore_validation_range(data,nmin=1,nmax=20)









####################################
#From Shu_ling that is Children ED data
####################################
ChildEDdata <- read.csv("D:/XIEFENG/AMIA_AutoScore/ChildrenEMERGENCY/Copy of Deidentified Patient Enrolment and Data Log_21022020_nolab.csv")
ChildEDdata$Age..in.days.<-as.numeric(as.character(ChildEDdata$Age..in.days.))
ChildEDdata$Gender<-NULL
ChildEDdata$Prematurity<-NULL
data<-Preprocess(ChildEDdata, outcome = "SI")


AutoScore_validation_range_test(data,nmin=1,nmax=20)

for(i in 5:14){
        print("Select the number of Variables")
        print(i)
        AutoScore_validation(data,n=i)   
        
}



#UniVariable(testdf1_mimic)
#MultiVariable(testdf1_mimic)
#lasso(testdf1_mimic)
#stepwise(testdf1_mimic)



###heatmap plotting
data <- as.matrix(SelectionHeatmapPlot[,2:6])
row.names(data)<-SelectionHeatmapPlot[,1]
# No dendrogram nor reordering for neither column or row
heatmap(data, Colv = NA, Rowv = NA,scale = "none")




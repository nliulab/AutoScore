sample_data<-FD2
set.seed(4)
#sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
summary(sample_data$base_excess_median)
plot(sample_data$base_excess_median)
num_var <- 5
final_variables <- names(ranking[c(1:num_var)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
#cut_vec$ph_median <- c(7.35, 7.4)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
pred_score <- AutoScore_testing(test_set, final_variables, cut_vec, scoring_table, threshold = "best", with_label = TRUE)
head(pred_score)
print_roc_performance(pred_score$Label, pred_score$pred_score, threshold = 50)
rank = ranking
mean(is.na(sample_data$base_excess_median))
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
AUC <- c()
i<-6
cat(paste("Select",i,"Variable(s):  "))
variable_list<-names(rank)[1:i]
train_set_1 <- train_set[, c(variable_list, "label")]
validation_set_1 <- validation_set[, c(variable_list, "label")]
model_roc<-compute_auc_val(train_set_1, validation_set_1,variable_list, categorize, quantiles, max_cluster, max_score)
compute_auc_val
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
compute_auc_val
model_roc<-compute_auc_val(train_set_1, validation_set_1,variable_list, categorize, quantiles, max_cluster, max_score)
categorize = "quantile"
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
do_trace = FALSE
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
max_score = 100,
max_score = 100
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
#source('D:/Document/GitHub/AutoScore_Improvement/AutoScore_TBP/AutoScore_new.R')
library(pROC)
library(randomForest)
library(ggplot2)
library(tableone)
library(knitr)
#source('D:/Document/GitHub/AutoScore_Improvement/AutoScore_TBP/AutoScore_new.R')
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
View(train_set_1)
View(validation_set)
View(validation_set_1)
mean(is.na(validation_set_1$base_excess_median))
cut_vec <- get_cut_vec(train_set_1, categorize = categorize, quantiles = quantiles, max_cluster = max_cluster)
train_set_2 <- transform_df_fixed(train_set_1, cut_vec)
validation_set_2 <- transform_df_fixed(validation_set_1, cut_vec)
View(validation_set_2)
View(validation_set_1)
View(train_set_1)
transform_df_fixed
df<-validation_set_1
i<-6
floor(min(df[, i]))*0.8
floor(min(df[, i]))
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 20,
cross_validation = TRUE,
categorize = "quantile",
fold = 10,
quantiles = c(0, 0.25, 0.5, 0.75, 1), #c(0, 0.05, 0.2, 0.8, 0.95, 1)
do_trace = FALSE
)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
num_var <- 5
final_variables <- names(ranking[c(1:num_var)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
cut_vec$lactate_median <- c(15)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
cut_vec$ph_median <- c(7.25)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
load("D:/Document/Project_AutoScore_validation/data_big.RData")
data <- read.csv("C:/Users/XFE/Downloads/numeric_steroid_mv_demo_final_0519_2.csv", stringsAsFactors=TRUE)
colSums(is.na(data ))
q<-colSums(is.na(data ))/length(data [,1])
#deteling
data1<-data[,q<0.68]
#check density and outlier!!Good checker
par(mfrow=c(5,5))
i<-1
plot(density(data1[,i],na.rm=T),main=names(data1)[i])
print(names(data1)[i])
i<-i+1
data1$calcium_first[data1$calcium_first>50]<-NA
data1$calcium_median[data1$calcium_median>50]<-NA
data1$magnesium_first[data1$magnesium_first>50]<-NA
data1$magnesium_median[data1$magnesium_median>50]<-NA
data1$ph_first[data1$ph_first>10]<-NA
data1$ph_median[data1$ph_median>10]<-NA
data1$phosphorus_first[data1$phosphorus_first>20]<-NA
data1$phosphorus_median[data1$phosphorus_median>20]<-NA
sele_sa<-data1$sao2_median>2
sele_sa[is.na(sele_sa)]<-FALSE
data1$sao2_median[sele_sa] <-data1$sao2_median[sele_sa]/100
sele_sa<-data1$sao2_first>2
sele_sa[is.na(sele_sa)]<-FALSE
data1$sao2_first[sele_sa] <-data1$sao2_first[sele_sa]/100
data1$mortality_2d<-data1$dateofdeath<8.64e+7*2
data1$mortality_2d[is.na(data1$mortality_2d)]<-FALSE
summary(data1$mortality_2d)
data1$mortality_3d<-data1$dateofdeath<8.64e+7*3
data1$mortality_3d[is.na(data1$mortality_3d)]<-FALSE
summary(data1$mortality_3d)
data1$mortality_7d<-data1$dateofdeath<8.64e+7*7
data1$mortality_7d[is.na(data1$mortality_7d)]<-FALSE
summary(data1$mortality_7d)
data1$mortality_14d<-data1$dateofdeath<8.64e+7*14
data1$mortality_14d[is.na(data1$mortality_14d)]<-FALSE
summary(data1$mortality_14d)
data1$mortality_icu<-data1$destination=="Overleden"
summary(data1$mortality_icu)
data1$label<-data1$mortality_3d
data1$label<-data1$mortality_icu
data_first<-data1[,c("INR_first", "alkaline_phosphatase_first",
"base_excess_first", "calcium_first", "chloride_first", "creatinine_first",
"diastolic_blood_pressure_first", "glucose_first", "hco3_first",
"heart_rate_first", "hematocrit_first", "lactate_first", "magnesium_first",
"mean_arterial_blood_pressure_first", "pao2_first", "pco2_first",
"ph_first", "phosphorus_first", "potassium_first", "sao2_first",
"sodium_first", "systolic_blood_pressure_first", "temperature_first",
"steroid_t_or_f", "mv_t_or_f", "gender",
"agegroup", "label" )]
FD2<-data_first
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
library(caret)
preProcValues <- preProcess(FD2, method = c("medianImpute"))
FD2<- predict(preProcValues, FD2)
#library('RANN')
colSums(is.na(FD2))/length(FD2[,2])
str(FD2)
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
set.seed(4)
sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
data1$label<-data1$mortality_icu
data_first<-data1[,c("INR_first", "alkaline_phosphatase_first",
"base_excess_first", "calcium_first", "chloride_first", "creatinine_first",
"diastolic_blood_pressure_first", "glucose_first", "hco3_first",
"heart_rate_first", "hematocrit_first", "lactate_first", "magnesium_first",
"mean_arterial_blood_pressure_first", "pao2_first", "pco2_first",
"ph_first", "phosphorus_first", "potassium_first", "sao2_first",
"sodium_first", "systolic_blood_pressure_first", "temperature_first",
"steroid_t_or_f", "mv_t_or_f", "gender",
"agegroup", "label" )]
FD2<-data_first
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
library(caret)
preProcValues <- preProcess(FD2, method = c("medianImpute"))
FD2<- predict(preProcValues, FD2)
#library('RANN')
colSums(is.na(FD2))/length(FD2[,2])
str(FD2)
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
set.seed(4)
sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])
# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])
# Example 3: Top 6 variables, the 9th and 10th variable are selected
num_var <- 5
final_variables <- names(ranking[c(1:num_var, 17, 18)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])
# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])
# Example 3: Top 6 variables, the 9th and 10th variable are selected
num_var <- 5
final_variables <- names(ranking[c(1:num_var, 13, 14)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
load("D:/NBoxDocuments2/EDData/XieFeng201902/Projects_XF/Diagnosis and CD (DL)/preventable Death.Rdata.RData")
load("D:/NBoxDocuments2/EDData_SERP/CodeForPaperFormation/SERP5_tableGeneration_runing.RData")
load("D:/NBoxDocuments2/EDData_SERP/CodeForPaperFormation/SERP_clinical_tableGeneration_runing.RData")
load("D:/NBoxDocuments2/EDData_SERP/CodeForPaperFormation/SERP_clinical_tableGeneration_runing (OriginalSERP).RData")
TestSet_PACS3_die
View(TestSet_PACS3_die)
CMultable
CUnitable
CUnitable
CUnitable<-Uni_glmTable(CD4)
CMultable<-Multi_glmTable(CD4)
Multi_Table<-function(model){
b<-cbind(exp(cbind(OR = coef(model), confint.default(model))),summary(model)$coef[, "Pr(>|t|)"])
b<-b[!grepl("Intercept", row.names(b),ignore.case = T),]
b<-round(b,digits = 64)
b<-as.data.frame(b)
b$OR<-paste(b$OR,"(",b$`2.5 %`,"-",b$`97.5 %`,")", sep = "")
return(b)
}
Multi_Table_glm<-function(model){
b<-cbind(exp(cbind(OR = coef(model), confint.default(model))),summary(model)$coef[, "Pr(>|z|)"])
b<-b[!grepl("Intercept", row.names(b),ignore.case = T),]
b<-round(b,digits = 64)
b<-as.data.frame(b)
b$OR<-paste(b$OR,"(",b$`2.5 %`,"-",b$`97.5 %`,")", sep = "")
return(b)
}
CUnitable<-Uni_glmTable(CD4)
CMultable<-Multi_glmTable(CD4)
CUnitable<-Uni_glmTable(CD4)
CMultable<-Multi_glmTable(CD4)
CD4<-CD3[CD3$TriageClass=="P3 and P4",]
CD4$TriageClass<-NULL
CUnitable<-Uni_glmTable(CD4)
CMultable<-Multi_glmTable(CD4)
load("D:/Document/Project_AutoScore_Survival/Auto_Survival_new_FinalPaper_4.8 (final2tryiauc).RData")
AUC_all_tmp
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
d<-sapply(AUC_all_tmp,function(x)sd(x)/sqrt(length(x)))
up<-round(m+1.96*d,3)
down<-round(m-1.96*d,3)
result<-paste0(round(m,3)," (",down,"-",up,")")
result
quantile(AUC_all_tmp,0.025)
ï¼Ÿquantile
'/quantile
'/quantil'
?quantile
quantile(AUC_all_tmp)
sapply(AUC_all_tmp,quantile())
sapply(AUC_all_tmp,quantile())
sapply(AUC_all_tmp,quantile())
?sapply
sapply(AUC_all_tmp,quantile)
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025,0.5,0.975)})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025,0.5,0.975))})
marker
marker
View(TestData)
AUC_all<-data.frame(iAUC=0,C_index=0)
AUC_all<-data.frame(iAUC=0,C_index=0)
for(i in 1:100){
index<-sample(1:8983,8983,replace = TRUE)
Val_tmp<-TestSet[index,]
marker_tmp <- marker[index]
AUC<-c()
#1. iAUC_uno +
Surv.rsp.new <- Surv(Val_tmp$time, Val_tmp$status)
#iAUC
km_fit_test <- survfit(Surv.rsp.new ~ 1, data = Val_tmp)
km_time<-summary(km_fit_test)$time
km_survival<-summary(km_fit_test)$surv
km_time<-km_time[-length(km_time)]
km_survival<-km_survival[-length(km_survival)]
AUC_uno <- AUC.uno(Surv.rsp.new, Surv.rsp.new, lpnew = marker_tmp, times = km_time)
#iAUC<-IntAUC(AUC_uno$auc,AUC_uno$times,km_survival,90,auc.type = "cumulative")
km_survival_w<-c(1,km_survival[-length(km_survival)])
km_survival_sum<-sum(km_survival_w-km_survival)
weight<-(km_survival_w-km_survival)/km_survival_sum
iAUC<-sum(weight*AUC_uno$auc)
AUC<- c(AUC,iAUC)
AUC_all<-rbind(AUC_all,AUC)}
AUC_all_tmp<-AUC_all
AUC_all_tmp<-AUC_all_tmp[-1,]
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
d<-sapply(AUC_all_tmp,function(x)sd(x)/sqrt(length(x)))
up<-round(m+1.96*d,3)
down<-round(m-1.96*d,3)
result<-paste0(round(m,3)," (",down,"-",up,")")
names(result)<-names(AUC_all)
library(survAUC)
library(survival)
AUC_all<-data.frame(iAUC=0,C_index=0)
for(i in 1:100){
index<-sample(1:8983,8983,replace = TRUE)
Val_tmp<-TestSet[index,]
marker_tmp <- marker[index]
AUC<-c()
#1. iAUC_uno +
Surv.rsp.new <- Surv(Val_tmp$time, Val_tmp$status)
#iAUC
km_fit_test <- survfit(Surv.rsp.new ~ 1, data = Val_tmp)
km_time<-summary(km_fit_test)$time
km_survival<-summary(km_fit_test)$surv
km_time<-km_time[-length(km_time)]
km_survival<-km_survival[-length(km_survival)]
AUC_uno <- AUC.uno(Surv.rsp.new, Surv.rsp.new, lpnew = marker_tmp, times = km_time)
#iAUC<-IntAUC(AUC_uno$auc,AUC_uno$times,km_survival,90,auc.type = "cumulative")
km_survival_w<-c(1,km_survival[-length(km_survival)])
km_survival_sum<-sum(km_survival_w-km_survival)
weight<-(km_survival_w-km_survival)/km_survival_sum
iAUC<-sum(weight*AUC_uno$auc)
AUC<- c(AUC,iAUC)
AUC_all<-rbind(AUC_all,AUC)}
AUC_all_tmp<-AUC_all
AUC_all_tmp<-AUC_all_tmp[-1,]
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
d<-sapply(AUC_all_tmp,function(x)sd(x)/sqrt(length(x)))
up<-round(m+1.96*d,3)
down<-round(m-1.96*d,3)
result<-paste0(round(m,3)," (",down,"-",up,")")
names(result)<-names(AUC_all)
marker_tmp
marker
for(i in 1:100){
index<-sample(1:8983,8983,replace = TRUE)
Val_tmp<-ValidationSet[index,]
marker_tmp <- marker[index]
AUC<-c()
#1. iAUC_uno +
Surv.rsp.new <- Surv(Val_tmp$time, Val_tmp$status)
#iAUC
km_fit_test <- survfit(Surv.rsp.new ~ 1, data = Val_tmp)
km_time<-summary(km_fit_test)$time
km_survival<-summary(km_fit_test)$surv
km_time<-km_time[-length(km_time)]
km_survival<-km_survival[-length(km_survival)]
AUC_uno <- AUC.uno(Surv.rsp.new, Surv.rsp.new, lpnew = marker_tmp, times = km_time)
#iAUC<-IntAUC(AUC_uno$auc,AUC_uno$times,km_survival,90,auc.type = "cumulative")
km_survival_w<-c(1,km_survival[-length(km_survival)])
km_survival_sum<-sum(km_survival_w-km_survival)
weight<-(km_survival_w-km_survival)/km_survival_sum
iAUC<-sum(weight*AUC_uno$auc)
AUC<- c(AUC,iAUC)
AUC_all<-rbind(AUC_all,AUC)}
AUC_all_tmp<-AUC_all
AUC_all_tmp<-AUC_all_tmp[-1,]
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
d<-sapply(AUC_all_tmp,function(x)sd(x)/sqrt(length(x)))
up<-round(m+1.96*d,3)
down<-round(m-1.96*d,3)
result<-paste0(round(m,3)," (",down,"-",up,")")
names(result)<-names(AUC_all)
AUC_all<-data.frame(iAUC=0,C_index=0)
for(i in 1:100){
index<-sample(1:4491,4491,replace = TRUE)
Val_tmp<-ValidationSet[index,]
marker_tmp <- marker[index]
AUC<-c()
#1. iAUC_uno +
Surv.rsp.new <- Surv(Val_tmp$time, Val_tmp$status)
#iAUC
km_fit_test <- survfit(Surv.rsp.new ~ 1, data = Val_tmp)
km_time<-summary(km_fit_test)$time
km_survival<-summary(km_fit_test)$surv
km_time<-km_time[-length(km_time)]
km_survival<-km_survival[-length(km_survival)]
AUC_uno <- AUC.uno(Surv.rsp.new, Surv.rsp.new, lpnew = marker_tmp, times = km_time)
#iAUC<-IntAUC(AUC_uno$auc,AUC_uno$times,km_survival,90,auc.type = "cumulative")
km_survival_w<-c(1,km_survival[-length(km_survival)])
km_survival_sum<-sum(km_survival_w-km_survival)
weight<-(km_survival_w-km_survival)/km_survival_sum
iAUC<-sum(weight*AUC_uno$auc)
AUC<- c(AUC,iAUC)
AUC_all<-rbind(AUC_all,AUC)}
AUC_all_tmp<-AUC_all
AUC_all_tmp<-AUC_all_tmp[-1,]
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
d<-sapply(AUC_all_tmp,function(x)sd(x)/sqrt(length(x)))
up<-round(m+1.96*d,3)
down<-round(m-1.96*d,3)
result<-paste0(round(m,3)," (",down,"-",up,")")
names(result)<-names(AUC_all)
result
sapply(AUC_all_tmp,quantile)
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025,0.5,0.975))})
AUC_all_tmp
AUC_all_tmp
result
m
m
m
up
up
AUC_all_tmp
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025,0.5,0.975))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
colSums(AUC_all_tmp)
m<-colMeans(AUC_all_tmp)
up<-sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.975))})
down<-sapply(AUC_all_tmp,function(x){quantile(x,probs = c(0.025))})
paste0(round(m,3)," (",down,"-",up,")")
paste0(round(m,3)," (",round(down,3),"-",round(up,3),")")
paste0(round(m,3)," (",round(down,3),"-",round(up,3),")")
m
concordance.index(x=marker, surv.time=ValidationSet$time, surv.event=ValidationSet$status)
concordance.index(x=marker, surv.time=ValidationSet$time, surv.event=ValidationSet$status)
library(survAUC)
library(survcomp)
concordance.index(x=marker, surv.time=ValidationSet$time, surv.event=ValidationSet$status)
concordancefit(Surv.rsp.new, -marker)
concordancefit(Surv.rsp.new, marker)

a<-round(as.numeric(ci(roc(label_list[[j]],score_list[[i]],quiet = T))),digits = 3)
auc_result[i,j]<-paste(a[2]," ","(",a[1],"-",a[3],")",sep="")}}
r<-data.frame(auc_result)
colnames(r)<-c("mortality_3d","2-day Mortality","mortality_5d","$mortality_7d","mortality_14d")
row.names(r)<-c("SERP","CART","PACS","MEWS","NEWS","CCI")
View(r)
save.image("D:/NBoxDocuments2/EDData_SERP/CodeForPaperFormation/SERP_clinical_tableGeneration_runing_revised_paper.RData")
dput(names(FD1))
FD2<-FD1[!FD1$admit_year=="2016",]
##311196
## Data Pre-selection
FD2<-FD2[FD2$validity==1,]
preselect<-c("Age", "Gender",
"ShiftTime", "DayofWeek", "Pulse", "Respiration",
"SPO2", "BP_Diastolic", "BP_Systolic",  "MI", "CHF", "PVD", "Stroke",
"Dementia", "Pulmonary", "Rheumatic", "PUD", "LiverD", "Diabetes",
"Paralysis", "Renal", "AllCancer",
"Num_visit_last_1yr",  "Total_Num_Surgery_last1yr",  "Total_icu_count_last1yr",  "Total_hd_count_last1yr",
"Mortality_2d", "mortality_3d",
"mortality_5d", "mortality_7d", "mortality_14d")
FD2<-FD2[,preselect]
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, cache = FALSE)
data("sample_data")
head(sample_data)
library(AutoScore)
data("sample_data")
head(sample_data)
load("D:/Document/Project_AutoScore/Project_development/AutoScoreR_markdown_and_dev/packageDev.RData")
View(sample_data)
set.seed(4)
sample_data_small <- sample_data[sample(1:20000, size = 1000),]
load("D:/Document/GitHub/AutoScore_Improvement/Data/testdf6_mimic_20000.Rdata")
model<-glm(label~.,testdf6_mimic_20000,family = binomial(link = "logit"))
str(testdf6_mimic_20000)
testdf6_mimic_20000$label<-NULL
testdf6_mimic_20000$spo2_mean<-log(testdf6_mimic_20000$spo2_mean)
colMeans(testdf6_mimic_20000)
cov(testdf6_mimic_20000)
sigma<-cov(testdf6_mimic_20000)
library(mvtnorm)
x <- rmvnorm(n=20000, mean=colMeans(testdf6_mimic_20000), sigma=sigma)
sample_data<-data.frame(x)
sample_data[sample_data<0]<-0
sample_data$label<-predict(model, sample_data,type = "link")
sample_data$label<-sample_data$label+ rnorm(20000,mean = 0, sd = 1)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)}
sample_data$label<-logit2prob(sample_data$label)
mean(sample_data$label>0.88)
mean(sample_data$label>0.96)
mean(sample_data$label>0.25)
mean(sample_data$label>0.50)
mean(sample_data$label>0.50)
mean(sample_data$label>0.50)
sample_data$label<-sample_data$label>0.5
sample_data$label<-as.factor(sample_data$label)
sample_data$spo2_mean<-exp(sample_data$spo2_mean)
sample_data$spo2_mean[sample_data$spo2_mean>100]<-100
sample_data[,c("tempc_mean","aniongap_mean","creatinine_mean","lactate_mean","potassium_mean")]<-round(sample_data[,c("tempc_mean","aniongap_mean","creatinine_mean","lactate_mean","potassium_mean")],1)
sample_data[,c("heartrate_mean", "sysbp_mean", "diasbp_mean", "meanbp_mean",
"resprate_mean",  "spo2_mean", "glucose_mean",
"bicarbonate_mean",  "chloride_mean", "hematocrit_mean",
"hemoglobin_mean",  "platelet_mean",
"bun_mean", "sodium_mean", "wbc_mean", "Age")]<- round(sample_data[,c("heartrate_mean", "sysbp_mean", "diasbp_mean", "meanbp_mean",
"resprate_mean",  "spo2_mean", "glucose_mean",
"bicarbonate_mean",  "chloride_mean", "hematocrit_mean",
"hemoglobin_mean",  "platelet_mean",
"bun_mean", "sodium_mean", "wbc_mean", "Age")],0)
set.seed(4)
sample_data_small <- sample_data[sample(1:20000, size = 1000),]
out_split <- split_data(data = sample_data_small, ratio = c(0.7, 0, 0.3), cross_validation = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 20,
cross_validation = TRUE,
categorize = "quantile",
fold = 10,
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),
do_trace = FALSE
)
num_var <- 6
final_variables <- names(ranking[1:num_var])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
cut_vec$platelet_mean <- c(150, 300)
cut_vec$lactate_mean <- c(1, 2, 3)
cut_vec$bun_mean <- c(12, 25)
cut_vec$heartrate_mean <- c(75, 90)
cut_vec$tempc_mean <- c(36.8, 37.2)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 100)
pred_score <- AutoScore_testing(test_set, final_variables, cut_vec, scoring_table, threshold = "best", with_label = TRUE)
head(pred_score)
set.seed(5)
sample_data_small <- sample_data[sample(1:20000, size = 1000),]
out_split <- split_data(data = sample_data_small, ratio = c(0.7, 0, 0.3), cross_validation = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 20,
cross_validation = TRUE,
categorize = "quantile",
fold = 10,
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),
do_trace = FALSE
)
num_var <- 5
final_variables <- names(ranking[1:num_var])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
cut_vec$platelet_mean <- c(150, 300)
cut_vec$lactate_mean <- c(1, 2, 3)
cut_vec$bun_mean <- c(12, 25)
cut_vec$heartrate_mean <- c(75, 90)
cut_vec$tempc_mean <- c(36.8, 37.2)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 100)
pred_score <- AutoScore_testing(test_set, final_variables, cut_vec, scoring_table, threshold = "best", with_label = TRUE)
head(pred_score)
library(usethis)
use_data(sample_data_small,overwrite = TRUE)
use_data(sample_data_small,overwrite = TRUE)
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
cut_vec$bun_mean <- c(10, 45)
cut_vec$platelet_mean <- c(50, 120, 300)
cut_vec$lactate_mean <- c(1, 2, 3)
cut_vec$Age <- c(35, 50, 80)
cut_vec$heartrate_mean <- c(60, 75, 100)
cut_vec$resprate_mean <- c(15,22)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 100)
pred_score <- AutoScore_testing(test_set, final_variables, cut_vec, scoring_table, threshold = "best", with_label = TRUE)
head(pred_score)
data("sample_data_small")
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
data("sample_data_small")
devtools::load_all(".")
library(AutoScore)
library(AutoScore)
load("D:/Document/Project_AutoScore_validation/data_big.RData")
library(AutoScore)
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, cache = FALSE)
set.seed(4)
sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
save(sample_data,file="D:/Document/Project_AutoScore_validation/data_big_pure.RData")
load("D:/Document/Project_AutoScore_validation/data_big_pure.RData")
set.seed(4)
sample_data<-FD2
set.seed(4)
#sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
summary(sample_data$base_excess_median)
plot(sample_data$base_excess_median)
num_var <- 5
final_variables <- names(ranking[c(1:num_var)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
#cut_vec$ph_median <- c(7.35, 7.4)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
pred_score <- AutoScore_testing(test_set, final_variables, cut_vec, scoring_table, threshold = "best", with_label = TRUE)
head(pred_score)
print_roc_performance(pred_score$Label, pred_score$pred_score, threshold = 50)
rank = ranking
mean(is.na(sample_data$base_excess_median))
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
AUC <- c()
i<-6
cat(paste("Select",i,"Variable(s):  "))
variable_list<-names(rank)[1:i]
train_set_1 <- train_set[, c(variable_list, "label")]
validation_set_1 <- validation_set[, c(variable_list, "label")]
model_roc<-compute_auc_val(train_set_1, validation_set_1,variable_list, categorize, quantiles, max_cluster, max_score)
compute_auc_val
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
compute_auc_val
model_roc<-compute_auc_val(train_set_1, validation_set_1,variable_list, categorize, quantiles, max_cluster, max_score)
categorize = "quantile"
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
do_trace = FALSE
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
max_score = 100,
max_score = 100
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
#source('D:/Document/GitHub/AutoScore_Improvement/AutoScore_TBP/AutoScore_new.R')
library(pROC)
library(randomForest)
library(ggplot2)
library(tableone)
library(knitr)
#source('D:/Document/GitHub/AutoScore_Improvement/AutoScore_TBP/AutoScore_new.R')
model_roc<-compute_auc_val(train_set_1, validation_set_1, variable_list, categorize, quantiles, max_cluster, max_score)
View(train_set_1)
View(validation_set)
View(validation_set_1)
mean(is.na(validation_set_1$base_excess_median))
cut_vec <- get_cut_vec(train_set_1, categorize = categorize, quantiles = quantiles, max_cluster = max_cluster)
train_set_2 <- transform_df_fixed(train_set_1, cut_vec)
validation_set_2 <- transform_df_fixed(validation_set_1, cut_vec)
View(validation_set_2)
View(validation_set_1)
View(train_set_1)
transform_df_fixed
df<-validation_set_1
i<-6
floor(min(df[, i]))*0.8
floor(min(df[, i]))
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 20,
cross_validation = TRUE,
categorize = "quantile",
fold = 10,
quantiles = c(0, 0.25, 0.5, 0.75, 1), #c(0, 0.05, 0.2, 0.8, 0.95, 1)
do_trace = FALSE
)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
num_var <- 5
final_variables <- names(ranking[c(1:num_var)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
cut_vec$lactate_median <- c(15)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
#cut_vec$lactate_mean <- c(1, 2, 3)
#cut_vec$bun_mean <- c(12, 25, 40)
#cut_vec$aniongap_mean <- c(11, 16)
cut_vec$ph_median <- c(7.25)
scoring_table <- AutoScore_fine_tuning(train_set,
validation_set,
final_variables,
cut_vec,
max_score = 50)
load("D:/Document/Project_AutoScore_validation/data_big.RData")
data <- read.csv("C:/Users/XFE/Downloads/numeric_steroid_mv_demo_final_0519_2.csv", stringsAsFactors=TRUE)
colSums(is.na(data ))
q<-colSums(is.na(data ))/length(data [,1])
#deteling
data1<-data[,q<0.68]
#check density and outlier!!Good checker
par(mfrow=c(5,5))
i<-1
plot(density(data1[,i],na.rm=T),main=names(data1)[i])
print(names(data1)[i])
i<-i+1
data1$calcium_first[data1$calcium_first>50]<-NA
data1$calcium_median[data1$calcium_median>50]<-NA
data1$magnesium_first[data1$magnesium_first>50]<-NA
data1$magnesium_median[data1$magnesium_median>50]<-NA
data1$ph_first[data1$ph_first>10]<-NA
data1$ph_median[data1$ph_median>10]<-NA
data1$phosphorus_first[data1$phosphorus_first>20]<-NA
data1$phosphorus_median[data1$phosphorus_median>20]<-NA
sele_sa<-data1$sao2_median>2
sele_sa[is.na(sele_sa)]<-FALSE
data1$sao2_median[sele_sa] <-data1$sao2_median[sele_sa]/100
sele_sa<-data1$sao2_first>2
sele_sa[is.na(sele_sa)]<-FALSE
data1$sao2_first[sele_sa] <-data1$sao2_first[sele_sa]/100
data1$mortality_2d<-data1$dateofdeath<8.64e+7*2
data1$mortality_2d[is.na(data1$mortality_2d)]<-FALSE
summary(data1$mortality_2d)
data1$mortality_3d<-data1$dateofdeath<8.64e+7*3
data1$mortality_3d[is.na(data1$mortality_3d)]<-FALSE
summary(data1$mortality_3d)
data1$mortality_7d<-data1$dateofdeath<8.64e+7*7
data1$mortality_7d[is.na(data1$mortality_7d)]<-FALSE
summary(data1$mortality_7d)
data1$mortality_14d<-data1$dateofdeath<8.64e+7*14
data1$mortality_14d[is.na(data1$mortality_14d)]<-FALSE
summary(data1$mortality_14d)
data1$mortality_icu<-data1$destination=="Overleden"
summary(data1$mortality_icu)
data1$label<-data1$mortality_3d
data1$label<-data1$mortality_icu
data_first<-data1[,c("INR_first", "alkaline_phosphatase_first",
"base_excess_first", "calcium_first", "chloride_first", "creatinine_first",
"diastolic_blood_pressure_first", "glucose_first", "hco3_first",
"heart_rate_first", "hematocrit_first", "lactate_first", "magnesium_first",
"mean_arterial_blood_pressure_first", "pao2_first", "pco2_first",
"ph_first", "phosphorus_first", "potassium_first", "sao2_first",
"sodium_first", "systolic_blood_pressure_first", "temperature_first",
"steroid_t_or_f", "mv_t_or_f", "gender",
"agegroup", "label" )]
FD2<-data_first
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
library(caret)
preProcValues <- preProcess(FD2, method = c("medianImpute"))
FD2<- predict(preProcValues, FD2)
#library('RANN')
colSums(is.na(FD2))/length(FD2[,2])
str(FD2)
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
set.seed(4)
sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
data1$label<-data1$mortality_icu
data_first<-data1[,c("INR_first", "alkaline_phosphatase_first",
"base_excess_first", "calcium_first", "chloride_first", "creatinine_first",
"diastolic_blood_pressure_first", "glucose_first", "hco3_first",
"heart_rate_first", "hematocrit_first", "lactate_first", "magnesium_first",
"mean_arterial_blood_pressure_first", "pao2_first", "pco2_first",
"ph_first", "phosphorus_first", "potassium_first", "sao2_first",
"sodium_first", "systolic_blood_pressure_first", "temperature_first",
"steroid_t_or_f", "mv_t_or_f", "gender",
"agegroup", "label" )]
FD2<-data_first
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
library(caret)
preProcValues <- preProcess(FD2, method = c("medianImpute"))
FD2<- predict(preProcValues, FD2)
#library('RANN')
colSums(is.na(FD2))/length(FD2[,2])
str(FD2)
colSums(is.na(FD2))
colSums(is.na(FD2))/length(FD2[,1])
set.seed(4)
sample_data<-FD2
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
ranking <- AutoScore_rank(train_set, ntree=100)
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])
# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])
# Example 3: Top 6 variables, the 9th and 10th variable are selected
num_var <- 5
final_variables <- names(ranking[c(1:num_var, 17, 18)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])
# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])
# Example 3: Top 6 variables, the 9th and 10th variable are selected
num_var <- 5
final_variables <- names(ranking[c(1:num_var, 13, 14)])
cut_vec <- AutoScore_weighting(
train_set,
validation_set,
final_variables,
max_score = 100,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)
source('D:/Document/GitHub/my_AutoScore/R/AutoScore.R')
AUC <- AutoScore_parsimony(
train_set,
validation_set,
rank = ranking,
max_score = 100,
n_min = 1,
n_max = 27,
categorize = "quantile",
quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
)

# AutoScore for survival outcomes (AutoScore-Survival) {#top}

## development with large sample

(sample size = 20000)**

### load package and survival data
```{r}
library(AutoScore)
data("sample_data_survival")
check_data_survival(sample_data_survival)
```


In Demo #1, we demonstrate the use of AutoScore on a comparably large dataset where separate training and validation sets are available. 
Please note that it is just a demo using simulated data, and thus, the result might not be clinically meaningful.

### Prepare training, validation, and test datasets
- Option 1: Prepare three separate datasets to train, validate, and test models.
- Option 2: Use demo codes below to randomly split your dataset into training, validation, and test datasets (70%, 10%, 20%, respectively).
```{r}
set.seed(4)
out_split <- split_data(data = sample_data_survival, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
```


### STEP(i): Generate variable ranking list with Random Survival Forest (AutoScore Module 1)
- `ntree`: Number of trees required only if when `method` is "rf" (Default: 100).(More time is needed if you run a larger number of trees. For demostration purpose, I just use `ntree = 10` in this guidebook)
```{r}
ranking <- AutoScore_rank_Survival(train_set, ntree = 5)
```

### STEP(ii): Select the best model with parsimony plot (AutoScore Modules 2+3+4)
- `nmin`: Minimum number of selected variables (Default: 1).
- `nmax`: Maximum number of selected variables (Default: 20).
- `categorize`: Methods for categorizing continuous variables. Options include `"quantile"` or `"kmeans"` (Default: `"quantile"`).
- `quantiles`: Predefined quantiles to convert continuous variables to categorical ones. (Default: `c(0, 0.05, 0.2, 0.8, 0.95, 1)`) Available if `categorize = "quantile"`.
- `max_cluster`: The max number of cluster (Default: 5). Available if `categorize = "kmeans"`.
- `max_score`: Maximum total score (Default: 100).
- `auc_lim_min`: Min y_axis limit in the parsimony plot (Default: 0.5). 
- `auc_lim_max`: Max y_axis limit in the parsimony plot (Default: "adaptive"). 
```{r, }
iAUC <- AutoScore_parsimony_Survival(
    train_set,
    validation_set,
    rank = ranking,
    max_score = 100,
    n_min = 1,
    n_max = 20,
    categorize = "quantile",
    quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),
    auc_lim_min = 0.5,
    auc_lim_max = "adaptive"
  )

```

- Users could use the `iAUC` for further analysis or export it as the CSV to other software for plotting.
```{r csv_generate2, eval=FALSE}
write.csv(data.frame(iAUC), file = "D:/iAUC.csv")
```

- Determine the optimal number of variables (`num_var`) based on the parsimony plot obtained in STEP(ii). 
- The final list of variables is the first `num_var` variables in the ranked list `ranking` obtained in STEP(i). 
- Optional: User can adjust the finally included variables `final_variables` based on the clinical preferences and knowledge.
```{r}
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])

# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])

# Example 3: Top 6 variables, the 9th and 10th variable are selected
num_var <- 6
final_variables <- names(ranking[c(1:num_var, 9, 10)])
```


```{r finalvariab2, results = "hide", warning=TRUE, message=FALSE,eval=TRUE,include=FALSE}
num_var <- 6
final_variables <- names(ranking[1:num_var])
```

### STEP(iii): Generate initial scores with the final list of variables (Re-run AutoScore Modules 2+3)
- Generate `cut_vec` with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).
- `time_point`: The time points to be evaluated using time-dependent AUC(t).
```{r weighting,fig.width=5,fig.height=5,warning = FALSE}
cut_vec <- AutoScore_weighting_Survival( 
    train_set,
    validation_set,
    final_variables,
    max_score = 100,
    categorize = "quantile",
    quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),
    time_point = c(1,3,7,14,30,60,90)
  )

```

### STEP(iv): Fine-tune the initial score generated in STEP(iii) (AutoScore Module 5 & Re-run AutoScore Modules 2+3) 
- Revise `cut_vec` with domain knowledge to update the scoring table (AutoScore Module 5).
- Re-run AutoScore Modules 2+3 to generate the updated scores.
- Users can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.
- `time_point`: The time points to be evaluated using time-dependent AUC(t).

```{r}
## For example, we have current cutoffs of continuous variable: Age 
## ==============  ===========  =====
## variable        interval     point
## ==============  ===========  =====
## Age             <35            0  
##                 [35,49)        7  
##                 [49,76)       17  
##                 [76,89)       23  
##                 >=89          27  
```

- Current cutoffs:`c(35, 49, 76, 89)`. We can fine tune the cutoffs as follows:
```{r}

# Example 1: rounding up to a nice number
cut_vec$Age <- c(35, 50, 75, 90)

# Example 2: changing cutoffs according to clinical knowledge or preference 
cut_vec$Age <- c(25, 50, 75, 90)

# Example 3: combining categories
cut_vec$Age <- c(50, 75, 90)

```
- Then we do similar checks for other variables and update scoring table using new cutoffs if needed.
```{r scoring,fig.width=5,fig.height=5, warning = FALSE}
cut_vec$Lab_H <- c(0.2, 1, 3, 4)
cut_vec$Lab_K <- c(10, 40)
cut_vec$Lab_B <- c(10, 17)
cut_vec$hVital_A<- c(70, 98)
scoring_table <- AutoScore_fine_tuning_Survival(train_set,
                        validation_set,
                        final_variables,
                        cut_vec,
                        max_score = 100,
                        time_point = c(1,3,7,14,30,60,90))

```

### STEP(v): Evaluate final risk scores on test dataset (AutoScore Module 6)
- `threshold`: Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to `"best"`, the optimal threshold will be calculated (Default: `"best"`).
- `with_label`: Set to `TRUE` if there are labels in the `test_set` and performance will be evaluated accordingly (Default: `TRUE`).
- Set the `with_label` to `FALSE` if there are not `label` in the `test_set` and the final predicted scores will be the output without performance evaluation.
- `time_point`: The time points to be evaluated using time-dependent AUC(t).
```{r,fig.width=5,fig.height=5,warning = FALSE}
pred_score <-
  AutoScore_testing_Survival(
    test_set,
    final_variables,
    cut_vec,
    scoring_table,
    threshold = "best",
    with_label = TRUE,
    time_point = c(1,3,7,14,30,60,90)
  )
head(pred_score)
```


## Further evaluation (conversion table, calibration etc)

Further analysis based on the final scoring systems (e.g., conversion table, model calibration, output the score)

- Use `plot_survival_km()` to generate Kaplan Meier Curve under different score thresholds (decided by users, e.g., 50).
```{r}
plot_survival_km(pred_score, score_cut = c(50))


```

- User can also use several score thresholds to cut the score for  generate Kaplan Meier Curve.
```{r}
plot_survival_km(pred_score, score_cut = c(40,50,60))

```

- Use `conversion_table_survival()` to generate the performance under different `score_cut` score cut-off (decided by users, e.g.,40,50,60).
- `time_point`: The time points to be evaluated using time-dependent AUC(t).
```{r,message=FALSE, warning=FALSE, error=FALSE}
table <- conversion_table_survival(pred_score, score_cut =c(40,50,60), time_point = c(7,14,30,60,90))

```

- You can also generate the `pred_score_train` based on training data for further analysis (e.g., KM curve or conversion table based on the training data).
```{r,fig.show="hide",fig.width=5,fig.height=5,warning = FALSE}
pred_score_train <-
  AutoScore_testing_Survival(
    train_set,
    final_variables,
    cut_vec,
    scoring_table,
    threshold = "best",
    with_label = TRUE,
    time_point = c(1,3,7,14,30,60,90)
  )
```

- Generate conversion table based on the training data different `score_cut` score cut-off (decided by users, e.g.,40,50,60).
```{r,message=FALSE, warning=FALSE, error=FALSE}
conversion_table_survival(pred_score_train, score_cut =c(40,50,60), time_point = c(7,14,30,60,90))
```

- Users could use the `pred_score` or `pred_score_train` for further analysis or export it as the CSV to other software (e.g., generating other curves).
```{r csv_generate3, eval=FALSE}
write.csv(pred_score, file = "D:/pred_score.csv")
write.csv(pred_score_train, file = "D:/pred_score_train.csv")
```


## development on Small dataset (sample size = 1000) with cross-validation for survival outcomes**

In Demo #2, we demonstrate the use of AutoScore on a comparably small dataset where there are no sufficient samples to form a separate training and validation datasets. Thus, the cross validation is employed to generate the parsimony plot.

### Get small dataset with 1000 samples
```{r}
data("sample_data_survival_small")
```

### Prepare training and test datasets
- Option 1: Prepare two separate datasets to train and test models.
- Option 2: Use demo codes below to randomly split your dataset into training and test datasets (70% and 30%, respectively). For cross-validation, `train_set` is equal to `validation_set` and the ratio of `validation_set` should be 0. Then cross-validation will be implemented in the STEP(ii) `AutoScore_parsimony()`.
```{r}
set.seed(4)
out_split <- split_data(data = sample_data_survival_small, ratio = c(0.7, 0, 0.3), cross_validation = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
```





## development on dataset with missing values (informative missing)**

In Demo #3, we demonstrate the use of AutoScore on a dataset with missing values. AutoScore can automatically treat the missingness as a new category named `Unknown`. Please note that it is just a demo using simulated data, and thus, the result might not be clinically meaningful.

### load package and data
```{r, warning=FALSE}
library(AutoScore)
data("sample_data_survival")
check_data_survival(sample_data_survival)
```
### Create informative missing
```{r}
sample_data_survival <- AutoScore:::induce_informative_missing(sample_data_survival, vars_to_induce = names(sample_data_survival)[1:2], prop_missing = c(0.2, 0.6))
```

The following steps are similar to Demo #1. 

```{r, include=FALSE}
set.seed(4)
out_split <- split_data(data = sample_data_survival, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set

ranking <- AutoScore_rank_Survival(train_set, ntree = 5)
```

NOTE: 

- High missing rate may cause the variable ranking less reliable, and thus, caution is needed for variable selection using parsimony plot.

```{r, results = "hide"}
iAUC <- AutoScore_parsimony_Survival(
    train_set,
    validation_set,
    rank = ranking,
    max_score = 100,
    n_min = 1,
    n_max = 20,
    categorize = "quantile",
    quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1),
    auc_lim_min = 0.5,
    auc_lim_max = "adaptive"
  )

```

```{r, results = "hide", warning=TRUE, message=FALSE,eval=TRUE,include=FALSE}
num_var <- 6
final_variables <- names(ranking[1:num_var])

cut_vec <- AutoScore_weighting_Survival( 
    train_set,
    validation_set,
    final_variables,
    max_score = 100,
    categorize = "quantile",
    quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1)
  )

cut_vec$Age <- c(50, 75, 90)
cut_vec$Lab_H <- c(0.2, 1, 3, 4)
cut_vec$Lab_K <- c(10, 40)
cut_vec$Lab_B <- c(10, 17)
cut_vec$hVital_A<- c(70, 98)
```

- The `Unknown` category indicating the missingness will be displayed in the final scoring table.

```{r echo=FALSE,fig.width=5,fig.height=5}
scoring_table <- AutoScore_fine_tuning_Survival(train_set,
                        validation_set,
                        final_variables,
                        cut_vec,
                        max_score = 100)
```

```{r,fig.width=5,fig.height=5,warning = FALSE, include=FALSE}
pred_score <-
  AutoScore_testing_Survival(
    test_set,
    final_variables,
    cut_vec,
    scoring_table,
    threshold = "best",
    with_label = TRUE
  )
head(pred_score)
plot_survival_km(pred_score, score_cut = c(50))
```

# AutoScore for ordinal outcomes (AutoScore-Ordinal) {#top}

```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.width = 7, fig.height = 5)
```

AutoScore-Ordinal refers to the AutoScore framework for developing point-based
scoring models for ordinal outcomes. Similar to the implementation described in
[Chapter 4](04-autoscore.qmd#top) for binary outcomes, AutoScore-Ordinal is
implemented by five functions: `AutoScore_rank_Ordinal()`,
`AutoScore_parsimony_Ordinal()`, `AutoScore_weighting_Ordinal()`,
`AutoScore_fine_tuning_Ordinal()` and `AutoScore_testing_Ordinal()`.

In this chapter, we demonstrate the use of AutoScore-Ordinal to develop sparse
risk scores for an ordinal outcome, adjust parameters to improve
interpretability, assess the performance of the final model and map the score to
predict risks for new data. To facilitate clinical applications, in the
following sections we demonstrate AutoScore application in 3 demos with large
and small datasets and with missing information.

::: callout-important
- *Scoring models below are based on simulated data to demonstrate AutoScore usage.* 
- *Variable names are intentionally masked to avoid misinterpretation and misuse.*
:::

Cite the following paper for AutoScore-Ordinal:

* Saffari SE, Ning Y, Xie F, Chakraborty B, Volovici V, Vaughan R, Ong MEH, Liu N, [AutoScore-Ordinal: An interpretable machine learning framework for generating scoring models for ordinal outcomes](https://doi.org/10.48550/arxiv.2202.08407), arXiv:2202.08407.

## Demo 1: large sample {#demo1}

In Demo 1, we demonstrate the use of AutoScore-Ordinal on a dataset with 20,000
observations using split-sample approach (i.e., to randomly divide the full
dataset into training, validation and test sets) for model development.

::: callout-important
*- Before proceeding, follow the steps in [Chapter 2](03-data_processing.qmd#top)
to ensure all data requirements are met.*
*- Refer to [Chapter 3](02-desc_analysis.qmd#ordinal) for how to generate simple
descriptive statistics before building prediction models.*
:::

<p class='p-h3'>Load package and data</p>

```{r, warning=TRUE, message=TRUE}
library(AutoScore)
data("sample_data_ordinal")
dim(sample_data_ordinal)
head(sample_data_ordinal)
check_data_ordinal(sample_data_ordinal)
```

<p class='p-h3'>Prepare training, validation, and test datasets</p>

- Option 1: Prepare three separate datasets to train, validate, and test models.
- Option 2: Use demo codes below to randomly split your dataset into training,
validation, and test datasets (70%, 10%, 20%, respectively), possibly stratified
by outcome categories (`strat_by_label = TRUE`) to ensure they are well
represented in all three datasets.

```{r}
set.seed(4)
out_split <- split_data(data = sample_data_ordinal, ratio = c(0.7, 0.1, 0.2), 
                        strat_by_label = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
```

### STEP(i): generate variable ranking list 

<p class="autoscore-module">AutoScore-Ordinal Module 1</p>

- Variables are ranked by random forest for multiclass classification.
- `ntree`: Number of trees in the random forest algorithm (Default: 100).

```{r rank_ord, cache=TRUE}
ranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)
```

### STEP(ii): select model with parsimony plot {#large-data}

<p class="autoscore-module">AutoScore-Ordinal Modules 2+3+4</p>

- `n_min`: Minimum number of selected variables (Default: 1).
- `n_max`: Maximum number of selected variables (Default: 20).
- `categorize`: Methods for categorizing continuous variables. Options include
`"quantile"` or `"kmeans"` (Default: `"quantile"`).
- `quantiles`: Predefined quantiles to convert continuous variables to
categorical ones. (Default: `c(0, 0.05, 0.2, 0.8, 0.95, 1)`) Available if
`categorize = "quantile"`.
- `max_cluster`: The maximum number of cluster (Default: 5). Available if
`categorize = "kmeans"`.
- `max_score`: Maximum total score (Default: 100).
- `auc_lim_min`: Minimum y_axis limit in the parsimony plot (Default: 0.5). 
- `auc_lim_max`: Maximum y_axis limit in the parsimony plot (Default:
"adaptive").
- `link`: link function in the ordinal regression, which affects predictive
performance. Options include `"logit"` (for proportional odds model),
`"cloglog"` (for proportional hazard model) and `"probit"` (Default: `"logit"`).

::: callout-important
*Use the same `link` parameter throughout descriptive analysis and model building steps.* 
:::

```{r mauc_ord, cache=TRUE}
link <- "logit"
mAUC <- AutoScore_parsimony_Ordinal(
  train_set = train_set, validation_set = validation_set, 
  rank = ranking, link = link, max_score = 100, n_min = 1, n_max = 20,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  auc_lim_min = 0, auc_lim_max = "adaptive"
)
```

::: callout-note
- *Users could use `mAUC` for further analysis or export it to CSV to other software for plotting.*
```{r, eval=FALSE}
write.csv(data.frame(mAUC), file = "mAUC.csv")
```
:::

- Determine the optimal number of variables (`num_var`) based on the parsimony
plot obtained in STEP(ii).
- The final list of variables is the first `num_var` variables in the ranked
list `ranking` obtained in STEP(i).
- Optional: User can adjust the finally included variables `final_variables`
based on the clinical preferences and knowledge.

```{r}
# Example 1: Top 5 variables are selected
num_var <- 5
final_variables <- names(ranking[1:num_var])

# Example 2: Top 14 variables are selected
num_var <- 14
final_variables <- names(ranking[1:num_var])

# Example 3: Top 5 variables, the 11th and 14th variable are selected
final_variables <- names(ranking[c(1:5, 11, 14)])
```

### STEP(iii): generate initial scores with final variables 

<p class="autoscore-module">Re-run AutoScore-Ordinal Modules 2+3</p>

- Generate `cut_vec` with current cutoffs of continuous variables, which can be
fine-tuned in STEP(iv).
- Performance of resulting scores is evaluated using the mean AUC across
dichotomous classifications (mAUC), with 95% CI computed using bootstrap 
(Default: `n_boot = 100` bootstrap samples). Setting `n_boot = 1` disables
bootstrap and reports mAUC without CI.
- Run time increases with larger `n_boot` value. Code below uses `n_boot = 10`
for demonstration.

```{r}
cut_vec <- AutoScore_weighting_Ordinal(
  train_set = train_set, validation_set = validation_set, 
  final_variables = final_variables, link = link, max_score = 100,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  n_boot = 10
)
```

### STEP(iv): fine-tune initial score from STEP(iii) {#fine-tune}

<p class="autoscore-module">AutoScore-Ordinal Module 5 & Re-run AutoScore-Ordinal Modules 2+3</p>

-   Revise `cut_vec` with domain knowledge to update the scoring table
(AutoScore-Ordinal Module 5).
-   Re-run AutoScore-Ordinal Modules 2+3 to generate the updated scores.
-   Users can choose any cutoff values and/or any number of categories, but are
suggested to choose numbers close to the automatically determined values.

```{r}
## For example, we have current cutoffs of continuous variable: Age 
## ==============  ===========  =====
## variable        interval     point
## ==============  ===========  =====
## Age                 <27          0  
##                     [27,46)      4  
##                     [46,78)     14  
##                     [78,87)     18 
##                     >=87        21 
```

- Current cutoffs:`c(27, 46, 78, 87)`. We can fine tune the cutoffs as follows:

```{r}
# Example 1: rounding to a nice number
cut_vec$Age <- c(25, 45, 75, 85)

# Example 2: changing cutoffs according to clinical knowledge or preference 
cut_vec$Age <- c(25, 50, 75, 85)

# Example 3: combining categories
cut_vec$Age <- c(45, 75, 85)
```

- mAUC and 95% bootstrap CI (Default: `n_boot = 100` bootstrap samples) are
reported after fine-tuning.
- Run time increases with larger `n_boot` value. Code below uses `n_boot = 10`
for demonstration.

```{r, warning = FALSE}
cut_vec$Util_D <- c(2 / 3, 4 / 3, 4, 6)
cut_vec$Vital_F <- c(17, 20, 25, 28)
cut_vec$Vital_A <- c(60, 70, 95, 115)
cut_vec$Lab_A <- c(45, 60, 135, 595)
cut_vec$Age <- c(25, 45, 75, 85)
scoring_table <- AutoScore_fine_tuning_Ordinal(
  train_set = train_set, validation_set = validation_set,
  final_variables = final_variables, link = link, cut_vec = cut_vec,
  max_score = 100, n_boot = 10
)
```

### STEP(v): evaluate final risk scores on test dataset 

<p class="autoscore-module">AutoScore-Ordinal Module 6</p>

- mAUC and generalised c-index are reported for the test set, with 95% bootstrap
CI (Default: `n_boot = 100` bootstrap samples).
- Run time increases with larger `n_boot` value. Code below uses `n_boot = 10`
for demonstration.

```{r}
pred_score <- AutoScore_testing_Ordinal(
  test_set = test_set, link = link, final_variables = final_variables, 
  cut_vec = cut_vec, scoring_table = scoring_table, 
  with_label = TRUE, n_boot = 10
)
head(pred_score)
```

- Users can compute mAUC and generalised c-index (with 95% bootstrap CI) for
previously saved `pred_score`.

```{r}
print_performance_ordinal(
  label = pred_score$Label, score = pred_score$pred_score, 
  n_boot = 10, report_cindex = TRUE
)
```

### Map score to risk {#demo1-map}

- The interactive figure below maps score to predicted risks.
- `point_size`: Size of points indicating all attainable scores (Default: 0.5).

```{r}
plot_predicted_risk(pred_score = pred_score, max_score = 100, 
                    final_variables = final_variables, link = link,
                    scoring_table = scoring_table, point_size = 1)
```

- Given the proportion of subjects for each score value (see figure above),
select reasonable score breaks (Default: 5, 10, 15, ..., 70) to report the
average predicted risk within each score interval, which can be used to predict
risk for a new subject.
- When selecting score breaks, avoid creating score intervals with too few observations.

```{r}
conversion_table_ordinal(pred_score = pred_score, link = link,
                         score_breaks = seq(from = 5, to = 70, by = 5), 
                         digits = 4)
```

:::callout-note
- *Users could use `pred_score` for further analysis or export it to CSV to other software  (e.g., generating the calibration curve).*

```{r, eval=FALSE}
write.csv(pred_score, file = "pred_score.csv")
```
:::

## Demo 2: small sample {#demo2}

In Demo 2, we demonstrate the use of AutoScore-Ordinal on a smaller dataset
where there are no sufficient samples to form a separate training and validation
dataset. Thus, the cross validation is employed to generate the parsimony plot.

<p class='p-h3'>Load small dataset with 5000 samples</p>

```{r}
data("sample_data_ordinal_small")
```

<p class='p-h3'>Prepare training and test datasets</p>

- Option 1: Prepare two separate datasets to train and test models.
- Option 2: Use demo codes below to randomly split your dataset into training
and test datasets (70% and 30%, respectively). For cross-validation, `train_set`
is equal to `validation_set` and the ratio of `validation_set` should be 0. Then
cross-validation will be implemented in the STEP(ii),
`AutoScore_parsimony_Ordinal()`.

```{r}
set.seed(4)
out_split <- split_data(data = sample_data_ordinal_small, ratio = c(0.7, 0, 0.3), 
                        cross_validation = TRUE, strat_by_label = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
```

### STEP(i): generate variable ranking list 

<p class="autoscore-module">AutoScore-Ordinal Module 1</p>

- Variables are ranked by random forest for multiclass classification.
- `ntree`: Number of trees in the random forest algorithm (Default: 100).

```{r rank_ord_small, cache=TRUE}
ranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)
```

### STEP(ii): select the best model with parsimony plot 

<p class="autoscore-module">AutoScore-Ordinal Modules 2+3+4</p>

- `nmin`: Minimum number of selected variables (Default: 1).
- `nmax`: Maximum number of selected variables (Default: 20).
- `categorize`: Methods for categorizing continuous variables. Options include
`"quantile"` or `"kmeans"` (Default: `"quantile"`).
- `quantiles`: Predefined quantiles to convert continuous variables to
categorical ones. (Default: `c(0, 0.05, 0.2, 0.8, 0.95, 1)`) Available if
`categorize = "quantile"`.
- `max_cluster`: The maximum number of cluster (Default: 5). Available if
`categorize = "kmeans"`.
- `max_score`: Maximum total score (Default: 100).
- `auc_lim_min`: Minimum y_axis limit in the parsimony plot (Default: 0.5). 
- `auc_lim_max`: Maximum y_axis limit in the parsimony plot (Default: "adaptive"). 
- `cross_validation`: `TRUE` if cross-validation is needed, especially for
small datasets.
- `fold`: The number of folds used in cross validation (Default: 10). Available
if `cross_validation = TRUE`.
- `do_trace`: If set to `TRUE`, all results based on each fold of
cross-validation would be printed out and plotted (Default: `FALSE`). Available
if `cross_validation = TRUE`.
- `link`: link function in the ordinal regression, which affects predictive
performance. Options include `"logit"` (for proportional odds model),
`"cloglog"` (for proportional hazard model) and `"probit"` (Default: `"logit"`).

::: callout-important
*Use the same `link` parameter throughout descriptive analysis and model building steps.* 
:::

```{r mauc_ord_small, cache=TRUE}
link <- "logit"
mAUC <- AutoScore_parsimony_Ordinal(
  train_set = train_set, validation_set = validation_set, link = link,
  rank = ranking, max_score = 100, n_min = 1, n_max = 20,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  auc_lim_min = 0, auc_lim_max = "adaptive",
  cross_validation = TRUE, fold = 10, do_trace = FALSE
)
```

::: callout-note
- *Users could use `mAUC` for further analysis or export it to CSV to other software for plotting.*
```{r, eval=FALSE}
write.csv(data.frame(mAUC), file = "mAUC.csv")
```
:::

- Determine the optimal number of variables (`num_var`) based on the parsimony
plot obtained in STEP(ii).
- The final list of variables is the first `num_var` variables in the ranked
list `ranking` obtained in STEP(i).
- Optional: User can adjust the finally included variables `final_variables`
based on the clinical preferences and knowledge.

```{r}
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])

# Example 2: Top 14 variables are selected
num_var <- 14
final_variables <- names(ranking[1:num_var])

# Example 3: Top 3 variables, the 6th, 10th and 15th variable are selected
final_variables <- names(ranking[c(1:3, 6, 10, 15)])
```

### STEP(iii): generate initial scores with final variables 

<p class="autoscore-module">Re-run AutoScore-Ordinal Modules 2+3</p>

- Generate `cut_vec` with current cutoffs of continuous variables, which can be
fine-tuned in STEP(iv).
- Performance of resulting scores is evaluated using the mean AUC across
dichotomous classifications (mAUC), with 95% CI computed using bootstrap 
(Default: `n_boot = 100` bootstrap samples). Setting `n_boot = 1` disables
bootstrap and reports mAUC without CI.

```{r}
cut_vec <- AutoScore_weighting_Ordinal(
  train_set = train_set, validation_set = validation_set, 
  final_variables = final_variables, link = link, max_score = 100,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  n_boot = 10
)
```

### STEP(iv): fine-tune initial score from STEP(iii) 

<p class="autoscore-module">AutoScore-Ordinal Module 5 & Re-run AutoScore-Ordinal Modules 2+3</p>

-   Revise `cut_vec` with domain knowledge to update the scoring table
(AutoScore-Ordinal Module 5).
-   Re-run AutoScore-Ordinal Modules 2+3 to generate the updated scores.
-   Users can choose any cutoff values and/or any number of categories, but are
suggested to choose numbers close to the automatically determined values.

```{r}
## For example, we have current cutoffs of continuous variable: Age 
## ==============  ===========  =====
## variable        interval     point
## ==============  ===========  =====
## Age                 <27          0  
##                     [27,46)      4  
##                     [46,78)     14  
##                     [78,87)     18 
##                     >=87        21 
```

- Current cutoffs:`c(27, 46, 78, 87)`. We can fine tune the cutoffs as follows:

```{r}
# Example 1: rounding to a nice number
cut_vec$Age <- c(25, 45, 75, 85)

# Example 2: changing cutoffs according to clinical knowledge or preference 
cut_vec$Age <- c(25, 50, 75, 85)

# Example 3: combining categories
cut_vec$Age <- c(45, 75, 85)
```

- mAUC and 95% bootstrap CI (Default: `n_boot = 100` bootstrap samples) are
reported after fine-tuning.
- Run time increases with larger `n_boot` value. Code below uses `n_boot = 10`
for demonstration.

```{r}
cut_vec$Util_D <- c(2 / 3, 4 / 3, 4, 6)
cut_vec$Lab_A <- c(45, 60, 135, 595)
cut_vec$Age <- c(25, 45, 75, 85)
cut_vec$Vital_A <- c(60, 70, 95, 115)
scoring_table <- AutoScore_fine_tuning_Ordinal(
  train_set = train_set, validation_set = validation_set, link = link,
  final_variables = final_variables, cut_vec = cut_vec, max_score = 100, 
  n_boot = 10
)
```

### STEP(v): evaluate final risk scores on test dataset 

<p class="autoscore-module">AutoScore-Ordinal Module 6</p>

- mAUC and generalised c-index are reported for the test set, with 95% bootstrap
CI (Default: `n_boot = 100` bootstrap samples).
- Run time increases with larger `n_boot` value. Code below uses `n_boot = 10`
for demonstration.

```{r}
pred_score <- AutoScore_testing_Ordinal(
  test_set = test_set, link = link, final_variables = final_variables, 
  cut_vec = cut_vec, scoring_table = scoring_table, 
  with_label = TRUE, n_boot = 10
)
head(pred_score)
```

### Map score to risk

- Users can also map score to risk using `plot_predicted_risk()` and
`conversion_table_ordinal()`. Please refer to [our demo for large
sample (6.1.6)](#demo1-map) for detail.

## Demo 3: data with missing values

In Demo 3, we demonstrate AutoScore-Ordinal for application to data with missing
values in two variables (i.e., `Lab_A` and `Vital_A`).

```{r, include=FALSE}
data("sample_data_ordinal")
sample_data_ordinal_missing <- AutoScore:::induce_informative_missing(
  df = sample_data_ordinal, vars_to_induce = c("Lab_A", "Vital_A"), 
  prop_missing = c(0.2, 0.6)
)
```

```{r, message=TRUE, warning=TRUE}
check_data_ordinal(sample_data_ordinal_missing)
```

AutoScore can automatically treat the missingness as a new category named
`Unknown`. The following steps are the **same** as those in [Demo 1  (5.1)](#demo1).

::: callout-important
- *High missing rate may cause the variable ranking less reliable, and thus, caution is needed for variable selection using parsimony plot.*
:::

```{r missing_ord}
set.seed(4)
out_split <- split_data(data = sample_data_ordinal_missing, ratio = c(0.7, 0.1, 0.2), 
                        strat_by_label = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set

link <- "logit"
ranking <- AutoScore_rank_Ordinal(train_set = train_set, ntree = 100)
mAUC <- AutoScore_parsimony_Ordinal(
  train_set = train_set, validation_set = validation_set, link = link,
  rank = ranking, max_score = 100, n_min = 1, n_max = 20,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  auc_lim_min = 0
)
```

::: callout-note
- *The `Unknown` category indicating the missingness will be displayed in the final scoring table.*
:::

```{r}
final_variables <- names(ranking[c(1:3, 11, 14)])
cut_vec <- AutoScore_weighting_Ordinal(
  train_set = train_set, validation_set = validation_set, 
  final_variables = final_variables, link = link, max_score = 100,
  categorize = "quantile", quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  n_boot = 10
)
```
